{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMPqksOVP9ywLflfzYGFzDj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shaunck96/AI-Generated-News/blob/main/News_Reddit_Financials_Extractor.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install --quiet \"pyautogen>=0.2.3\"\n",
        "!pip install langchain==0.0.340\n",
        "!pip install openai==0.28\n",
        "!pip install langchain_community\n",
        "!pip install gnews\n",
        "!pip install tiktoken\n",
        "!pip install langchain_text_splitters\n",
        "#!pip install langchain_openai\n",
        "!pip install praw"
      ],
      "metadata": {
        "id": "xCfJrhnMm1a5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e6aa888-a465-4110-ddbf-275a42b43746"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain==0.0.340 in /usr/local/lib/python3.10/dist-packages (0.0.340)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.340) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.340) (2.0.28)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.340) (3.9.3)\n",
            "Requirement already satisfied: anyio<4.0 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.340) (3.7.1)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.340) (4.0.3)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.340) (0.6.4)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.340) (1.33)\n",
            "Collecting langsmith<0.1.0,>=0.0.63 (from langchain==0.0.340)\n",
            "  Using cached langsmith-0.0.92-py3-none-any.whl (56 kB)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.340) (1.25.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.340) (2.6.3)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.340) (2.26.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.340) (8.2.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.340) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.340) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.340) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.340) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.340) (1.9.4)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<4.0->langchain==0.0.340) (3.6)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<4.0->langchain==0.0.340) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4.0->langchain==0.0.340) (1.2.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain==0.0.340) (3.21.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain==0.0.340) (0.9.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain==0.0.340) (2.4)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain==0.0.340) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain==0.0.340) (2.16.3)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain==0.0.340) (4.10.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain==0.0.340) (1.26.18)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain==0.0.340) (2024.2.2)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain==0.0.340) (2.0.12)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain==0.0.340) (3.0.3)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json<0.7,>=0.5.7->langchain==0.0.340) (23.2)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain==0.0.340) (1.0.0)\n",
            "Installing collected packages: langsmith\n",
            "  Attempting uninstall: langsmith\n",
            "    Found existing installation: langsmith 0.1.23\n",
            "    Uninstalling langsmith-0.1.23:\n",
            "      Successfully uninstalled langsmith-0.1.23\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "langchain-community 0.0.27 requires langsmith<0.2.0,>=0.1.0, but you have langsmith 0.0.92 which is incompatible.\n",
            "langchain-core 0.1.30 requires langsmith<0.2.0,>=0.1.0, but you have langsmith 0.0.92 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed langsmith-0.0.92\n",
            "Collecting openai==0.28\n",
            "  Using cached openai-0.28.0-py3-none-any.whl (76 kB)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (2.26.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (4.66.2)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (3.9.3)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (1.26.18)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (2024.2.2)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (3.6)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (4.0.3)\n",
            "Installing collected packages: openai\n",
            "  Attempting uninstall: openai\n",
            "    Found existing installation: openai 1.13.3\n",
            "    Uninstalling openai-1.13.3:\n",
            "      Successfully uninstalled openai-1.13.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "pyautogen 0.2.17 requires openai>=1.3, but you have openai 0.28.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed openai-0.28.0\n",
            "Requirement already satisfied: langchain_community in /usr/local/lib/python3.10/dist-packages (0.0.27)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (2.0.28)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (3.9.3)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.6.4)\n",
            "Requirement already satisfied: langchain-core<0.2.0,>=0.1.30 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.1.30)\n",
            "Collecting langsmith<0.2.0,>=0.1.0 (from langchain_community)\n",
            "  Using cached langsmith-0.1.23-py3-none-any.whl (66 kB)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (1.25.2)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (2.26.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (8.2.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (4.0.3)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.21.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (0.9.0)\n",
            "Requirement already satisfied: anyio<5,>=3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.30->langchain_community) (3.7.1)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.30->langchain_community) (1.33)\n",
            "Requirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.30->langchain_community) (23.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.30->langchain_community) (2.6.3)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.0->langchain_community) (3.9.15)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (1.26.18)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (2024.2.2)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (3.6)\n",
            "Requirement already satisfied: typing-extensions>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain_community) (4.10.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain_community) (3.0.3)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core<0.2.0,>=0.1.30->langchain_community) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core<0.2.0,>=0.1.30->langchain_community) (1.2.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.2.0,>=0.1.30->langchain_community) (2.4)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core<0.2.0,>=0.1.30->langchain_community) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core<0.2.0,>=0.1.30->langchain_community) (2.16.3)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (1.0.0)\n",
            "Installing collected packages: langsmith\n",
            "  Attempting uninstall: langsmith\n",
            "    Found existing installation: langsmith 0.0.92\n",
            "    Uninstalling langsmith-0.0.92:\n",
            "      Successfully uninstalled langsmith-0.0.92\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "langchain 0.0.340 requires langsmith<0.1.0,>=0.0.63, but you have langsmith 0.1.23 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed langsmith-0.1.23\n",
            "Requirement already satisfied: gnews in /usr/local/lib/python3.10/dist-packages (0.3.6)\n",
            "Requirement already satisfied: feedparser~=6.0.2 in /usr/local/lib/python3.10/dist-packages (from gnews) (6.0.11)\n",
            "Requirement already satisfied: bs4~=0.0.1 in /usr/local/lib/python3.10/dist-packages (from gnews) (0.0.2)\n",
            "Requirement already satisfied: beautifulsoup4~=4.9.3 in /usr/local/lib/python3.10/dist-packages (from gnews) (4.9.3)\n",
            "Requirement already satisfied: pymongo~=3.12.0 in /usr/local/lib/python3.10/dist-packages (from gnews) (3.12.3)\n",
            "Requirement already satisfied: dnspython~=1.16.0 in /usr/local/lib/python3.10/dist-packages (from gnews) (1.16.0)\n",
            "Requirement already satisfied: python-dotenv~=0.19.0 in /usr/local/lib/python3.10/dist-packages (from gnews) (0.19.2)\n",
            "Requirement already satisfied: requests==2.26.0 in /usr/local/lib/python3.10/dist-packages (from gnews) (2.26.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests==2.26.0->gnews) (1.26.18)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests==2.26.0->gnews) (2024.2.2)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests==2.26.0->gnews) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests==2.26.0->gnews) (3.6)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4~=4.9.3->gnews) (2.5)\n",
            "Requirement already satisfied: sgmllib3k in /usr/local/lib/python3.10/dist-packages (from feedparser~=6.0.2->gnews) (1.0.0)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.10/dist-packages (0.6.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2023.12.25)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2.26.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (1.26.18)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2024.2.2)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.6)\n",
            "Requirement already satisfied: langchain_text_splitters in /usr/local/lib/python3.10/dist-packages (0.0.1)\n",
            "Requirement already satisfied: langchain-core<0.2.0,>=0.1.28 in /usr/local/lib/python3.10/dist-packages (from langchain_text_splitters) (0.1.30)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.28->langchain_text_splitters) (6.0.1)\n",
            "Requirement already satisfied: anyio<5,>=3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.28->langchain_text_splitters) (3.7.1)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.28->langchain_text_splitters) (1.33)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.28->langchain_text_splitters) (0.1.23)\n",
            "Requirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.28->langchain_text_splitters) (23.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.28->langchain_text_splitters) (2.6.3)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.28->langchain_text_splitters) (2.26.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.28->langchain_text_splitters) (8.2.3)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core<0.2.0,>=0.1.28->langchain_text_splitters) (3.6)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core<0.2.0,>=0.1.28->langchain_text_splitters) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core<0.2.0,>=0.1.28->langchain_text_splitters) (1.2.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.2.0,>=0.1.28->langchain_text_splitters) (2.4)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.0->langchain-core<0.2.0,>=0.1.28->langchain_text_splitters) (3.9.15)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core<0.2.0,>=0.1.28->langchain_text_splitters) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core<0.2.0,>=0.1.28->langchain_text_splitters) (2.16.3)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core<0.2.0,>=0.1.28->langchain_text_splitters) (4.10.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-core<0.2.0,>=0.1.28->langchain_text_splitters) (1.26.18)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-core<0.2.0,>=0.1.28->langchain_text_splitters) (2024.2.2)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-core<0.2.0,>=0.1.28->langchain_text_splitters) (2.0.12)\n",
            "Requirement already satisfied: praw in /usr/local/lib/python3.10/dist-packages (7.7.1)\n",
            "Requirement already satisfied: prawcore<3,>=2.1 in /usr/local/lib/python3.10/dist-packages (from praw) (2.4.0)\n",
            "Requirement already satisfied: update-checker>=0.18 in /usr/local/lib/python3.10/dist-packages (from praw) (0.18.0)\n",
            "Requirement already satisfied: websocket-client>=0.54.0 in /usr/local/lib/python3.10/dist-packages (from praw) (1.7.0)\n",
            "Requirement already satisfied: requests<3.0,>=2.6.0 in /usr/local/lib/python3.10/dist-packages (from prawcore<3,>=2.1->praw) (2.26.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.1->praw) (1.26.18)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.1->praw) (2024.2.2)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.1->praw) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.1->praw) (3.6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "2hhmVsNls8LA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d388e88a-87dd-432c-ec62-f9b46f2c22df"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "from langchain_community.document_loaders import WebBaseLoader\n",
        "import tiktoken\n",
        "import nltk\n",
        "from pydantic import BaseModel, Field\n",
        "from langchain.output_parsers import PydanticOutputParser\n",
        "from langchain.output_parsers import StructuredOutputParser, ResponseSchema\n",
        "from langchain.prompts import PromptTemplate, ChatPromptTemplate, HumanMessagePromptTemplate\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "import openai\n",
        "import ast\n",
        "from typing import List\n",
        "import json\n",
        "from gnews import GNews\n",
        "import pandas as pd\n",
        "from typing import Optional\n",
        "import praw\n",
        "import json\n",
        "import pandas as pd\n",
        "import logging\n",
        "from typing import Optional, List, Dict\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.output_parsers import PydanticOutputParser\n",
        "from pydantic import BaseModel, Field\n",
        "nltk.download('punkt')\n",
        "\n",
        "with open('openai_config.json', 'r') as f:\n",
        "    config = json.load(f)\n",
        "\n",
        "openai.api_key = config[\"openai_key\"]\n",
        "\n",
        "# Configure logging\n",
        "#logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
        "\n",
        "class MongoDBHandler:\n",
        "    def __init__(self, uri):\n",
        "        try:\n",
        "            self.client = MongoClient(uri)\n",
        "            logging.info(\"MongoDB connection established.\")\n",
        "        except errors.ConnectionFailure:\n",
        "            logging.error(\"Failed to connect to MongoDB.\")\n",
        "            raise\n",
        "\n",
        "    def insert_records(self, db_name, collection_name, records, avoid_duplicates=False):\n",
        "        if not records:  # Validate records is not empty\n",
        "            logging.warning(\"No records provided to insert.\")\n",
        "            return\n",
        "        db = self.client[db_name]\n",
        "        collection = db[collection_name]\n",
        "        try:\n",
        "            if avoid_duplicates:\n",
        "                inserted_count = 0\n",
        "                for record in records:\n",
        "                    if collection.count_documents({\"unique_identifier\": record.get(\"unique_identifier\")}, limit=1) == 0:\n",
        "                        collection.insert_one(record)\n",
        "                        inserted_count += 1\n",
        "                logging.info(f\"{inserted_count} records inserted successfully into MongoDB.\")\n",
        "            else:\n",
        "                result = collection.insert_many(records)\n",
        "                logging.info(f\"{len(result.inserted_ids)} records inserted successfully into MongoDB.\")\n",
        "        except Exception as e:\n",
        "            logging.error(f\"Failed to insert records: {e}\")\n",
        "\n",
        "    def count_records(self, db_name, collection_name):\n",
        "        db = self.client[db_name]\n",
        "        collection = db[collection_name]\n",
        "        try:\n",
        "            count = collection.count_documents({})\n",
        "            return count\n",
        "        except Exception as e:\n",
        "            logging.error(f\"Error counting records: {e}\")\n",
        "            return None\n",
        "\n",
        "    def get_last_upload_timestamp(self, db_name, collection_name):\n",
        "        db = self.client[db_name]\n",
        "        collection = db[collection_name]\n",
        "        try:\n",
        "            last_record = collection.find_one(sort=[('_id', -1)])\n",
        "            if last_record:\n",
        "                return last_record.get(\"Accepted Date\")\n",
        "            return None\n",
        "        except Exception as e:\n",
        "            logging.error(f\"Error retrieving last upload timestamp: {e}\")\n",
        "            return None\n",
        "\n",
        "    def update_record(self, db_name, collection_name, filter_query, update_query):\n",
        "        db = self.client[db_name]\n",
        "        collection = db[collection_name]\n",
        "        try:\n",
        "            result = collection.update_one(filter_query, {\"$set\": update_query})\n",
        "            if result.modified_count > 0:\n",
        "                logging.info(\"Record updated successfully.\")\n",
        "            else:\n",
        "                logging.warning(\"No records updated.\")\n",
        "        except Exception as e:\n",
        "            logging.error(f\"Failed to update record: {e}\")\n",
        "\n",
        "    def truncate_collection(self, db_name, collection_name):\n",
        "        db = self.client[db_name]\n",
        "        collection = db[collection_name]\n",
        "        try:\n",
        "            collection.delete_many({})\n",
        "            logging.info(\"Collection truncated successfully.\")\n",
        "        except Exception as e:\n",
        "            logging.error(f\"Failed to truncate collection: {e}\")\n",
        "\n",
        "    def read_collection(self, db_name, collection_name):\n",
        "        db = self.client[db_name]\n",
        "        collection = db[collection_name]\n",
        "        try:\n",
        "            return list(collection.find())\n",
        "        except Exception as e:\n",
        "            logging.error(f\"Failed to read collection: {e}\")\n",
        "            return []\n",
        "\n",
        "    def generate_descriptive_statistics(self, db_name, collection_name):\n",
        "        # Implementation depends on the data and required statistics\n",
        "        pass\n",
        "\n",
        "    def drop_duplicates_and_rewrite(self, db_name, collection_name, unique_key):\n",
        "        db = self.client[db_name]\n",
        "        collection = db[collection_name]\n",
        "        try:\n",
        "            data = list(collection.find())\n",
        "            unique_records = {}\n",
        "            for record in data:\n",
        "                key = record.get(unique_key)\n",
        "                if key and key not in unique_records:\n",
        "                    unique_records[key] = record\n",
        "\n",
        "            if unique_records:\n",
        "                collection.delete_many({})\n",
        "                collection.insert_many(list(unique_records.values()))\n",
        "                logging.info(\"Duplicates dropped and table rewritten successfully.\")\n",
        "            else:\n",
        "                logging.warning(\"No unique records found to write.\")\n",
        "        except Exception as e:\n",
        "            logging.error(f\"Failed to drop duplicates and rewrite: {e}\")\n",
        "\n",
        "nltk.download('punkt')\n",
        "\n",
        "def num_tokens_from_string(string: str, encoding_name: str) -> int:\n",
        "    \"\"\"Returns the number of tokens in a text string.\"\"\"\n",
        "    encoding = tiktoken.encoding_for_model(\"gpt-3.5-turbo\")\n",
        "    num_tokens = len(encoding.encode(string))\n",
        "    return num_tokens\n",
        "\n",
        "def get_completion(prompt: str, model: str = \"gpt-3.5-turbo\") -> str:\n",
        "    \"\"\"\n",
        "    Query your LLM model with your prompt.\n",
        "    Parameters:\n",
        "    prompt (str): The text prompt you want the LLM to respond to.\n",
        "    model (str, optional): The model to be used for generating the response. Default is \"gpt-3.5-turbo\".\n",
        "    Returns:\n",
        "    str: The generated text completion from the specified model.\n",
        "    \"\"\"\n",
        "    openai.api_key = \"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\"\n",
        "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
        "\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model= model,\n",
        "        messages=messages,\n",
        "        temperature=0.5\n",
        "    )\n",
        "\n",
        "    return response.choices[0].message[\"content\"]\n",
        "\n",
        "def prompt_selection(task='technical_analysis', input_to_llm='', stock='', resp='', req=''):\n",
        "\n",
        "  class techAnalysis(BaseModel):\n",
        "      current_price_and_range: str = Field(description=\"Current stock price and day's range\")\n",
        "      price_52_week_range: str = Field(description=\"52-week price range of the stock\")\n",
        "      analyst_consensus_and_target: str = Field(description=\"Analyst consensus and price target for the next 12 months\")\n",
        "      key_financial_ratios: str = Field(description=\"Key financial ratios like P/E, P/B, P/S, P/CF\")\n",
        "      earnings_report_summary: str = Field(description=\"Latest earnings report summary and next earnings report date\")\n",
        "      technical_analysis_consensus: str = Field(description=\"Technical analysis consensus\")\n",
        "      recent_news_headlines: str = Field(description=\"Most recent major news headlines related to the stock\")\n",
        "      dividend_information: str = Field(description=\"Dividend information including last dividend amount and yield\")\n",
        "      major_risks: str = Field(description=\"Major risks associated with the stock\")\n",
        "      web_traffic_data: str = Field(description=\"Web traffic and user interest data\")\n",
        "\n",
        "  class StockForecast(BaseModel):\n",
        "      average_price_target: str = Field(description=\"Average price target for the stock over the next 12 months\")\n",
        "      highest_price_target: str = Field(description=\"Highest price target for the stock over the next 12 months\")\n",
        "      lowest_price_target: str = Field(description=\"Lowest price target for the stock over the next 12 months\")\n",
        "      analyst_rating_consensus: str = Field(description=\"Overall analyst rating consensus\")\n",
        "      number_of_analysts: str = Field(description=\"Number of analysts giving ratings\")\n",
        "      buy_ratings: str = Field(description=\"Number of buy ratings\")\n",
        "      hold_ratings: str = Field(description=\"Number of hold ratings\")\n",
        "      sell_ratings: str = Field(description=\"Number of sell ratings\")\n",
        "      next_quarters_earnings_estimate: str = Field(description=\"Next quarter's earnings estimate for the stock\")\n",
        "      sales_forecast: str = Field(description=\"Sales forecast for the next quarter\")\n",
        "      major_news_headlines: str = Field(description=\"Most recent major news headlines related to the stock\")\n",
        "\n",
        "  class StockTechnicalAnalysis(BaseModel):\n",
        "      overall_consensus: str = Field(description=\"Overall consensus based on technical analysis\")\n",
        "      macd_indicator: str = Field(description=\"Moving Averages Convergence Divergence indicator value\")\n",
        "      rsi: str = Field(description=\"Relative Strength Index value\")\n",
        "      williams_r: str = Field(description=\"Williams %R value\")\n",
        "      cci: str = Field(description=\"Commodity Channel Index value\")\n",
        "      roc: str = Field(description=\"Price Rate of Change value\")\n",
        "      pivot_points: dict = Field(description=\"Pivot points including S3, S2, S1, Pivot Point, R1, R2, R3 values\")\n",
        "      moving_averages: dict = Field(description=\"Moving averages including simple and exponential values for different periods\")\n",
        "      implied_action: dict = Field(description=\"Implied actions based on technical indicators\")\n",
        "\n",
        "  class OptionDetail(BaseModel):\n",
        "      strike_price: float = Field(description=\"The price at which the option can be exercised\")\n",
        "      last_price: float = Field(description=\"The last traded price of the option\")\n",
        "      change_percentage: float = Field(description=\"Percentage change in the option's price\")\n",
        "      volume: int = Field(description=\"Trading volume of the option\")\n",
        "      open_interest: int = Field(description=\"Open interest of the option\")\n",
        "      open_interest_change: int = Field(description=\"Change in open interest\")\n",
        "      last_trade_time: str = Field(description=\"Time of the last trade of the option\")\n",
        "\n",
        "  class OptionsChainData(BaseModel):\n",
        "      next_earnings_date: str = Field(..., description=\"Next earnings date for the stock\")\n",
        "      call_options: List[OptionDetail] = Field(..., description=\"List of call options data\")\n",
        "      put_options: List[OptionDetail] = Field(..., description=\"List of put options data\")\n",
        "\n",
        "  class EarningsHistoryEntry(BaseModel):\n",
        "      report_date: str = Field(..., description=\"Date of the earnings report\")\n",
        "      fiscal_quarter: str = Field(..., description=\"Fiscal quarter of the earnings report\")\n",
        "      forecast_eps: float = Field(..., description=\"Forecasted EPS for the quarter\")\n",
        "      actual_eps: float = Field(..., description=\"Actual EPS for the quarter\")\n",
        "      eps_yoy_change: str = Field(..., description=\"Year-over-year change in EPS\")\n",
        "\n",
        "  class EarningsPriceChangeEntry(BaseModel):\n",
        "      report_date: str = Field(..., description=\"Date of the earnings report\")\n",
        "      price_before: float = Field(..., description=\"Stock price one day before the earnings report\")\n",
        "      price_after: float = Field(..., description=\"Stock price one day after the earnings report\")\n",
        "      percentage_change: float = Field(..., description=\"Percentage change in stock price due to the earnings report\")\n",
        "\n",
        "  class EarningsData(BaseModel):\n",
        "      next_earnings_date: str = Field(..., description=\"Next scheduled earnings report date\")\n",
        "      period_ending: str = Field(..., description=\"The period ending for the next earnings report\")\n",
        "      consensus_eps_forecast: float = Field(..., description=\"Consensus EPS forecast for the next earnings report\")\n",
        "      last_year_eps: float = Field(..., description=\"EPS for the same quarter last year\")\n",
        "      analyst_consensus: str = Field(..., description=\"Overall analyst consensus rating\")\n",
        "      earnings_history: List[EarningsHistoryEntry] = Field(..., description=\"Historical earnings data\")\n",
        "      earnings_related_price_changes: List[EarningsPriceChangeEntry] = Field(..., description=\"Earnings-related price changes\")\n",
        "\n",
        "  class InsiderTradingActivity(BaseModel):\n",
        "      date: str = Field(..., description=\"Date of the insider trading activity\")\n",
        "      name: str = Field(..., description=\"Name of the insider\")\n",
        "      position: str = Field(..., description=\"Position of the insider within the company\")\n",
        "      action: str = Field(..., description=\"Type of activity (bought or sold)\")\n",
        "      value: float = Field(..., description=\"Value of the traded shares\")\n",
        "\n",
        "  class HedgeFundTradingActivity(BaseModel):\n",
        "      date: str = Field(..., description=\"Date of the hedge fund trading activity\")\n",
        "      firm: str = Field(..., description=\"Name of the hedge fund\")\n",
        "      action: str = Field(..., description=\"Type of activity (bought or sold)\")\n",
        "      value: float = Field(..., description=\"Value of the traded shares\")\n",
        "\n",
        "  class Shareholder(BaseModel):\n",
        "      name: str = Field(..., description=\"Name of the shareholder\")\n",
        "      shares: float = Field(..., description=\"Number of shares held\")\n",
        "      type: str = Field(..., description=\"Type of shareholder (Institution, Individual, etc.)\")\n",
        "      holding_percentage: float = Field(..., description=\"Percentage of total shares held by the shareholder\")\n",
        "      value: float = Field(..., description=\"Market value of the shares held\")\n",
        "\n",
        "  class StockOwnership(BaseModel):\n",
        "      insiders_percentage: float = Field(..., description=\"Percentage of stocks owned by insiders\")\n",
        "      mutual_funds_percentage: float = Field(..., description=\"Percentage of stocks owned by mutual funds\")\n",
        "      institutional_investors_percentage: float = Field(..., description=\"Percentage of stocks owned by other institutional investors\")\n",
        "      public_companies_individuals_percentage: float = Field(..., description=\"Percentage of stocks owned by public companies and individual investors\")\n",
        "      recent_insider_trading: List[InsiderTradingActivity] = Field(..., description=\"Recent insider trading activities\")\n",
        "      recent_hedge_fund_trading: List[HedgeFundTradingActivity] = Field(..., description=\"Recent hedge fund trading activities\")\n",
        "      top_shareholders: List[Shareholder] = Field(..., description=\"List of top shareholders\")\n",
        "      top_mutual_fund_holders: List[Shareholder] = Field(..., description=\"List of top mutual fund holders\")\n",
        "      top_etf_holders: List[Shareholder] = Field(..., description=\"List of top ETF holders\")\n",
        "\n",
        "  class IncomeStatement(BaseModel):\n",
        "      total_revenue: float = Field(..., description=\"Total revenue of the company\")\n",
        "      gross_profit: float = Field(..., description=\"Gross profit of the company\")\n",
        "      ebit: float = Field(..., description=\"Earnings before interest and taxes (EBIT)\")\n",
        "      ebitda: float = Field(..., description=\"Earnings before interest, taxes, depreciation, and amortization (EBITDA)\")\n",
        "      net_income: float = Field(..., description=\"Net income available to common stockholders\")\n",
        "\n",
        "  class BalanceSheet(BaseModel):\n",
        "      cash_and_equivalents: float = Field(..., description=\"Total cash, cash equivalents and short-term investments\")\n",
        "      total_assets: float = Field(..., description=\"Total assets of the company\")\n",
        "      total_debt: float = Field(..., description=\"Total debt of the company\")\n",
        "      net_debt: float = Field(..., description=\"Net debt of the company\")\n",
        "      total_liabilities: float = Field(..., description=\"Total liabilities of the company\")\n",
        "      stockholders_equity: float = Field(..., description=\"Total stockholders' equity\")\n",
        "\n",
        "  class CashFlow(BaseModel):\n",
        "      free_cash_flow: float = Field(..., description=\"Free cash flow of the company\")\n",
        "      operating_cash_flow: float = Field(..., description=\"Operating cash flow\")\n",
        "      investing_cash_flow: float = Field(..., description=\"Investing cash flow\")\n",
        "      financing_cash_flow: float = Field(..., description=\"Financing cash flow\")\n",
        "\n",
        "  class Financials(BaseModel):\n",
        "      market_cap: float = Field(..., description=\"Market capitalization\")\n",
        "      eps_ttm: float = Field(..., description=\"Earnings per share for the trailing twelve months\")\n",
        "      pe_ratio: float = Field(..., description=\"Price to earnings ratio\")\n",
        "      dividend_yield: float = Field(..., description=\"Dividend yield percentage\")\n",
        "      next_earnings_date: str = Field(..., description=\"Date of the next earnings report\")\n",
        "      income_statement: IncomeStatement = Field(..., description=\"Income statement details\")\n",
        "      balance_sheet: BalanceSheet = Field(..., description=\"Balance sheet details\")\n",
        "      cash_flow: CashFlow = Field(..., description=\"Cash flow details\")\n",
        "\n",
        "  class StockCompetitor(BaseModel):\n",
        "      name: str = Field(..., description=\"Name of the competing company\")\n",
        "      price: float = Field(..., description=\"Current price of the company's stock\")\n",
        "      market_cap: str = Field(..., description=\"Market capitalization of the competing company\")\n",
        "      pe_ratio: float = Field(..., description=\"Price to earnings ratio of the competing company\")\n",
        "      yearly_gain: float = Field(..., description=\"Yearly gain percentage of the company's stock\")\n",
        "      analyst_consensus: str = Field(..., description=\"Overall analyst consensus on the stock (e.g., Buy, Hold, Sell)\")\n",
        "      analyst_price_target: str = Field(..., description=\"Analyst price target for the stock\")\n",
        "      top_analysts_price_target: str = Field(..., description=\"Price target given by top analysts\")\n",
        "      smart_score: int = Field(..., description=\"TipRanks Smart Score of the stock\")\n",
        "\n",
        "  class StockCompetitors(BaseModel):\n",
        "      apple_details: StockCompetitor = Field(..., description=\"Details of stock\")\n",
        "      competitors: List[StockCompetitor] = Field(..., description=\"List of stock competitors\")\n",
        "\n",
        "  if task == 'technical_analysis':\n",
        "    prompt = f\"\"\"\n",
        "    Given the following webpage content from TipRanks about {stock} stock analysis:\n",
        "\n",
        "    \"{input_to_llm}\"\n",
        "\n",
        "    Extract and summarize the following information:\n",
        "\n",
        "    1. Current {stock} stock price and day's range.\n",
        "    2. 52-week price range of {stock} stock.\n",
        "    3. Analyst consensus and price target for {stock} over the next 12 months.\n",
        "    4. Key financial ratios: P/E, P/B, P/S, P/CF.\n",
        "    5. Latest earnings report summary and next earnings report date.\n",
        "    6. Technical analysis consensus (Bullish, Bearish, Neutral).\n",
        "    7. Most recent major news headlines related to {stock}.\n",
        "    8. Dividend information: last dividend amount and yield.\n",
        "    9. Major risks associated with {stock} stock as identified.\n",
        "    10. Web traffic and user interest data if available.\n",
        "\n",
        "    Provide the information in a structured and concise format.\"\"\"\n",
        "    pydantic_object=techAnalysis\n",
        "    return [prompt, pydantic_object]\n",
        "\n",
        "  elif task == \"forecast_data\":\n",
        "    prompt = f\"\"\"\n",
        "    Given the following webpage content from TipRanks about {stock} stock forecast:\n",
        "\n",
        "    \"{input_to_llm}\"\n",
        "\n",
        "    Extract and summarize the following forecast data:\n",
        "\n",
        "    1. The average price target for {stock} over the next 12 months.\n",
        "    2. The highest price target for {stock} over the next 12 months.\n",
        "    3. The lowest price target for {stock} over the next 12 months.\n",
        "    4. The overall analyst rating consensus for {stock}.\n",
        "    5. The total number of analysts giving ratings to {stock}.\n",
        "    6. The number of buy, hold, and sell ratings.\n",
        "    7. The next quarter's earnings estimate for {stock}.\n",
        "    8. The sales forecast for the next quarter for {stock}.\n",
        "    9. The most recent major news headlines related to {stock}.\n",
        "\n",
        "    Provide the information in a structured and concise format.\n",
        "    \"\"\"\n",
        "    pydantic_object = StockForecast\n",
        "    return [prompt, pydantic_object]\n",
        "\n",
        "  elif task == \"ta\":\n",
        "    prompt = f\"\"\"\n",
        "    Given the following webpage content from TipRanks about {stock} technical analysis:\n",
        "\n",
        "    \"{input_to_llm}\"\n",
        "\n",
        "    Extract and summarize the following technical analysis data:\n",
        "\n",
        "    1. Overall technical analysis consensus (e.g., Sell, Neutral, Buy).\n",
        "    2. Values and implied actions for key technical indicators:\n",
        "        - MACD (Moving Average Convergence Divergence)\n",
        "        - RSI (Relative Strength Index)\n",
        "        - Williams %R\n",
        "        - CCI (Commodity Channel Index)\n",
        "        - ROC (Rate of Change)\n",
        "    3. Pivot points including S3, S2, S1, central pivot point, R1, R2, R3.\n",
        "    4. Moving averages for different periods (e.g., 5-day, 20-day, 50-day, etc.) and the associated market signals (Sell or Buy).\n",
        "\n",
        "    Provide the information in a structured and concise format.\n",
        "    \"\"\"\n",
        "    pydantic_object = StockTechnicalAnalysis\n",
        "    return [prompt, pydantic_object]\n",
        "\n",
        "  elif task == \"OptionDetail\":\n",
        "    prompt = f\"\"\"\n",
        "    Given the following content extracted from the TipRanks website about {stock} stock options chain and prices:\n",
        "\n",
        "    \"{input_to_llm}\"\n",
        "\n",
        "    Extract and summarize the options chain data including:\n",
        "\n",
        "    1. Next earnings date for {stock}.\n",
        "    2. Call options data, including strike price, last price, percentage change, volume, open interest, and last trade time for each available strike.\n",
        "    3. Put options data, including strike price, last price, percentage change, volume, open interest, and last trade time for each available strike.\n",
        "\n",
        "    Present the information in a clear and structured format suitable for further analysis.\n",
        "    \"\"\"\n",
        "    pydantic_object = OptionsChainData\n",
        "    return [prompt, pydantic_object]\n",
        "\n",
        "\n",
        "  elif task == 'earnings_analysis':\n",
        "    prompt = f\"\"\"\n",
        "    Given the following webpage content from TipRanks about {stock} earnings dates and reports:\n",
        "\n",
        "    \"{input_to_llm}\"\n",
        "\n",
        "    Extract and summarize the following information:\n",
        "\n",
        "    1. Next scheduled earnings report date for {stock}.\n",
        "    2. Period ending and corresponding fiscal quarter for the next earnings report.\n",
        "    3. Consensus EPS forecast and last year's EPS for the next scheduled earnings.\n",
        "    4. Analyst consensus rating for {stock}.\n",
        "    5. Historical earnings data, including report dates, fiscal quarters, forecasted EPS, actual EPS, and EPS year-over-year change.\n",
        "    6. Stock price changes related to the earnings reports, including the price one day before and after the earnings release, and the percentage change.\n",
        "\n",
        "    Present the information in a clear, structured, and concise format.\"\"\"\n",
        "    pydantic_object = EarningsData\n",
        "    return [prompt, pydantic_object]\n",
        "\n",
        "  elif task == 'ownership':\n",
        "    prompt = f\"\"\"\n",
        "    Given the following webpage content from TipRanks about {stock} stock ownership:\n",
        "\n",
        "    \"{input_to_llm}\"\n",
        "\n",
        "    Extract and summarize the following information:\n",
        "\n",
        "    1. Percentage ownership breakdown of {stock} stock by Insiders, Mutual Funds, Other Institutional Investors, and Public Companies/Individual Investors.\n",
        "    2. Recent insider trading activities including date, name, position, action, and value.\n",
        "    3. Recent hedge fund trading activities including date, firm, action, and value.\n",
        "    4. Details of top shareholders including name, number of shares, type, percentage holding, and value.\n",
        "    5. Details of top mutual fund holders including name, number of shares, percentage holding, and value.\n",
        "    6. Details of top ETF holders including name, number of shares, percentage holding, and value.\n",
        "\n",
        "    Present the information in a clear, structured, and concise format.\"\"\"\n",
        "    pydantic_object = StockOwnership\n",
        "    return [prompt, pydantic_object]\n",
        "\n",
        "  elif task == 'financials':\n",
        "    prompt = f\"\"\"\n",
        "    Given the following webpage content from TipRanks about {stock} financial statements:\n",
        "\n",
        "    \"{input_to_llm}\"\n",
        "\n",
        "    Extract and summarize the following information:\n",
        "\n",
        "    1. Market capitalization, EPS (TTM), P/E ratio, and dividend yield.\n",
        "    2. Next earnings date.\n",
        "    3. Detailed financials including:\n",
        "        a. Income Statement: Total Revenue, Gross Profit, EBIT, EBITDA, and Net Income.\n",
        "        b. Balance Sheet: Cash and Equivalents, Total Assets, Total Debt, Net Debt, Total Liabilities, and Stockholders Equity.\n",
        "        c. Cash Flow: Free Cash Flow, Operating Cash Flow, Investing Cash Flow, and Financing Cash Flow.\n",
        "\n",
        "    Present the information in a clear, structured, and concise format.\"\"\"\n",
        "    pydantic_object = Financials\n",
        "    return [prompt, pydantic_object]\n",
        "\n",
        "  elif task == 'competitors':\n",
        "    prompt = f\"\"\"\n",
        "    Given the following webpage content from TipRanks about {stock} Stock Competitors:\n",
        "\n",
        "    \"{input_to_llm}\"\n",
        "\n",
        "    Extract and summarize the following information:\n",
        "\n",
        "    1. {stock} stock details including price, market cap, P/E ratio, yearly gain, analyst consensus, and Smart Score.\n",
        "    2. Information on similar stocks including name, price, market cap, P/E ratio, yearly gain, analyst consensus, analyst price target, top analysts' price target, and Smart Score.\n",
        "\n",
        "    Present the information in a clear, structured, and concise format.\"\"\"\n",
        "    pydantic_object = StockCompetitors\n",
        "    return [prompt, pydantic_object]\n",
        "\n",
        "\n",
        "def gpt_response(task='', input_to_llm='', stock = '', resp='', req=''):\n",
        "  prompt_and_pyd_obj = prompt_selection(task, input_to_llm, resp, req)\n",
        "  prompt = prompt_and_pyd_obj[0]\n",
        "  pydantic_object = prompt_and_pyd_obj[1]\n",
        "  pydantic_parser = PydanticOutputParser(pydantic_object=pydantic_object)\n",
        "  format_instructions = pydantic_parser.get_format_instructions()\n",
        "  print(format_instructions)\n",
        "  query = prompt\n",
        "  prompt = PromptTemplate(\n",
        "      template=\"Answer the user query.\\n{format_instructions}\\n{query}\\n\",\n",
        "      input_variables=[\"query\"],\n",
        "      partial_variables={\"format_instructions\": pydantic_parser.get_format_instructions()},\n",
        "  )\n",
        "  _input = prompt.format_prompt(query=query)\n",
        "  answer = get_completion(_input.to_string())\n",
        "  return answer\n",
        "\n",
        "def gpt_trigger(input_to_llm, stock, task):\n",
        "  ta = gpt_response(task,\n",
        "                    input_to_llm=input_to_llm,\n",
        "                    stock=stock)\n",
        "  return ta\n",
        "\n",
        "def stock_data(ticker):\n",
        "  ticker = ticker\n",
        "  stock_analysis_data_by_ticker = WebBaseLoader(f\"https://www.tipranks.com/stocks/{ticker}\").load()\n",
        "  analyst_forecast_data_by_ticker = WebBaseLoader(f\"https://www.tipranks.com/stocks/{ticker}/forecast\").load()\n",
        "  ta_data_by_ticker = WebBaseLoader(f\"https://www.tipranks.com/stocks/{ticker}/technical-analysis\").load()\n",
        "  options_data_by_ticker = WebBaseLoader(f\"https://www.tipranks.com/stocks/{ticker}/options-chain\").load()\n",
        "  earnings_data_by_ticker = WebBaseLoader(f\"https://www.tipranks.com/stocks/{ticker}/earnings\").load()\n",
        "  ownership_data_by_ticker = WebBaseLoader(f\"https://www.tipranks.com/stocks/{ticker}/ownership\").load()\n",
        "  financials_data_by_ticker = WebBaseLoader(f\"https://www.tipranks.com/stocks/{ticker}/financials\").load()\n",
        "  similar_stocks_data_by_ticker = WebBaseLoader(f\"https://www.tipranks.com/stocks/{ticker}/similar-stocks\").load()\n",
        "\n",
        "  results = {}\n",
        "\n",
        "  # Web scraping and data extraction for technical analysis\n",
        "  try:\n",
        "      ta_data = ast.literal_eval(gpt_trigger(stock_analysis_data_by_ticker[0].page_content, ticker.upper(), \"technical_analysis\").split(\"```json\\n\")[1].replace(\"```\",\"\"))\n",
        "      results['technical_analysis'] = ta_data\n",
        "  except Exception as e:\n",
        "      print(\"failed\")\n",
        "      results['technical_analysis'] = {'error': str(e)}\n",
        "\n",
        "  # Web scraping and data extraction for technical analysis details\n",
        "  try:\n",
        "      tech_data = ast.literal_eval(gpt_trigger(ta_data_by_ticker[0].page_content, ticker.upper(), \"ta\"))#.split(\"```json\\n\")[1].replace(\"```\",\"\"))\n",
        "      results['technical_analysis_details'] = tech_data\n",
        "  except Exception as e:\n",
        "      print(\"failed\")\n",
        "      results['technical_analysis_details'] = {'error': str(e)}\n",
        "\n",
        "  # Web scraping and data extraction for options chain\n",
        "  try:\n",
        "      options_data = ast.literal_eval(gpt_trigger(options_data_by_ticker[0].page_content, ticker.upper(), \"OptionDetail\"))#.split(\"```json\\n\")[1].replace(\"```\",\"\"))\n",
        "      results['options_chain'] = options_data\n",
        "  except Exception as e:\n",
        "      results['options_chain'] = {'error': str(e)}\n",
        "\n",
        "  # Web scraping and data extraction for earnings analysis\n",
        "  try:\n",
        "      earnings_data = ast.literal_eval(gpt_trigger(earnings_data_by_ticker[0].page_content, ticker.upper(), \"earnings_analysis\"))#.replace(\"```json\\n\",\"\").replace(\"\\n```\",\"\"))\n",
        "      results['earnings_analysis'] = earnings_data\n",
        "  except Exception as e:\n",
        "      results['earnings_analysis'] = {'error': str(e)}\n",
        "\n",
        "  # Web scraping and data extraction for ownership data\n",
        "  try:\n",
        "      ownership_data = json.loads(gpt_trigger(ownership_data_by_ticker[0].page_content, ticker.upper(), \"ownership\"))#.replace(\"```json\\n\",\"\").replace(\"\\n```\",\"\"))\n",
        "      results['ownership_data'] = ownership_data\n",
        "  except Exception as e:\n",
        "      print(\"failed\")\n",
        "      results['ownership_data'] = {'error': str(e)}\n",
        "\n",
        "  # Web scraping and data extraction for financials\n",
        "  try:\n",
        "      financials_data = ast.literal_eval(gpt_trigger(financials_data_by_ticker[0].page_content, ticker.upper(), \"financials\"))#.replace(\"```json\\n\",\"\").replace(\"\\n```\",\"\"))\n",
        "      results['financials'] = financials_data\n",
        "  except Exception as e:\n",
        "      print(\"failed\")\n",
        "      results['financials'] = {'error': str(e)}\n",
        "\n",
        "  # Web scraping and data extraction for similar stocks\n",
        "  try:\n",
        "      similar_stocks_data = ast.literal_eval(gpt_trigger(similar_stocks_data_by_ticker[0].page_content, ticker.upper(), \"competitors\"))#.replace(\"```json\\n\",\"\").replace(\"\\n```\",\"\"))\n",
        "      results['similar_stocks'] = similar_stocks_data\n",
        "  except Exception as e:\n",
        "      print(\"failed\")\n",
        "      results['similar_stocks'] = {'error': str(e)}\n",
        "\n",
        "  return results\n",
        "\n",
        "def google_news_scraper(tickr):\n",
        "    google_news = GNews(language='en', country='US', period='7d')\n",
        "    news = google_news.get_news(tickr)\n",
        "    news_scrapper = pd.DataFrame(news)\n",
        "    news_scrapper.sort_values(by=['published date'], ascending=False, inplace=True)\n",
        "    return news_scrapper\n",
        "\n",
        "def get_news_content(url):\n",
        "    try:\n",
        "        return WebBaseLoader(WebBaseLoader(url).load()[0].page_content.split(\"Google NewsOpening \")[1]).load()[0].page_content\n",
        "    except Exception as e:\n",
        "        print(f\"Error retrieving content: {e}\")\n",
        "        return \"Dummy content\"\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stock = \"mrna\"\n",
        "index=20\n",
        "stock_info = stock_data(stock)\n",
        "stock_news = google_news_scraper(stock)\n",
        "stock_news['content'] = stock_news['url'].apply(get_news_content)\n",
        "stock_news = stock_news[stock_news['content']!='Dummy content']\n",
        "stock_news_content = stock_news['content'].iloc[index]\n",
        "print(stock_info)\n",
        "print(stock_news['content'].iloc[index])"
      ],
      "metadata": {
        "id": "_IsL4eK8tEvZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe24fef7-10ef-4a09-fdb6-660856daee61"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The output should be formatted as a JSON instance that conforms to the JSON schema below.\n",
            "\n",
            "As an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\n",
            "the object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\n",
            "\n",
            "Here is the output schema:\n",
            "```\n",
            "{\"properties\": {\"current_price_and_range\": {\"description\": \"Current stock price and day's range\", \"title\": \"Current Price And Range\", \"type\": \"string\"}, \"price_52_week_range\": {\"description\": \"52-week price range of the stock\", \"title\": \"Price 52 Week Range\", \"type\": \"string\"}, \"analyst_consensus_and_target\": {\"description\": \"Analyst consensus and price target for the next 12 months\", \"title\": \"Analyst Consensus And Target\", \"type\": \"string\"}, \"key_financial_ratios\": {\"description\": \"Key financial ratios like P/E, P/B, P/S, P/CF\", \"title\": \"Key Financial Ratios\", \"type\": \"string\"}, \"earnings_report_summary\": {\"description\": \"Latest earnings report summary and next earnings report date\", \"title\": \"Earnings Report Summary\", \"type\": \"string\"}, \"technical_analysis_consensus\": {\"description\": \"Technical analysis consensus\", \"title\": \"Technical Analysis Consensus\", \"type\": \"string\"}, \"recent_news_headlines\": {\"description\": \"Most recent major news headlines related to the stock\", \"title\": \"Recent News Headlines\", \"type\": \"string\"}, \"dividend_information\": {\"description\": \"Dividend information including last dividend amount and yield\", \"title\": \"Dividend Information\", \"type\": \"string\"}, \"major_risks\": {\"description\": \"Major risks associated with the stock\", \"title\": \"Major Risks\", \"type\": \"string\"}, \"web_traffic_data\": {\"description\": \"Web traffic and user interest data\", \"title\": \"Web Traffic Data\", \"type\": \"string\"}}, \"required\": [\"current_price_and_range\", \"price_52_week_range\", \"analyst_consensus_and_target\", \"key_financial_ratios\", \"earnings_report_summary\", \"technical_analysis_consensus\", \"recent_news_headlines\", \"dividend_information\", \"major_risks\", \"web_traffic_data\"]}\n",
            "```\n",
            "failed\n",
            "The output should be formatted as a JSON instance that conforms to the JSON schema below.\n",
            "\n",
            "As an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\n",
            "the object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\n",
            "\n",
            "Here is the output schema:\n",
            "```\n",
            "{\"properties\": {\"overall_consensus\": {\"description\": \"Overall consensus based on technical analysis\", \"title\": \"Overall Consensus\", \"type\": \"string\"}, \"macd_indicator\": {\"description\": \"Moving Averages Convergence Divergence indicator value\", \"title\": \"Macd Indicator\", \"type\": \"string\"}, \"rsi\": {\"description\": \"Relative Strength Index value\", \"title\": \"Rsi\", \"type\": \"string\"}, \"williams_r\": {\"description\": \"Williams %R value\", \"title\": \"Williams R\", \"type\": \"string\"}, \"cci\": {\"description\": \"Commodity Channel Index value\", \"title\": \"Cci\", \"type\": \"string\"}, \"roc\": {\"description\": \"Price Rate of Change value\", \"title\": \"Roc\", \"type\": \"string\"}, \"pivot_points\": {\"description\": \"Pivot points including S3, S2, S1, Pivot Point, R1, R2, R3 values\", \"title\": \"Pivot Points\", \"type\": \"object\"}, \"moving_averages\": {\"description\": \"Moving averages including simple and exponential values for different periods\", \"title\": \"Moving Averages\", \"type\": \"object\"}, \"implied_action\": {\"description\": \"Implied actions based on technical indicators\", \"title\": \"Implied Action\", \"type\": \"object\"}}, \"required\": [\"overall_consensus\", \"macd_indicator\", \"rsi\", \"williams_r\", \"cci\", \"roc\", \"pivot_points\", \"moving_averages\", \"implied_action\"]}\n",
            "```\n",
            "failed\n",
            "The output should be formatted as a JSON instance that conforms to the JSON schema below.\n",
            "\n",
            "As an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\n",
            "the object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\n",
            "\n",
            "Here is the output schema:\n",
            "```\n",
            "{\"$defs\": {\"OptionDetail\": {\"properties\": {\"strike_price\": {\"description\": \"The price at which the option can be exercised\", \"title\": \"Strike Price\", \"type\": \"number\"}, \"last_price\": {\"description\": \"The last traded price of the option\", \"title\": \"Last Price\", \"type\": \"number\"}, \"change_percentage\": {\"description\": \"Percentage change in the option's price\", \"title\": \"Change Percentage\", \"type\": \"number\"}, \"volume\": {\"description\": \"Trading volume of the option\", \"title\": \"Volume\", \"type\": \"integer\"}, \"open_interest\": {\"description\": \"Open interest of the option\", \"title\": \"Open Interest\", \"type\": \"integer\"}, \"open_interest_change\": {\"description\": \"Change in open interest\", \"title\": \"Open Interest Change\", \"type\": \"integer\"}, \"last_trade_time\": {\"description\": \"Time of the last trade of the option\", \"title\": \"Last Trade Time\", \"type\": \"string\"}}, \"required\": [\"strike_price\", \"last_price\", \"change_percentage\", \"volume\", \"open_interest\", \"open_interest_change\", \"last_trade_time\"], \"title\": \"OptionDetail\", \"type\": \"object\"}}, \"properties\": {\"next_earnings_date\": {\"description\": \"Next earnings date for the stock\", \"title\": \"Next Earnings Date\", \"type\": \"string\"}, \"call_options\": {\"description\": \"List of call options data\", \"items\": {\"$ref\": \"#/$defs/OptionDetail\"}, \"title\": \"Call Options\", \"type\": \"array\"}, \"put_options\": {\"description\": \"List of put options data\", \"items\": {\"$ref\": \"#/$defs/OptionDetail\"}, \"title\": \"Put Options\", \"type\": \"array\"}}, \"required\": [\"next_earnings_date\", \"call_options\", \"put_options\"]}\n",
            "```\n",
            "The output should be formatted as a JSON instance that conforms to the JSON schema below.\n",
            "\n",
            "As an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\n",
            "the object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\n",
            "\n",
            "Here is the output schema:\n",
            "```\n",
            "{\"$defs\": {\"EarningsHistoryEntry\": {\"properties\": {\"report_date\": {\"description\": \"Date of the earnings report\", \"title\": \"Report Date\", \"type\": \"string\"}, \"fiscal_quarter\": {\"description\": \"Fiscal quarter of the earnings report\", \"title\": \"Fiscal Quarter\", \"type\": \"string\"}, \"forecast_eps\": {\"description\": \"Forecasted EPS for the quarter\", \"title\": \"Forecast Eps\", \"type\": \"number\"}, \"actual_eps\": {\"description\": \"Actual EPS for the quarter\", \"title\": \"Actual Eps\", \"type\": \"number\"}, \"eps_yoy_change\": {\"description\": \"Year-over-year change in EPS\", \"title\": \"Eps Yoy Change\", \"type\": \"string\"}}, \"required\": [\"report_date\", \"fiscal_quarter\", \"forecast_eps\", \"actual_eps\", \"eps_yoy_change\"], \"title\": \"EarningsHistoryEntry\", \"type\": \"object\"}, \"EarningsPriceChangeEntry\": {\"properties\": {\"report_date\": {\"description\": \"Date of the earnings report\", \"title\": \"Report Date\", \"type\": \"string\"}, \"price_before\": {\"description\": \"Stock price one day before the earnings report\", \"title\": \"Price Before\", \"type\": \"number\"}, \"price_after\": {\"description\": \"Stock price one day after the earnings report\", \"title\": \"Price After\", \"type\": \"number\"}, \"percentage_change\": {\"description\": \"Percentage change in stock price due to the earnings report\", \"title\": \"Percentage Change\", \"type\": \"number\"}}, \"required\": [\"report_date\", \"price_before\", \"price_after\", \"percentage_change\"], \"title\": \"EarningsPriceChangeEntry\", \"type\": \"object\"}}, \"properties\": {\"next_earnings_date\": {\"description\": \"Next scheduled earnings report date\", \"title\": \"Next Earnings Date\", \"type\": \"string\"}, \"period_ending\": {\"description\": \"The period ending for the next earnings report\", \"title\": \"Period Ending\", \"type\": \"string\"}, \"consensus_eps_forecast\": {\"description\": \"Consensus EPS forecast for the next earnings report\", \"title\": \"Consensus Eps Forecast\", \"type\": \"number\"}, \"last_year_eps\": {\"description\": \"EPS for the same quarter last year\", \"title\": \"Last Year Eps\", \"type\": \"number\"}, \"analyst_consensus\": {\"description\": \"Overall analyst consensus rating\", \"title\": \"Analyst Consensus\", \"type\": \"string\"}, \"earnings_history\": {\"description\": \"Historical earnings data\", \"items\": {\"$ref\": \"#/$defs/EarningsHistoryEntry\"}, \"title\": \"Earnings History\", \"type\": \"array\"}, \"earnings_related_price_changes\": {\"description\": \"Earnings-related price changes\", \"items\": {\"$ref\": \"#/$defs/EarningsPriceChangeEntry\"}, \"title\": \"Earnings Related Price Changes\", \"type\": \"array\"}}, \"required\": [\"next_earnings_date\", \"period_ending\", \"consensus_eps_forecast\", \"last_year_eps\", \"analyst_consensus\", \"earnings_history\", \"earnings_related_price_changes\"]}\n",
            "```\n",
            "The output should be formatted as a JSON instance that conforms to the JSON schema below.\n",
            "\n",
            "As an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\n",
            "the object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\n",
            "\n",
            "Here is the output schema:\n",
            "```\n",
            "{\"$defs\": {\"HedgeFundTradingActivity\": {\"properties\": {\"date\": {\"description\": \"Date of the hedge fund trading activity\", \"title\": \"Date\", \"type\": \"string\"}, \"firm\": {\"description\": \"Name of the hedge fund\", \"title\": \"Firm\", \"type\": \"string\"}, \"action\": {\"description\": \"Type of activity (bought or sold)\", \"title\": \"Action\", \"type\": \"string\"}, \"value\": {\"description\": \"Value of the traded shares\", \"title\": \"Value\", \"type\": \"number\"}}, \"required\": [\"date\", \"firm\", \"action\", \"value\"], \"title\": \"HedgeFundTradingActivity\", \"type\": \"object\"}, \"InsiderTradingActivity\": {\"properties\": {\"date\": {\"description\": \"Date of the insider trading activity\", \"title\": \"Date\", \"type\": \"string\"}, \"name\": {\"description\": \"Name of the insider\", \"title\": \"Name\", \"type\": \"string\"}, \"position\": {\"description\": \"Position of the insider within the company\", \"title\": \"Position\", \"type\": \"string\"}, \"action\": {\"description\": \"Type of activity (bought or sold)\", \"title\": \"Action\", \"type\": \"string\"}, \"value\": {\"description\": \"Value of the traded shares\", \"title\": \"Value\", \"type\": \"number\"}}, \"required\": [\"date\", \"name\", \"position\", \"action\", \"value\"], \"title\": \"InsiderTradingActivity\", \"type\": \"object\"}, \"Shareholder\": {\"properties\": {\"name\": {\"description\": \"Name of the shareholder\", \"title\": \"Name\", \"type\": \"string\"}, \"shares\": {\"description\": \"Number of shares held\", \"title\": \"Shares\", \"type\": \"number\"}, \"type\": {\"description\": \"Type of shareholder (Institution, Individual, etc.)\", \"title\": \"Type\", \"type\": \"string\"}, \"holding_percentage\": {\"description\": \"Percentage of total shares held by the shareholder\", \"title\": \"Holding Percentage\", \"type\": \"number\"}, \"value\": {\"description\": \"Market value of the shares held\", \"title\": \"Value\", \"type\": \"number\"}}, \"required\": [\"name\", \"shares\", \"type\", \"holding_percentage\", \"value\"], \"title\": \"Shareholder\", \"type\": \"object\"}}, \"properties\": {\"insiders_percentage\": {\"description\": \"Percentage of stocks owned by insiders\", \"title\": \"Insiders Percentage\", \"type\": \"number\"}, \"mutual_funds_percentage\": {\"description\": \"Percentage of stocks owned by mutual funds\", \"title\": \"Mutual Funds Percentage\", \"type\": \"number\"}, \"institutional_investors_percentage\": {\"description\": \"Percentage of stocks owned by other institutional investors\", \"title\": \"Institutional Investors Percentage\", \"type\": \"number\"}, \"public_companies_individuals_percentage\": {\"description\": \"Percentage of stocks owned by public companies and individual investors\", \"title\": \"Public Companies Individuals Percentage\", \"type\": \"number\"}, \"recent_insider_trading\": {\"description\": \"Recent insider trading activities\", \"items\": {\"$ref\": \"#/$defs/InsiderTradingActivity\"}, \"title\": \"Recent Insider Trading\", \"type\": \"array\"}, \"recent_hedge_fund_trading\": {\"description\": \"Recent hedge fund trading activities\", \"items\": {\"$ref\": \"#/$defs/HedgeFundTradingActivity\"}, \"title\": \"Recent Hedge Fund Trading\", \"type\": \"array\"}, \"top_shareholders\": {\"description\": \"List of top shareholders\", \"items\": {\"$ref\": \"#/$defs/Shareholder\"}, \"title\": \"Top Shareholders\", \"type\": \"array\"}, \"top_mutual_fund_holders\": {\"description\": \"List of top mutual fund holders\", \"items\": {\"$ref\": \"#/$defs/Shareholder\"}, \"title\": \"Top Mutual Fund Holders\", \"type\": \"array\"}, \"top_etf_holders\": {\"description\": \"List of top ETF holders\", \"items\": {\"$ref\": \"#/$defs/Shareholder\"}, \"title\": \"Top Etf Holders\", \"type\": \"array\"}}, \"required\": [\"insiders_percentage\", \"mutual_funds_percentage\", \"institutional_investors_percentage\", \"public_companies_individuals_percentage\", \"recent_insider_trading\", \"recent_hedge_fund_trading\", \"top_shareholders\", \"top_mutual_fund_holders\", \"top_etf_holders\"]}\n",
            "```\n",
            "failed\n",
            "The output should be formatted as a JSON instance that conforms to the JSON schema below.\n",
            "\n",
            "As an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\n",
            "the object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\n",
            "\n",
            "Here is the output schema:\n",
            "```\n",
            "{\"$defs\": {\"BalanceSheet\": {\"properties\": {\"cash_and_equivalents\": {\"description\": \"Total cash, cash equivalents and short-term investments\", \"title\": \"Cash And Equivalents\", \"type\": \"number\"}, \"total_assets\": {\"description\": \"Total assets of the company\", \"title\": \"Total Assets\", \"type\": \"number\"}, \"total_debt\": {\"description\": \"Total debt of the company\", \"title\": \"Total Debt\", \"type\": \"number\"}, \"net_debt\": {\"description\": \"Net debt of the company\", \"title\": \"Net Debt\", \"type\": \"number\"}, \"total_liabilities\": {\"description\": \"Total liabilities of the company\", \"title\": \"Total Liabilities\", \"type\": \"number\"}, \"stockholders_equity\": {\"description\": \"Total stockholders' equity\", \"title\": \"Stockholders Equity\", \"type\": \"number\"}}, \"required\": [\"cash_and_equivalents\", \"total_assets\", \"total_debt\", \"net_debt\", \"total_liabilities\", \"stockholders_equity\"], \"title\": \"BalanceSheet\", \"type\": \"object\"}, \"CashFlow\": {\"properties\": {\"free_cash_flow\": {\"description\": \"Free cash flow of the company\", \"title\": \"Free Cash Flow\", \"type\": \"number\"}, \"operating_cash_flow\": {\"description\": \"Operating cash flow\", \"title\": \"Operating Cash Flow\", \"type\": \"number\"}, \"investing_cash_flow\": {\"description\": \"Investing cash flow\", \"title\": \"Investing Cash Flow\", \"type\": \"number\"}, \"financing_cash_flow\": {\"description\": \"Financing cash flow\", \"title\": \"Financing Cash Flow\", \"type\": \"number\"}}, \"required\": [\"free_cash_flow\", \"operating_cash_flow\", \"investing_cash_flow\", \"financing_cash_flow\"], \"title\": \"CashFlow\", \"type\": \"object\"}, \"IncomeStatement\": {\"properties\": {\"total_revenue\": {\"description\": \"Total revenue of the company\", \"title\": \"Total Revenue\", \"type\": \"number\"}, \"gross_profit\": {\"description\": \"Gross profit of the company\", \"title\": \"Gross Profit\", \"type\": \"number\"}, \"ebit\": {\"description\": \"Earnings before interest and taxes (EBIT)\", \"title\": \"Ebit\", \"type\": \"number\"}, \"ebitda\": {\"description\": \"Earnings before interest, taxes, depreciation, and amortization (EBITDA)\", \"title\": \"Ebitda\", \"type\": \"number\"}, \"net_income\": {\"description\": \"Net income available to common stockholders\", \"title\": \"Net Income\", \"type\": \"number\"}}, \"required\": [\"total_revenue\", \"gross_profit\", \"ebit\", \"ebitda\", \"net_income\"], \"title\": \"IncomeStatement\", \"type\": \"object\"}}, \"properties\": {\"market_cap\": {\"description\": \"Market capitalization\", \"title\": \"Market Cap\", \"type\": \"number\"}, \"eps_ttm\": {\"description\": \"Earnings per share for the trailing twelve months\", \"title\": \"Eps Ttm\", \"type\": \"number\"}, \"pe_ratio\": {\"description\": \"Price to earnings ratio\", \"title\": \"Pe Ratio\", \"type\": \"number\"}, \"dividend_yield\": {\"description\": \"Dividend yield percentage\", \"title\": \"Dividend Yield\", \"type\": \"number\"}, \"next_earnings_date\": {\"description\": \"Date of the next earnings report\", \"title\": \"Next Earnings Date\", \"type\": \"string\"}, \"income_statement\": {\"allOf\": [{\"$ref\": \"#/$defs/IncomeStatement\"}], \"description\": \"Income statement details\"}, \"balance_sheet\": {\"allOf\": [{\"$ref\": \"#/$defs/BalanceSheet\"}], \"description\": \"Balance sheet details\"}, \"cash_flow\": {\"allOf\": [{\"$ref\": \"#/$defs/CashFlow\"}], \"description\": \"Cash flow details\"}}, \"required\": [\"market_cap\", \"eps_ttm\", \"pe_ratio\", \"dividend_yield\", \"next_earnings_date\", \"income_statement\", \"balance_sheet\", \"cash_flow\"]}\n",
            "```\n",
            "The output should be formatted as a JSON instance that conforms to the JSON schema below.\n",
            "\n",
            "As an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\n",
            "the object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\n",
            "\n",
            "Here is the output schema:\n",
            "```\n",
            "{\"$defs\": {\"StockCompetitor\": {\"properties\": {\"name\": {\"description\": \"Name of the competing company\", \"title\": \"Name\", \"type\": \"string\"}, \"price\": {\"description\": \"Current price of the company's stock\", \"title\": \"Price\", \"type\": \"number\"}, \"market_cap\": {\"description\": \"Market capitalization of the competing company\", \"title\": \"Market Cap\", \"type\": \"string\"}, \"pe_ratio\": {\"description\": \"Price to earnings ratio of the competing company\", \"title\": \"Pe Ratio\", \"type\": \"number\"}, \"yearly_gain\": {\"description\": \"Yearly gain percentage of the company's stock\", \"title\": \"Yearly Gain\", \"type\": \"number\"}, \"analyst_consensus\": {\"description\": \"Overall analyst consensus on the stock (e.g., Buy, Hold, Sell)\", \"title\": \"Analyst Consensus\", \"type\": \"string\"}, \"analyst_price_target\": {\"description\": \"Analyst price target for the stock\", \"title\": \"Analyst Price Target\", \"type\": \"string\"}, \"top_analysts_price_target\": {\"description\": \"Price target given by top analysts\", \"title\": \"Top Analysts Price Target\", \"type\": \"string\"}, \"smart_score\": {\"description\": \"TipRanks Smart Score of the stock\", \"title\": \"Smart Score\", \"type\": \"integer\"}}, \"required\": [\"name\", \"price\", \"market_cap\", \"pe_ratio\", \"yearly_gain\", \"analyst_consensus\", \"analyst_price_target\", \"top_analysts_price_target\", \"smart_score\"], \"title\": \"StockCompetitor\", \"type\": \"object\"}}, \"properties\": {\"apple_details\": {\"allOf\": [{\"$ref\": \"#/$defs/StockCompetitor\"}], \"description\": \"Details of stock\"}, \"competitors\": {\"description\": \"List of stock competitors\", \"items\": {\"$ref\": \"#/$defs/StockCompetitor\"}, \"title\": \"Competitors\", \"type\": \"array\"}}, \"required\": [\"apple_details\", \"competitors\"]}\n",
            "```\n",
            "{'technical_analysis': {'error': 'list index out of range'}, 'technical_analysis_details': {'error': 'invalid syntax (<unknown>, line 1)'}, 'options_chain': {'next_earnings_date': 'May 02, 2024, TBA', 'call_options': [{'strike_price': 98.0, 'last_price': 6.1, 'change_percentage': 67.12, 'volume': 223844, 'open_interest': 410, 'open_interest_change': -41, 'last_trade_time': '03/08, 08:56 PM'}, {'strike_price': 99.0, 'last_price': 5.45, 'change_percentage': 72.47, 'volume': 341669, 'open_interest': 500, 'open_interest_change': 3, 'last_trade_time': '03/08, 08:56 PM'}, {'strike_price': 100.0, 'last_price': 4.7, 'change_percentage': 74.07, 'volume': 1194, 'open_interest': 10086, 'open_interest_change': 650, 'last_trade_time': '03/08, 08:59 PM'}, {'strike_price': 101.0, 'last_price': 4.05, 'change_percentage': 79.2, 'volume': 3534, 'open_interest': 7211, 'open_interest_change': 2, 'last_trade_time': '03/08, 08:59 PM'}, {'strike_price': 102.0, 'last_price': 3.35, 'change_percentage': 76.32, 'volume': 2673, 'open_interest': 2577, 'open_interest_change': 30, 'last_trade_time': '03/08, 08:59 PM'}], 'put_options': [{'strike_price': 98.0, 'last_price': 0.93, 'change_percentage': -56.34, 'volume': 2283, 'open_interest': 1552, 'open_interest_change': 203, 'last_trade_time': '03/08, 08:56 PM'}, {'strike_price': 99.0, 'last_price': 1.17, 'change_percentage': -53.2, 'volume': 3011, 'open_interest': 3716, 'open_interest_change': 0, 'last_trade_time': '03/08, 08:59 PM'}, {'strike_price': 100.0, 'last_price': 1.45, 'change_percentage': -52.46, 'volume': 1028, 'open_interest': 2373, 'open_interest_change': -121, 'last_trade_time': '03/08, 08:59 PM'}, {'strike_price': 101.0, 'last_price': 2.02, 'change_percentage': -41.79, 'volume': 311, 'open_interest': 302, 'open_interest_change': 0, 'last_trade_time': '03/08, 08:46 PM'}, {'strike_price': 102.0, 'last_price': 2.24, 'change_percentage': -45.37, 'volume': 168, 'open_interest': 46, 'open_interest_change': -30, 'last_trade_time': '03/08, 08:57 PM'}]}, 'earnings_analysis': {'error': 'invalid syntax (<unknown>, line 1)'}, 'ownership_data': {'error': 'Expecting value: line 1 column 1 (char 0)'}, 'financials': {'market_cap': 1000000000, 'eps_ttm': 2.5, 'pe_ratio': 20, 'dividend_yield': 2.5, 'next_earnings_date': '2022-05-15', 'income_statement': {'total_revenue': 50000000, 'gross_profit': 20000000, 'ebit': 10000000, 'ebitda': 12000000, 'net_income': 8000000}, 'balance_sheet': {'cash_and_equivalents': 5000000, 'total_assets': 30000000, 'total_debt': 10000000, 'net_debt': 5000000, 'total_liabilities': 15000000, 'stockholders_equity': 15000000}, 'cash_flow': {'free_cash_flow': 6000000, 'operating_cash_flow': 10000000, 'investing_cash_flow': -2000000, 'financing_cash_flow': 1000000}}, 'similar_stocks': {'apple_details': {'name': 'Apple Inc.', 'price': 145.86, 'market_cap': '2.43T', 'pe_ratio': 28.05, 'yearly_gain': 12.45, 'analyst_consensus': 'Buy', 'smart_score': 8}, 'competitors': [{'name': 'Microsoft Corporation', 'price': 289.67, 'market_cap': '2.18T', 'pe_ratio': 34.56, 'yearly_gain': 20.32, 'analyst_consensus': 'Strong Buy', 'analyst_price_target': '$310.50', 'top_analysts_price_target': '$320.00', 'smart_score': 9}, {'name': 'Amazon.com Inc.', 'price': 3399.92, 'market_cap': '1.71T', 'pe_ratio': 60.78, 'yearly_gain': 4.78, 'analyst_consensus': 'Buy', 'analyst_price_target': '$3800.00', 'top_analysts_price_target': '$4000.00', 'smart_score': 7}, {'name': 'Alphabet Inc.', 'price': 2737.5, 'market_cap': '1.84T', 'pe_ratio': 30.45, 'yearly_gain': 39.21, 'analyst_consensus': 'Strong Buy', 'analyst_price_target': '$3000.00', 'top_analysts_price_target': '$3200.00', 'smart_score': 9}]}}\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\tLansdowne Partners UK LLP Raises Stock Position in Moderna, Inc. (NASDAQ:MRNA)\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Skip to main content\n",
            "\n",
            "\n",
            "\n",
            "QQQ  437.27  (-0.40%) AAPL  172.42  (+0.99%) MSFT  403.65  (-0.63%) META  486.01  (-3.94%) GOOGL  138.50  (+2.28%) AMZN  172.38  (-1.69%) TSLA  178.68  (+1.90%) NVDA  866.64  (-0.99%) NIO  6.11  (+5.34%) AMD  199.74  (-3.69%) BABA  75.49  (+2.64%) T  17.32  (+0.70%) F  12.18  (+0.00%) MU  94.63  (-3.06%) CGC  3.08  (+0.98%) GE  166.36  (-0.95%) DIS  112.52  (+1.99%) AMC  4.37  (+1.63%) PFE  27.89  (+2.46%) PYPL  59.97  (+1.63%) XOM  108.53  (+0.14%) QQQ  437.27  (-0.40%) AAPL  172.42  (+0.99%) MSFT  403.65  (-0.63%) META  486.01  (-3.94%) GOOGL  138.50  (+2.28%) AMZN  172.38  (-1.69%) TSLA  178.68  (+1.90%) NVDA  866.64  (-0.99%) NIO  6.11  (+5.34%) AMD  199.74  (-3.69%) BABA  75.49  (+2.64%) T  17.32  (+0.70%) F  12.18  (+0.00%) MU  94.63  (-3.06%) CGC  3.08  (+0.98%) GE  166.36  (-0.95%) DIS  112.52  (+1.99%) AMC  4.37  (+1.63%) PFE  27.89  (+2.46%) PYPL  59.97  (+1.63%) XOM  108.53  (+0.14%) QQQ  437.27  (-0.40%) AAPL  172.42  (+0.99%) MSFT  403.65  (-0.63%) META  486.01  (-3.94%) GOOGL  138.50  (+2.28%) AMZN  172.38  (-1.69%) TSLA  178.68  (+1.90%) NVDA  866.64  (-0.99%) NIO  6.11  (+5.34%) AMD  199.74  (-3.69%) BABA  75.49  (+2.64%) T  17.32  (+0.70%) F  12.18  (+0.00%) MU  94.63  (-3.06%) CGC  3.08  (+0.98%) GE  166.36  (-0.95%) DIS  112.52  (+1.99%) AMC  4.37  (+1.63%) PFE  27.89  (+2.46%) PYPL  59.97  (+1.63%) XOM  108.53  (+0.14%) QQQ  437.27  (-0.40%) AAPL  172.42  (+0.99%) MSFT  403.65  (-0.63%) META  486.01  (-3.94%) GOOGL  138.50  (+2.28%) AMZN  172.38  (-1.69%) TSLA  178.68  (+1.90%) NVDA  866.64  (-0.99%) NIO  6.11  (+5.34%) AMD  199.74  (-3.69%) BABA  75.49  (+2.64%) T  17.32  (+0.70%) F  12.18  (+0.00%) MU  94.63  (-3.06%) CGC  3.08  (+0.98%) GE  166.36  (-0.95%) DIS  112.52  (+1.99%) AMC  4.37  (+1.63%) PFE  27.89  (+2.46%) PYPL  59.97  (+1.63%) XOM  108.53  (+0.14%) \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " Free Trial  Log in \n",
            "\n",
            "\n",
            "\n",
            "Search\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " Find now \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Research Tools\n",
            "\n",
            "All Access Tools\n",
            "My MarketBeat\n",
            "\n",
            "My Portfolio\n",
            "My Performance\n",
            "My Insights\n",
            "My Headlines\n",
            "My Calendar\n",
            "My Ratings\n",
            "My Insider Trades\n",
            "My Earnings\n",
            "My SEC Filings\n",
            "My Social\n",
            "My Newsletter\n",
            "My Portfolio Ideas\n",
            "My Account\n",
            "\n",
            "\n",
            "\n",
            "Calculators\n",
            "\n",
            "Dividend Calculator\n",
            "Dividend Yield Calculator\n",
            "Market Cap Calculator\n",
            "Options Profit Calculator\n",
            "Stock Average Calculator\n",
            "Stock Split Calculator\n",
            "Stock Profit Calculator\n",
            "\n",
            "\n",
            "Research Tools\n",
            "\n",
            "Compare Stocks\n",
            "Live News Feed \n",
            "Momentum Alerts \n",
            "Idea Engine \n",
            "Stock Lists\n",
            "Export Data (CSV) \n",
            "\n",
            "\n",
            "\n",
            "Stock Screeners\n",
            "\n",
            "Stock Screener\n",
            "ETF Screener \n",
            "Analyst Ratings Screener \n",
            "Saved Ratings Searches \n",
            "Dividend Screener\n",
            "Earnings Screener \n",
            "Insider Trades Screener \n",
            "\n",
            "\n",
            "Top-Rated Analysts\n",
            "\n",
            "Top-Rated Analysts \n",
            "Top-Rated Brokerages \n",
            "\n",
            "\n",
            "Trending Stocks\n",
            "\n",
            "Trending MarketBeat Stocks \n",
            "Trending Media Mentions \n",
            "High Media Sentiment Stocks \n",
            "Trending WallStreetBets Stocks \n",
            "\n",
            "\n",
            "Premium Reports\n",
            "\n",
            "All Reports \n",
            "7 Election Stocks to Own 7 Magnificent Stocks in 2024 \n",
            "10 Best AI Stocks\n",
            "Best Stocks for 2024 Report \n",
            "Guide To High Short Interest Stocks \n",
            "Elon Musk's Next Move\n",
            "Next 7 Blockbuster Stocks \n",
            "Stock Picks from Top Analysts \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Financial Calendars\n",
            "\n",
            "Calendars and Market Data\n",
            "\n",
            "Analyst Ratings\n",
            "\n",
            "U.S. Ratings\n",
            "U.K. Ratings\n",
            "Canadian Ratings\n",
            "Stock Ratings by Issuer\n",
            "Stock Ratings Screener \n",
            "Top-Rated Stocks \n",
            "Lowest-Rated Stocks \n",
            "Top-Rated Analysts \n",
            "Top-Rated Brokerages \n",
            "Most-Upgraded Stocks \n",
            "Most-Downgraded Stocks \n",
            "Free Ratings Newsletter\n",
            "\n",
            "\n",
            "\n",
            "Congressional Data\n",
            "\n",
            "Recent Trades\n",
            "Most Bought Stocks\n",
            "Most Sold Stocks\n",
            "Members of Congress\n",
            "\n",
            "\n",
            "\n",
            "Corporate Events\n",
            "\n",
            "Corporate Buybacks\n",
            "Economic Reports\n",
            "Initial Public Offerings (IPOs)\n",
            "Secondary Public Offerings\n",
            "IPO Lockup Expirations\n",
            "IPO Quiet Period Expirations\n",
            "SEC Filings\n",
            "13F Filings\n",
            "Top 13F Buys\n",
            "Top 13F Sells\n",
            "Stock Splits\n",
            "\n",
            "\n",
            "\n",
            "Dividends\n",
            "\n",
            "Today's Announcements\n",
            "Ex-Dividend Calendar\n",
            "Dividend Increases\n",
            "Dividend Cuts\n",
            "Dividend Kings\n",
            "Dividend Achievers\n",
            "Dividend Aristocrats\n",
            "Best Dividend Stocks\n",
            "Cheap Dividend Stocks\n",
            "High-Yield Dividend Stocks\n",
            "Monthly Dividend Stocks\n",
            "Dividend Capture Stocks\n",
            "Top-Rated Dividend Stocks \n",
            "Dividend Screener\n",
            "Dividend Investing Guide\n",
            "Free Dividend Newsletter\n",
            "\n",
            "\n",
            "\n",
            "Earnings\n",
            "\n",
            "Today's Announcements\n",
            "Tomorrow's Announcements\n",
            "Next Week's Announcements\n",
            "Upcoming Earnings Calls\n",
            "Earnings Call Transcripts\n",
            "Earnings Beats & Misses\n",
            "Earnings Guidance\n",
            "Earnings News\n",
            "Earnings Screener \n",
            "\n",
            "\n",
            "\n",
            "Insider Trades\n",
            "\n",
            "Today's Insider Trades\n",
            "CEO Purchases/Sales\n",
            "CFO Purchases/Sales\n",
            "Top Insider Buying Stocks \n",
            "Top Insider Selling Stocks \n",
            "Insider Trades Screener \n",
            "Insider Trades Newsletter\n",
            "\n",
            "\n",
            "\n",
            "Market Holidays\n",
            "\n",
            "U.S. Market Holidays\n",
            "Canadian Market Holidays\n",
            "U.K. Market Holidays\n",
            "Australian Market Holidays\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Market Data\n",
            "\n",
            "Market Data and Calendars\n",
            "Commodities\n",
            "Cryptocurrencies\n",
            "\n",
            "All Cryptocurrencies\n",
            "Cryptocurrency Headlines\n",
            "Cryptocurrency Newsletter\n",
            "Crypto Heatmap\n",
            "\n",
            "\n",
            "Currencies\n",
            "Gainers & Decliners\n",
            "\n",
            "Percentage Gainers\n",
            "Percentage Decliners\n",
            "Breakout Stocks\n",
            "Gap Up Stocks\n",
            "Gap Down Stocks\n",
            "\n",
            "\n",
            "High & Low PE\n",
            "\n",
            "High PE Stocks\n",
            "Low PE Stocks\n",
            "High PE Growth Stocks\n",
            "Low PE Growth Stocks\n",
            "\n",
            "\n",
            "Highs & Lows\n",
            "\n",
            "52-Week Highs\n",
            "52-Week Lows\n",
            "\n",
            "\n",
            "High & Low Beta Stocks\n",
            "\n",
            "High Beta Stocks\n",
            "Low Beta Stocks\n",
            "Negative Beta Stocks\n",
            "\n",
            "\n",
            "Indices\n",
            "\n",
            "DOW 30\n",
            "FTSE 100\n",
            "NASDAQ Composite\n",
            "S&P 500\n",
            "S&P TSX\n",
            "\n",
            "\n",
            "Low Priced Stocks\n",
            "\n",
            "Stocks Under $0.50\n",
            "Stocks Under $1\n",
            "Stocks Under $2\n",
            "Stocks Under $5\n",
            "Stocks Under $10\n",
            "Stocks Under $20\n",
            "Stocks Under $30\n",
            "Stocks Under $50\n",
            "Stocks On Sale\n",
            "\n",
            "\n",
            "Most Active\n",
            "\n",
            "Most Active Stocks\n",
            "Most Volatile Stocks\n",
            "Unusual Trading Volume\n",
            "Trading Halts\n",
            "\n",
            "\n",
            "Options\n",
            "\n",
            "Unusual Call Volume\n",
            "Unusual Put Volume\n",
            "\n",
            "\n",
            "Penny Stocks\n",
            "\n",
            "Most Active Penny Stocks\n",
            "Most Popular Penny Stocks\n",
            "Top Penny Stocks Today\n",
            "\n",
            "\n",
            "Sector Performance\n",
            "\n",
            "U.S. Sector Performance\n",
            "Canadian Sector Performance\n",
            "U.K. Sector Performance\n",
            "Cryptocurrency Performance\n",
            "\n",
            "\n",
            "Short Interest\n",
            "\n",
            "Largest Short Positions\n",
            "Short Interest Increases\n",
            "Short Interest Decreases\n",
            "Stocks to Short \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Stock Lists\n",
            "\n",
            "All Stock Lists\n",
            "Stocks by Interest\n",
            "\n",
            "5G Stocks\n",
            "Blue Chip Stocks\n",
            "Biotech Stocks\n",
            "Election Stocks\n",
            "FAANG Stocks\n",
            "Gold Stocks\n",
            "Large Cap Stocks\n",
            "Lumber Stocks\n",
            "Marijuana Stocks\n",
            "Oil Stocks\n",
            "REITs\n",
            "Russell 2000 Stocks\n",
            "Small Cap Stocks\n",
            "SPACs\n",
            "Travel Stocks\n",
            "Water Stocks\n",
            "Warren Buffett Stocks\n",
            "\n",
            "\n",
            "Stocks by Exchange\n",
            "\n",
            "NYSE Stocks\n",
            "NASDAQ Stocks\n",
            "OTCMKTS Stocks\n",
            "TSX Stocks\n",
            "TSXV Stocks\n",
            "LSE Stocks\n",
            "\n",
            "\n",
            "Technical Indicators\n",
            "\n",
            "Death Cross Stocks\n",
            "Golden Cross Stocks\n",
            "RSI Overbought Stocks\n",
            "RSI Oversold Stocks\n",
            "\n",
            "\n",
            "Stocks by Sector\n",
            "\n",
            "Automotive Stocks\n",
            "Aerospace Stocks\n",
            "Basic Materials Stocks\n",
            "Business Services Stocks\n",
            "Consumer Discretionary Stocks\n",
            "Consumer Staples Stocks\n",
            "Construction Stocks\n",
            "Energy Stocks\n",
            "Finance Stocks\n",
            "Industrial Stocks\n",
            "Manufacturing Stocks\n",
            "Medical Stocks\n",
            "Real Estate Stocks\n",
            "Retail Stocks\n",
            "Technology Stocks\n",
            "Transportation Stocks\n",
            "Utilities Stocks\n",
            "\n",
            "\n",
            "Stock Comparisons\n",
            "\n",
            "Airline Stocks\n",
            "Artificial Intelligence Stocks\n",
            "Automotive Stocks\n",
            "Bank Stocks\n",
            "Bitcoin Stocks\n",
            "Defense Stocks\n",
            "EV Charging Stocks\n",
            "Fertilizer Stocks\n",
            "Growth Stocks\n",
            "Lithium Stocks\n",
            "Magnificent Seven Stocks\n",
            "Marijuana Stocks\n",
            "Meme Stocks\n",
            "Pharmaceutical Stocks\n",
            "Toy Stocks\n",
            "WallStreetBets Stocks\n",
            "\n",
            "\n",
            "Premium Stock Lists\n",
            "\n",
            "Top MarketRank Stocks \n",
            "Top ESG Stocks \n",
            "Top-Rated Stocks \n",
            "Top-Rated Dividend Stocks \n",
            "Top-Rated Small-Cap Stocks \n",
            "Top-Rated Tech Stocks \n",
            "Lowest-Rated Stocks \n",
            "Most-Upgraded Stocks \n",
            "Most-Downgraded Stocks \n",
            "Top Insider Buying Stocks \n",
            "Top Insider Selling Stocks \n",
            "Stocks to Short \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Headlines\n",
            "\n",
            "MarketBeat TV3 Stocks That Members of Congress Can't Stop Buying3 Stocks That Members of Congress Can't Stop BuyingAeroVironment Stock Rockets To New HighAeroVironment Stock Rockets To New HighApple Scraps EV Plans: Heres Whats Next, Lower PricesApple Scraps EV Plans: Heres Whats Next, Lower PricesPalantir Stock Spikes on U.S. Army TITAN ContractPalantir Stock Spikes on U.S. Army TITAN ContractFeatured ArticlesUnbearably Good Investment: A Build-A-Bear Stock AnalysisCoinbase Stock Tempting but isnt without its RisksThis Industrial Products Stock is Goldmans Favorite This CycleAnother 20% Upside for Broadcom Stock: Analysts Say Buy the DipTarget Nails the Bullseye on Outsized Earnings BeatFirst Solar Heats Up Rebound In Solar Energy Demand 100% Upside in This Real Estate Stock, Institutions Buying InGoldman Likes This Apparel Stock, Markets Love It Even MoreCommvault Continues its Rally, Outpacing Tech Stocks, MidcapsHeres The One Pet Stock Thats Not in the DoghouseMedtronic is a Dividend Aristocrat That Keeps Gaining More Featured Articles \n",
            "News\n",
            "\n",
            "Premium Articles \n",
            "Real-Time News Feed \n",
            "Economic News\n",
            "Market News\n",
            "Stock News\n",
            "Inflation News\n",
            "Political News\n",
            "Dividends News\n",
            "Earnings News\n",
            "Instant News Alerts\n",
            "All Headlines\n",
            "Investing Slideshows\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Learn\n",
            "\n",
            "\n",
            "\n",
            "Featured Topic: Options Trading\n",
            "\n",
            "Using Options for 1-for-2 Risk/Reward Ratio on UiPath EarningsHow to Use Options Collars to Hedge Your Stock GainsHow to Use Credit Spreads to Make Income from Optionsbluebird bio: How to play LEAPS options for growth and income How to Use Iron Condors to Collect Income from Stock OptionsHow to use options calendar spreads to generate weekly income\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Learn\n",
            "Read investment guides, how-to articles, and explainers.\n",
            "\n",
            "\n",
            "Stock Ideas\n",
            "Looking for ideas for stocks to invest in? These stocks are poised to move.\n",
            "\n",
            "\n",
            "Financial Terms\n",
            "Learn the language of investment with our glossary of over 200 financial terms.\n",
            "\n",
            "\n",
            "Help\n",
            "View our library of help videos to learn how to use the tools on the MarketBeat website.\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Lansdowne Partners UK LLP Raises Stock Position in Moderna, Inc. (NASDAQ:MRNA)\n",
            "\n",
            "\n",
            "\n",
            "Written by MarketBeatMarch 4, 2024 Share  Share \n",
            "\n",
            "Lansdowne Partners UK LLP increased its position in shares of Moderna, Inc. (NASDAQ:MRNA - Free Report) by 63.4% during the third quarter, according to its most recent Form 13F filing with the SEC. The firm owned 58,000 shares of the company's stock after buying an additional 22,500 shares during the period. Moderna comprises about 0.5% of Lansdowne Partners UK LLP's portfolio, making the stock its 15th biggest position. Lansdowne Partners UK LLP's holdings in Moderna were worth $5,991,000 at the end of the most recent reporting period. Get Moderna alerts:Sign UpNovavaxs dispute resolution and upcoming earnings callOther large investors have also recently made changes to their positions in the company. Douglas Lane & Associates LLC increased its stake in shares of Moderna by 36.4% during the third quarter. Douglas Lane & Associates LLC now owns 355,177 shares of the company's stock worth $36,686,000 after buying an additional 94,810 shares during the period. ARK Investment Management LLC increased its stake in shares of Moderna by 81.7% during the third quarter. ARK Investment Management LLC now owns 259,838 shares of the company's stock worth $26,839,000 after buying an additional 116,840 shares during the period. Kentucky Retirement Systems Insurance Trust Fund purchased a new stake in shares of Moderna during the third quarter worth approximately $1,185,000. Invesco Ltd. increased its stake in shares of Moderna by 19.8% during the third quarter. Invesco Ltd. now owns 3,126,028 shares of the company's stock worth $322,887,000 after buying an additional 517,683 shares during the period. Finally, Kranot Hishtalmut Le Morim Tichoniim Havera Menahelet LTD increased its stake in shares of Moderna by 10.5% during the third quarter. Kranot Hishtalmut Le Morim Tichoniim Havera Menahelet LTD now owns 32,188 shares of the company's stock worth $3,252,000 after buying an additional 3,052 shares during the period. 64.51% of the stock is currently owned by hedge funds and other institutional investors. Insider Activity at ModernaIn related news, President Stephen Hoge sold 45,000 shares of the business's stock in a transaction that occurred on Wednesday, December 27th. The stock was sold at an average price of $100.01, for a total transaction of $4,500,450.00. Following the completion of the transaction, the president now owns 1,531,063 shares in the company, valued at approximately $153,121,610.63. The transaction was disclosed in a legal filing with the Securities & Exchange Commission, which is available at the SEC website. In other news, CFO James M. Mock sold 647 shares of the business's stock in a transaction on Thursday, February 29th. The stock was sold at an average price of $94.57, for a total value of $61,186.79. Following the sale, the chief financial officer now owns 4,300 shares of the company's stock, valued at approximately $406,651. The transaction was disclosed in a document filed with the Securities & Exchange Commission, which can be accessed through this link. Also, President Stephen Hoge sold 45,000 shares of the business's stock in a transaction on Wednesday, December 27th. The stock was sold at an average price of $100.01, for a total value of $4,500,450.00. Following the completion of the sale, the president now directly owns 1,531,063 shares in the company, valued at approximately $153,121,610.63. The disclosure for this sale can be found here. Insiders sold 110,604 shares of company stock worth $11,083,220 in the last 90 days. 15.70% of the stock is currently owned by company insiders. Analyst Upgrades and Downgrades3 health care stocks off to strong starts in 2024MRNA has been the subject of a number of research analyst reports. Canaccord Genuity Group upped their price target on Moderna from $82.00 to $91.00 and gave the company a \"hold\" rating in a report on Friday, February 23rd. Canaccord Genuity Group began coverage on Moderna in a report on Wednesday, November 29th. They issued a \"hold\" rating and a $82.00 price objective for the company. JPMorgan Chase & Co. decreased their price target on Moderna from $93.00 to $90.00 and set a \"neutral\" rating for the company in a report on Friday, December 1st. Oppenheimer raised Moderna from a \"market perform\" rating to an \"outperform\" rating and set a $142.00 price target for the company in a report on Tuesday, January 2nd. Finally, Royal Bank of Canada reiterated an \"outperform\" rating and issued a $125.00 price objective on shares of Moderna in a research report on Friday, February 23rd. Two analysts have rated the stock with a sell rating, eight have given a hold rating and five have assigned a buy rating to the company. According to MarketBeat, the company currently has an average rating of \"Hold\" and a consensus target price of $129.82.View Our Latest Research Report on ModernaModerna Stock Down 0.3 %MarketBeat Week in Review  1/1 - 1/5MRNA stock traded down $0.27 during midday trading on Monday, hitting $94.79. 1,956,287 shares of the company's stock were exchanged, compared to its average volume of 4,502,548. Moderna, Inc. has a 12-month low of $62.55 and a 12-month high of $163.24. The company has a current ratio of 3.42, a quick ratio of 3.36 and a debt-to-equity ratio of 0.04. The stock has a market capitalization of $36.22 billion, a price-to-earnings ratio of -7.66 and a beta of 1.60. The firm has a 50 day moving average price of $98.97 and a 200-day moving average price of $94.25. Moderna (NASDAQ:MRNA - Get Free Report) last issued its quarterly earnings results on Thursday, February 22nd. The company reported $0.55 earnings per share for the quarter, beating analysts' consensus estimates of ($0.78) by $1.33. Moderna had a negative return on equity of 10.23% and a negative net margin of 68.84%. The business had revenue of $2.80 billion during the quarter, compared to the consensus estimate of $2.53 billion. During the same period in the previous year, the business earned $3.61 EPS. The business's quarterly revenue was down 44.9% on a year-over-year basis. On average, analysts anticipate that Moderna, Inc. will post -7.17 EPS for the current year. Moderna Profile (Free Report)Moderna, Inc, a biotechnology company, discovers, develops, and commercializes messenger RNA therapeutics and vaccines for the treatment of infectious diseases, immuno-oncology, rare diseases, autoimmune, and cardiovascular diseases in the United States, Europe, and internationally. Its respiratory vaccines include COVID-19, influenza, respiratory syncytial virus, spikevax, and hMPV/PIV3 vaccines; latent vaccines comprise cytomegalovirus, epstein-barr virus, herpes simplex virus, varicella-zoster virus, and human immunodeficiency virus vaccines; and public health vaccines consists of Zika and Nipah vaccines.Featured StoriesFive stocks we like better than ModernaComparing and Trading High PE Ratio StocksJamie Dimon Quits Bitcoin: Bitcoin On Track To Hit $100KP/E Ratio Calculation: How to Assess StocksHow to Short a Stock in 5 Easy Steps3 Ways To Invest In Coffee, Other Than Drinking It5 Under-the-Radar Artificial Intelligence (AI) Stocks Want to see what other hedge funds are holding MRNA? Visit HoldingsChannel.com to get the latest 13F filings and insider trades for Moderna, Inc. (NASDAQ:MRNA - Free Report).This instant news alert was generated by narrative science technology and financial data from MarketBeat in order to provide readers with the fastest and most accurate reporting. This story was reviewed by MarketBeat's editorial team prior to publication. Please send any questions or comments about this story to contact@marketbeat.com. Detecting Cancer in Mere Seconds: Early Investment Opportunity (From Vita Imaging) (Ad)Should you invest $1,000 in Moderna right now?Before you consider Moderna, you'll want to hear this.MarketBeat keeps track of Wall Street's top-rated and best performing research analysts and the stocks they recommend to their clients on a daily basis. MarketBeat has identified the five stocks that top analysts are quietly whispering to their clients to buy now before the broader market catches on... and Moderna wasn't on the list.While Moderna currently has a \"Hold\" rating among analysts, top-rated analysts believe these five stocks are better buys.View The Five Stocks Here 7 Stocks to Own Before the 2024 ElectionLooking to avoid the hassle of mudslinging, volatility, and uncertainty? You'd need to be out of the market, which isnt viable. So where should investors put their money? Find out with this report.Get This Free Report\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Featured Articles and OffersHow to Invest in Artificial Intelligence in These Simple WaysPosted March 7, 2024View How to Invest in Artificial Intelligence in These Simple WaysCan You Invest in ChatGPT Stock? Find Out HerePosted March 7, 2024View Can You Invest in ChatGPT Stock? Find Out HereCathie Wood Likes UiPath Stock Over NVDA, Should You?Posted March 5, 2024View Cathie Wood Likes UiPath Stock Over NVDA, Should You?5 Stocks with Unusually Large Short InterestPosted March 8, 2024View 5 Stocks with Unusually Large Short InterestMorgan Stanley Buys 1,406,491 Shares of Alibaba Group Holding Limited (NYSE:BABA)Posted March 9, 2024View Morgan Stanley Buys 1,406,491 Shares of Alibaba Group Holding Limited (NYSE:BABA)Is it Time To Sell These 5 Overvalued Stocks?Posted March 7, 2024View Is it Time To Sell These 5 Overvalued Stocks?\n",
            "Recent Videos3 Stocks That Members of Congress Can't Stop BuyingAeroVironment Stock Rockets To New HighApple Scraps EV Plans: Heres Whats Next, Lower PricesPalantir Stock Spikes on U.S. Army TITAN Contract\n",
            "\n",
            "Search Headlines:\n",
            "\n",
            "\n",
            "Search Articles\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Get 30 Days of MarketBeat All Access Free\n",
            "Sign up for MarketBeat All Access to gain access to MarketBeat's full suite of research tools:\n",
            "\n",
            "Best-in-Class Portfolio Monitoring\n",
            "View the latest news, buy/sell ratings, SEC filings and insider transactions for your stocks. Compare your portfolio performance to leading indices and get personalized stock ideas based on your portfolio.\n",
            "\n",
            "Stock Ideas and Recommendations\n",
            "Get daily stock ideas from top-performing Wall Street analysts. Get short term trading ideas from the MarketBeat Idea Engine. View which stocks are hot on social media with MarketBeat's trending stocks report.\n",
            "\n",
            "Advanced Stock Screeners and Research Tools\n",
            "Identify stocks that meet your criteria using seven unique stock screeners. See what's happening in the market right now with MarketBeat's real-time news feed. Export data to Excel for your own analysis. \n",
            "\n",
            "\n",
            "Start Your 30-Day Free Trial \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Sign in to your free account to enjoy these benefits\n",
            "\n",
            "In-depth profiles and analysis for 20,000 public companies.\n",
            "Real-time analyst ratings, insider transactions, earnings data, and more.\n",
            "Our daily ratings and market update email newsletter.\n",
            "\n",
            "\n",
            "\n",
            "Sign in to your free account to enjoy all that MarketBeat has to offer.\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Sign In\n",
            "\n",
            "\n",
            "Create Account\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Your Email Address:\n",
            "\n",
            "\n",
            "\n",
            "Your Password:\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "or\n",
            "\n",
            "\n",
            "\n",
            "Sign in with Facebook\n",
            "\n",
            "Sign in with Google\n",
            "\n",
            "Forgot your password?\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Your Email Address:\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Choose a Password:\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Create My Account (Free)\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "or\n",
            "\n",
            "\n",
            "\n",
            "Sign in with Facebook\n",
            "\n",
            "Sign in with Google\n",
            "\n",
            "By creating a free account, you agree to our terms of service. This site is protected by reCAPTCHA and the Google Privacy Policy and Terms of Service apply.\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "As Featured By:\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Empowering Individual Investors\n",
            "\n",
            "345 N Reid Place, Suite 620, Sioux Falls, SD 57103\n",
            "\n",
            "contact@marketbeat.com\n",
            "\n",
            "(844) 978-6257\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Twitter\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Facebook\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "YouTube\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "LinkedIn\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "About MarketBeat\n",
            "\n",
            "About\n",
            "\n",
            "Editorial Guidelines\n",
            "Authors\n",
            "Press Room\n",
            "Careers\n",
            "Contact\n",
            "FAQ\n",
            "Help\n",
            "\n",
            "\n",
            "\n",
            "MarketBeat Products\n",
            "\n",
            "Compare Products\n",
            "MarketBeat All Access\n",
            "Customer Reviews\n",
            "MarketBeat Daily Ratings\n",
            "MarketBeat Daily Canada\n",
            "MarketBeat CryptoBeat\n",
            "MarketBeat Mobile App\n",
            "\n",
            "\n",
            "\n",
            "Popular Tools\n",
            "\n",
            "Stock Lists\n",
            "Compare Stocks\n",
            "Dividend Calculator\n",
            "My MarketBeat\n",
            "Stock Screener\n",
            "\n",
            "\n",
            "\n",
            "Financial Calendars\n",
            "\n",
            "Analyst Ratings\n",
            "Dividends\n",
            "Earnings\n",
            "Insider Trades\n",
            "Stock Market Holidays\n",
            "\n",
            "\n",
            "\n",
            "Terms & Info\n",
            "\n",
            "Advertising\n",
            "Accessibility Statement\n",
            "Do Not Sell My Information\n",
            "Privacy Policy\n",
            "RSS Feeds\n",
            "Terms of Service\n",
            "Sitemap\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            " American Consumer News, LLC dba MarketBeat 2010-2024. All rights reserved.\n",
            "\n",
            " 2024 Market data provided is at least 10-minutes delayed and hosted by Barchart Solutions. Information is provided 'as-is' and solely for informational purposes, not for trading purposes or advice, and is delayed. To see all exchange delays and terms of use please see Barchart's disclaimer. \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "My Account - \n",
            "\n",
            " My MarketBeat\n",
            " My Newsletter\n",
            " My Alerts\n",
            " My Subscriptions\n",
            " My Account Settings\n",
            " My Payment Settings\n",
            " Log Out\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stock_info"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dHNrKMXLhMSs",
        "outputId": "c9c87b17-1bf5-4aff-8be2-3f6486d831ea"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'technical_analysis': {'error': 'list index out of range'},\n",
              " 'technical_analysis_details': {'error': 'invalid syntax (<unknown>, line 1)'},\n",
              " 'options_chain': {'next_earnings_date': 'May 02, 2024, TBA',\n",
              "  'call_options': [{'strike_price': 98.0,\n",
              "    'last_price': 6.1,\n",
              "    'change_percentage': 67.12,\n",
              "    'volume': 223844,\n",
              "    'open_interest': 410,\n",
              "    'open_interest_change': -41,\n",
              "    'last_trade_time': '03/08, 08:56 PM'},\n",
              "   {'strike_price': 99.0,\n",
              "    'last_price': 5.45,\n",
              "    'change_percentage': 72.47,\n",
              "    'volume': 341669,\n",
              "    'open_interest': 500,\n",
              "    'open_interest_change': 3,\n",
              "    'last_trade_time': '03/08, 08:56 PM'},\n",
              "   {'strike_price': 100.0,\n",
              "    'last_price': 4.7,\n",
              "    'change_percentage': 74.07,\n",
              "    'volume': 1194,\n",
              "    'open_interest': 10086,\n",
              "    'open_interest_change': 650,\n",
              "    'last_trade_time': '03/08, 08:59 PM'},\n",
              "   {'strike_price': 101.0,\n",
              "    'last_price': 4.05,\n",
              "    'change_percentage': 79.2,\n",
              "    'volume': 3534,\n",
              "    'open_interest': 7211,\n",
              "    'open_interest_change': 2,\n",
              "    'last_trade_time': '03/08, 08:59 PM'},\n",
              "   {'strike_price': 102.0,\n",
              "    'last_price': 3.35,\n",
              "    'change_percentage': 76.32,\n",
              "    'volume': 2673,\n",
              "    'open_interest': 2577,\n",
              "    'open_interest_change': 30,\n",
              "    'last_trade_time': '03/08, 08:59 PM'}],\n",
              "  'put_options': [{'strike_price': 98.0,\n",
              "    'last_price': 0.93,\n",
              "    'change_percentage': -56.34,\n",
              "    'volume': 2283,\n",
              "    'open_interest': 1552,\n",
              "    'open_interest_change': 203,\n",
              "    'last_trade_time': '03/08, 08:56 PM'},\n",
              "   {'strike_price': 99.0,\n",
              "    'last_price': 1.17,\n",
              "    'change_percentage': -53.2,\n",
              "    'volume': 3011,\n",
              "    'open_interest': 3716,\n",
              "    'open_interest_change': 0,\n",
              "    'last_trade_time': '03/08, 08:59 PM'},\n",
              "   {'strike_price': 100.0,\n",
              "    'last_price': 1.45,\n",
              "    'change_percentage': -52.46,\n",
              "    'volume': 1028,\n",
              "    'open_interest': 2373,\n",
              "    'open_interest_change': -121,\n",
              "    'last_trade_time': '03/08, 08:59 PM'},\n",
              "   {'strike_price': 101.0,\n",
              "    'last_price': 2.02,\n",
              "    'change_percentage': -41.79,\n",
              "    'volume': 311,\n",
              "    'open_interest': 302,\n",
              "    'open_interest_change': 0,\n",
              "    'last_trade_time': '03/08, 08:46 PM'},\n",
              "   {'strike_price': 102.0,\n",
              "    'last_price': 2.24,\n",
              "    'change_percentage': -45.37,\n",
              "    'volume': 168,\n",
              "    'open_interest': 46,\n",
              "    'open_interest_change': -30,\n",
              "    'last_trade_time': '03/08, 08:57 PM'}]},\n",
              " 'earnings_analysis': {'error': 'invalid syntax (<unknown>, line 1)'},\n",
              " 'ownership_data': {'error': 'Expecting value: line 1 column 1 (char 0)'},\n",
              " 'financials': {'market_cap': 1000000000,\n",
              "  'eps_ttm': 2.5,\n",
              "  'pe_ratio': 20,\n",
              "  'dividend_yield': 2.5,\n",
              "  'next_earnings_date': '2022-05-15',\n",
              "  'income_statement': {'total_revenue': 50000000,\n",
              "   'gross_profit': 20000000,\n",
              "   'ebit': 10000000,\n",
              "   'ebitda': 12000000,\n",
              "   'net_income': 8000000},\n",
              "  'balance_sheet': {'cash_and_equivalents': 5000000,\n",
              "   'total_assets': 30000000,\n",
              "   'total_debt': 10000000,\n",
              "   'net_debt': 5000000,\n",
              "   'total_liabilities': 15000000,\n",
              "   'stockholders_equity': 15000000},\n",
              "  'cash_flow': {'free_cash_flow': 6000000,\n",
              "   'operating_cash_flow': 10000000,\n",
              "   'investing_cash_flow': -2000000,\n",
              "   'financing_cash_flow': 1000000}},\n",
              " 'similar_stocks': {'apple_details': {'name': 'Apple Inc.',\n",
              "   'price': 145.86,\n",
              "   'market_cap': '2.43T',\n",
              "   'pe_ratio': 28.05,\n",
              "   'yearly_gain': 12.45,\n",
              "   'analyst_consensus': 'Buy',\n",
              "   'smart_score': 8},\n",
              "  'competitors': [{'name': 'Microsoft Corporation',\n",
              "    'price': 289.67,\n",
              "    'market_cap': '2.18T',\n",
              "    'pe_ratio': 34.56,\n",
              "    'yearly_gain': 20.32,\n",
              "    'analyst_consensus': 'Strong Buy',\n",
              "    'analyst_price_target': '$310.50',\n",
              "    'top_analysts_price_target': '$320.00',\n",
              "    'smart_score': 9},\n",
              "   {'name': 'Amazon.com Inc.',\n",
              "    'price': 3399.92,\n",
              "    'market_cap': '1.71T',\n",
              "    'pe_ratio': 60.78,\n",
              "    'yearly_gain': 4.78,\n",
              "    'analyst_consensus': 'Buy',\n",
              "    'analyst_price_target': '$3800.00',\n",
              "    'top_analysts_price_target': '$4000.00',\n",
              "    'smart_score': 7},\n",
              "   {'name': 'Alphabet Inc.',\n",
              "    'price': 2737.5,\n",
              "    'market_cap': '1.84T',\n",
              "    'pe_ratio': 30.45,\n",
              "    'yearly_gain': 39.21,\n",
              "    'analyst_consensus': 'Strong Buy',\n",
              "    'analyst_price_target': '$3000.00',\n",
              "    'top_analysts_price_target': '$3200.00',\n",
              "    'smart_score': 9}]}}"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up basic configuration for logging\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
        "\n",
        "def reddit_scraper(subreddit_name, search_term):\n",
        "    try:\n",
        "        # Load Reddit credentials from a JSON file\n",
        "        with open('reddit_creds.json', 'r') as f:\n",
        "            client_creds = json.load(f)\n",
        "\n",
        "        # Initialize PRAW with credentials\n",
        "        reddit = praw.Reddit(client_id=client_creds[\"client_id\"],\n",
        "                             client_secret=client_creds['client_secret'],\n",
        "                             user_agent=client_creds['user_agent'],\n",
        "                             ratelimit_seconds=300)\n",
        "\n",
        "        # Fetch posts from subreddit\n",
        "        posts = []\n",
        "        subreddit = reddit.subreddit(subreddit_name).search(search_term, time_filter='month', limit=100)\n",
        "        for post in subreddit:\n",
        "            posts.append([post.title, post.score, post.id, post.subreddit, post.url, post.num_comments, post.selftext, post.created])\n",
        "\n",
        "        if not posts:\n",
        "            logging.warning(\"No posts found for the given search term.\")\n",
        "            return\n",
        "\n",
        "        # Convert list of posts into a DataFrame\n",
        "        posts_df = pd.DataFrame(posts, columns=['title', 'score', 'id', 'subreddit', 'url', 'num_comments', 'body', 'created'])\n",
        "\n",
        "        # Fetch and attach comments to each post\n",
        "        for index, post_id in enumerate(posts_df['id']):\n",
        "            try:\n",
        "                submission = reddit.submission(id=post_id)\n",
        "                submission.comments.replace_more(limit=0)\n",
        "                comments = [comment.body for comment in submission.comments.list()]\n",
        "                posts_df.at[index, 'comments'] = ', '.join(comments)\n",
        "            except Exception as e:\n",
        "                logging.error(f\"Error fetching comments for post {post_id}: {e}\")\n",
        "\n",
        "        # Print the DataFrame or write it to a CSV file\n",
        "        return(posts_df)\n",
        "        # Uncomment the line below to write the result to a CSV file\n",
        "        # posts_df.to_csv(f'top_reddit_posts_with_comments_{subreddit_name}_{search_term}.csv')\n",
        "    except Exception as e:\n",
        "        logging.error(f\"An error occurred: {e}\")\n",
        "\n",
        "# Example usage\n",
        "post_df = reddit_scraper(\"wallstreetbets\", stock)\n",
        "post_df\n"
      ],
      "metadata": {
        "id": "Amhx-uusnOpM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 745
        },
        "outputId": "48b4164a-f07c-488b-d200-812b5543db87"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n",
            "WARNING:praw:It appears that you are using PRAW in an asynchronous environment.\n",
            "It is strongly recommended to use Async PRAW: https://asyncpraw.readthedocs.io.\n",
            "See https://praw.readthedocs.io/en/latest/getting_started/multiple_instances.html#discord-bots-and-asynchronous-environments for more info.\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               title  score       id  \\\n",
              "0  Why is the CEO of MRNA selling a week before e...    244  1ax4f1f   \n",
              "1  Cancer research and breakthroughs in partnersh...      9  1arwqtf   \n",
              "2                                    Thoughts on SQ?     20  1avv45d   \n",
              "3  From $500K and back again TWICE. The adventure...     84  1av3upc   \n",
              "4  Most Anticipated Earnings Releases for the wee...   1026  1arusfa   \n",
              "\n",
              "        subreddit                                                url  \\\n",
              "0  wallstreetbets  https://www.reddit.com/r/wallstreetbets/commen...   \n",
              "1  wallstreetbets  https://www.reddit.com/r/wallstreetbets/commen...   \n",
              "2  wallstreetbets  https://www.reddit.com/r/wallstreetbets/commen...   \n",
              "3  wallstreetbets  https://www.reddit.com/r/wallstreetbets/commen...   \n",
              "4  wallstreetbets               https://i.redd.it/4gwpr2nqbuic1.jpeg   \n",
              "\n",
              "   num_comments                                               body  \\\n",
              "0            55  i think i will short mrna now lol\\n\\nhttps://p...   \n",
              "1             5  One of the most exciting medicines of the past...   \n",
              "2            33  I bought 50 70c weeklies at today's low becaus...   \n",
              "3            45  I have seen much success and wonder in my days...   \n",
              "4          1318                                                      \n",
              "\n",
              "        created                                           comments  \n",
              "0  1.708602e+09  \\n**User Report**| | | |\\n:--|:--|:--|:--\\n**T...  \n",
              "1  1.708048e+09  \\n**User Report**| | | |\\n:--|:--|:--|:--\\n**T...  \n",
              "2  1.708469e+09  \\n**User Report**| | | |\\n:--|:--|:--|:--\\n**T...  \n",
              "3  1.708389e+09  \\n**User Report**| | | |\\n:--|:--|:--|:--\\n**T...  \n",
              "4  1.708043e+09  NVDA earnings will decide the fate of this ral...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b446c4e9-2f5f-454e-9cb2-d3a4e4957ae9\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>score</th>\n",
              "      <th>id</th>\n",
              "      <th>subreddit</th>\n",
              "      <th>url</th>\n",
              "      <th>num_comments</th>\n",
              "      <th>body</th>\n",
              "      <th>created</th>\n",
              "      <th>comments</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Why is the CEO of MRNA selling a week before e...</td>\n",
              "      <td>244</td>\n",
              "      <td>1ax4f1f</td>\n",
              "      <td>wallstreetbets</td>\n",
              "      <td>https://www.reddit.com/r/wallstreetbets/commen...</td>\n",
              "      <td>55</td>\n",
              "      <td>i think i will short mrna now lol\\n\\nhttps://p...</td>\n",
              "      <td>1.708602e+09</td>\n",
              "      <td>\\n**User Report**| | | |\\n:--|:--|:--|:--\\n**T...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Cancer research and breakthroughs in partnersh...</td>\n",
              "      <td>9</td>\n",
              "      <td>1arwqtf</td>\n",
              "      <td>wallstreetbets</td>\n",
              "      <td>https://www.reddit.com/r/wallstreetbets/commen...</td>\n",
              "      <td>5</td>\n",
              "      <td>One of the most exciting medicines of the past...</td>\n",
              "      <td>1.708048e+09</td>\n",
              "      <td>\\n**User Report**| | | |\\n:--|:--|:--|:--\\n**T...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Thoughts on SQ?</td>\n",
              "      <td>20</td>\n",
              "      <td>1avv45d</td>\n",
              "      <td>wallstreetbets</td>\n",
              "      <td>https://www.reddit.com/r/wallstreetbets/commen...</td>\n",
              "      <td>33</td>\n",
              "      <td>I bought 50 70c weeklies at today's low becaus...</td>\n",
              "      <td>1.708469e+09</td>\n",
              "      <td>\\n**User Report**| | | |\\n:--|:--|:--|:--\\n**T...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>From $500K and back again TWICE. The adventure...</td>\n",
              "      <td>84</td>\n",
              "      <td>1av3upc</td>\n",
              "      <td>wallstreetbets</td>\n",
              "      <td>https://www.reddit.com/r/wallstreetbets/commen...</td>\n",
              "      <td>45</td>\n",
              "      <td>I have seen much success and wonder in my days...</td>\n",
              "      <td>1.708389e+09</td>\n",
              "      <td>\\n**User Report**| | | |\\n:--|:--|:--|:--\\n**T...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Most Anticipated Earnings Releases for the wee...</td>\n",
              "      <td>1026</td>\n",
              "      <td>1arusfa</td>\n",
              "      <td>wallstreetbets</td>\n",
              "      <td>https://i.redd.it/4gwpr2nqbuic1.jpeg</td>\n",
              "      <td>1318</td>\n",
              "      <td></td>\n",
              "      <td>1.708043e+09</td>\n",
              "      <td>NVDA earnings will decide the fate of this ral...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b446c4e9-2f5f-454e-9cb2-d3a4e4957ae9')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b446c4e9-2f5f-454e-9cb2-d3a4e4957ae9 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b446c4e9-2f5f-454e-9cb2-d3a4e4957ae9');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-03f24687-0a7e-4e08-86d9-3fb065637bbd\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-03f24687-0a7e-4e08-86d9-3fb065637bbd')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-03f24687-0a7e-4e08-86d9-3fb065637bbd button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_e350dbea-d169-4b80-bcb9-e359aeec9bae\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('post_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_e350dbea-d169-4b80-bcb9-e359aeec9bae button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('post_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "post_df",
              "summary": "{\n  \"name\": \"post_df\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"title\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"Cancer research and breakthroughs in partnership with artificial intelligence. $IDNA\",\n          \"Most Anticipated Earnings Releases for the week beginning February 19th, 2024\",\n          \"Thoughts on SQ?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 429,\n        \"min\": 9,\n        \"max\": 1026,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          9,\n          1026,\n          20\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"1arwqtf\",\n          \"1arusfa\",\n          \"1avv45d\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"subreddit\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"wallstreetbets\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"url\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"https://www.reddit.com/r/wallstreetbets/comments/1arwqtf/cancer_research_and_breakthroughs_in_partnership/\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"num_comments\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 574,\n        \"min\": 5,\n        \"max\": 1318,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          5\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"body\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"One of the most exciting medicines of the past year have been GLP-1 drugs taking the spotlight but i think major breakthroughs and development in the oncology space are coming this year, specifically with genomic and mRNA treatments, and i think AI will accelerate our progress. This is the new space race. But a cure is win for everyone regardless.\\n\\n[https://www.reuters.com/business/healthcare-pharmaceuticals/putin-says-russia-is-close-creating-cancer-vaccines-2024-02-14/](https://www.reuters.com/business/healthcare-pharmaceuticals/putin-says-russia-is-close-creating-cancer-vaccines-2024-02-14/)\\n\\nmRNA and genomic research hold great promise in revolutionizing cancer treatment and potentially offering a cure. One key advantage is in the personalized approach they offer. Researching a persons genetics  enables scientists to understand the genetic makeup of individual tumors, leading to a tailored treatment that targets the specific mutations driving cancer growth. By analyzing the unique genetic signatures of tumors, researchers can identify vulnerabilities and develop mRNA-based therapies that precisely instruct the immune system to recognize and destroy cancer cells.\\n\\nmRNA has demonstrated remarkable versatility and safety in delivering the treatment. Unlike traditional treatments such as chemotherapy and radiation (Nuking the immune system), which can cause severe side effects due to their nonspecific targeting, mRNA vaccines and therapies have shown the ability to selectively target cancer cells while sparing healthy tissues. This targeted approach minimizes adverse effects and enhances the effectiveness of treatment, offering new hope to patients battling various forms of cancer.\\n\\nI think **the true benefit** that humanity will have from AI is disease research. The significant contribution of AI lies in its ability to analyze huge amounts of data efficiently and accurately. In cancer research, AI algorithms can sift through extensive genomic data, medical records, imaging scans, and scientific literature to identify patterns, correlations, and potential treatment options that might otherwise be overlooked by human researchers. What normally would take years can now take days or weeks.\\n\\nMy Favorite ETF in the space is IDNA, you get a basket of very high quality companies in the space so you don't have to pick individual names.\\n\\nThis is going to be so much bigger than GLP-1.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"created\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 253315.54015950148,\n        \"min\": 1708042651.0,\n        \"max\": 1708602020.0,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          1708048227.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"comments\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"\\n**User Report**| | | |\\n:--|:--|:--|:--\\n**Total Submissions**|10|**First Seen In WSB**|1 year ago\\n**Total Comments**|862|**Previous Best DD**|\\n**Account Age**|1 year|[^scan ^comment ](https://www.reddit.com/message/compose/?to=VisualMod&subject=scan_comment&message=Replace%20this%20text%20with%20a%20comment%20ID%20(which%20looks%20like%20h26cq3k\\\\)%20to%20have%20the%20bot%20scan%20your%20comment%20and%20correct%20your%20first%20seen%20date.)|[^scan ^submission ](https://www.reddit.com/message/compose/?to=VisualMod&subject=scan_submission&message=Replace%20this%20text%20with%20a%20submission%20ID%20(which%20looks%20like%20h26cq3k\\\\)%20to%20have%20the%20bot%20scan%20your%20submission%20and%20correct%20your%20first%20seen%20date.)\\n\\n[**Join WSB Discord**](http://discord.gg/wsbverse), It's even got some of the same letters as NVDA!!!, MRNA AI, But but it\\u2019s putin\\u2026\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class StockNewsDetail(BaseModel):\n",
        "    stock_name: str = Field(description=\"Name of the stock or company mentioned in the news.\")\n",
        "    recent_performance: Optional[str] = Field(None, description=\"Recent performance of the stock.\")\n",
        "    key_initiatives: Optional[str] = Field(None, description=\"Key initiatives or projects undertaken by the company.\")\n",
        "    market_trends: Optional[str] = Field(None, description=\"Current market trends affecting the stock.\")\n",
        "    future_outlook: Optional[str] = Field(None, description=\"Future outlook or predictions for the stock.\")\n",
        "    analyst_sentiment: Optional[str] = Field(None, description=\"Analyst sentiment or opinions regarding the stock.\")\n",
        "    news_sentiment: Optional[str] = Field(None, description=\"Overall Sentiment of the news relevant to the stock\")\n",
        "\n",
        "class GeneralStockNews(BaseModel):\n",
        "    publication_date: Optional[str] = Field(None, description=\"Date the article was published.\")\n",
        "    author: Optional[str] = Field(None, description=\"Author of the article.\")\n",
        "    title: Optional[str] = Field(None, description=\"Title of the news article.\")\n",
        "    details: List[StockNewsDetail] = Field(description=\"Details extracted from the news article regarding the specified stock or stocks.\")\n",
        "\n",
        "\n",
        "prompt_template = f\"\"\"\n",
        "# System Instructions:\n",
        "Given the text from a news article, the task is to extract and summarize key information relevant {stock} discussed in the article. The information should be extracted following a structured format based on a predefined Pydantic model. The output should adhere to the fields defined in the model: Name of the stock, Recent performance, Key initiatives, Market trends, Future outlook, and Analyst sentiment.\n",
        "\n",
        "Ensure to capture significant details such as specific figures, percentages, descriptions of projects, current market impacts, predictions, and analyst opinions. The response should be clear, concise, and structured according to the fields of the Pydantic model, ensuring all relevant information from the article is accurately reflected.\n",
        "\n",
        "# User Prompt:\n",
        "Given the following content from a news article about the stock {stock}:\n",
        "\n",
        "{stock_news_content}\n",
        "\n",
        "Extract and summarize the key information relevant to {stock} discussed in the article:\n",
        "\n",
        "1. Name of the stock or company.\n",
        "2. Recent performance of the stock, including any specific figures or percentages.\n",
        "3. Description of any key initiatives or projects undertaken by the company.\n",
        "4. Mention of current market trends and how they are affecting the stock or company.\n",
        "5. Predictions or future outlook provided for the stock.\n",
        "6. Analyst sentiment or general opinions regarding the stock's future performance.\n",
        "\n",
        "# Return Format:\n",
        "The output should be organized following the structure of the Pydantic models 'StockNewsDetail' and 'GeneralStockNews'. This entails providing the structured information under respective fields like 'stock_name', 'recent_performance', 'key_initiatives', 'market_trends', 'future_outlook', and 'analyst_sentiment' for the 'StockNewsDetail' model; and 'publication_date', 'author', 'title', and 'details' for the 'GeneralStockNews' model.\n",
        "\n",
        "Ensure the information is clearly separated and adequately formatted to match the descriptions and types specified in the Pydantic model fields.\n",
        "\n",
        "\"\"\"\n",
        "pydantic_object = GeneralStockNews\n",
        "\n",
        "pydantic_parser = PydanticOutputParser(pydantic_object=pydantic_object)\n",
        "format_instructions = pydantic_parser.get_format_instructions()\n",
        "query = prompt_template\n",
        "prompt = PromptTemplate(\n",
        "    template=\"Answer the user query.\\n{format_instructions}\\n{query}\\n\",\n",
        "    input_variables=[\"query\"],\n",
        "    partial_variables={\"format_instructions\": pydantic_parser.get_format_instructions()},\n",
        ")\n",
        "_input = prompt.format_prompt(query=query)\n",
        "answer = get_completion(_input.to_string())\n",
        "answer"
      ],
      "metadata": {
        "id": "n2rHjxhrtin4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "outputId": "97d7fcab-9ae9-4287-cd74-f2be6023bd93"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'{\\n    \"publication_date\": null,\\n    \"author\": null,\\n    \"title\": null,\\n    \"details\": [\\n        {\\n            \"stock_name\": \"Moderna, Inc. (NASDAQ:MRNA)\",\\n            \"recent_performance\": \"Increased position by 63.4% during the third quarter.\",\\n            \"key_initiatives\": null,\\n            \"market_trends\": null,\\n            \"future_outlook\": null,\\n            \"analyst_sentiment\": null\\n        }\\n    ]\\n}'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class BlockCommentInsight(BaseModel):\n",
        "    average_sentiment: str = Field(description=\"The average sentiment of the comments block (positive, negative, neutral).\")\n",
        "    average_sentiment_score: float = Field(description=\"A numeric score representing the average strength of the sentiment across comments.\")\n",
        "    common_themes: List[str] = Field(description=\"Common themes or topics identified across the comments.\")\n",
        "    sentiment_distribution: Dict[str, int] = Field(description=\"A distribution of sentiment types within the block of comments.\")\n",
        "    common_recommendations: List[str] = Field(description=\"Common recommendations or warnings derived from the block of comments.\")\n",
        "    common_trending_links: Optional[List[str]] = Field(description=\"List of frequently mentioned links for additional information or context.\")\n",
        "    common_highlighted_quotes: Optional[List[str]] = Field(description=\"Common notable quotes or statements from the block of comments.\")\n",
        "    associated_rumors: Optional[List[str]] = Field(description=\"Common rumors or news items mentioned within the block of comments.\")\n",
        "    market_impact_insights: Optional[str] = Field(description=\"Collective insights on potential market impacts derived from the block of comments.\")\n",
        "\n",
        "class RedditStockPost(BaseModel):\n",
        "    sentiment: Optional[str] = Field(description=\"The overall sentiment of the post (bullish, bearish, neutral).\")\n",
        "    key_insights: Optional[str] = Field(description=\"Key insights related to share purchases, warnings, or stock performance.\")\n",
        "    rumors_and_news: Optional[str] = Field(description=\"Information on stock rumors and news mentioned in the post.\")\n",
        "    comments_summary: Optional[str] = Field(description=\"Summary of relevant opinions and insights from the comments.\")\n",
        "    block_comments_insights: Optional[List[BlockCommentInsight]] = Field(description=\"Summarized insights from blocks of comments, including average sentiment, key points, common themes, popularity, and potential market impact.\")\n",
        "\n",
        "prompt_template = \"\"\"\n",
        "For the following group of Reddit posts about the stock {}:\n",
        "\n",
        "{}\n",
        "\n",
        "Follow the following instructions to generate insights about the stock {stock} from each of the above reddit posts:\n",
        "\n",
        "Instructions:\n",
        "1. For each of the Reddit post content about the stock {stock}, perform the following analysis. Extract and summarize the information into the structured format shown below. Only include information about the stock {stock} and ensure clarity on investment decisions and market perspectives. Use additional filters as necessary for accurate extraction.\n",
        "2. Ensure the final output is structured according to the format provided. This structure is essential for the output to be directly usable in Python code, particularly with `ast.literal_eval` or `json.loads`.\n",
        "3. After completing the analysis, double-check that the output format matches the structure shown below. Make sure all placeholders (like 'CLASSIFY_AS', 'SUMMARIZE_KEY_INSIGHTS', etc.) are replaced with actual data derived from the analysis. Ensure that strings are quoted, lists and dictionaries are properly formatted, and no trailing commas are left.\n",
        "4. Verify that the final output does not contain any syntax errors and can be easily converted into a dictionary using `ast.literal_eval`. This can be done by copying the final output into a Python environment and attempting to parse it with `ast.literal_eval`. If no errors are raised, the format is correct.\n",
        "\n",
        "1. Sentiment of the post with respect to {stock}: Classify as bullish, bearish, or neutral.\n",
        "2. Key insights for share purchases with respect to {stock}: Summarize any specific recommendations, warnings, or insights.\n",
        "3. Stock rumors and news with respect to {stock}: Identify and summarize any rumors or news that could influence stock prices.\n",
        "4. Summary of comments with respect to {stock}: Extract and condense relevant opinions and insights from the comments.\n",
        "5. Detailed comments insights with respect to {stock}: Provide detailed insights from individual comments, including the commenter's sentiment, key points, upvotes, and any relevant links mentioned. Summarize major themes or discussions emerging from these detailed insights.\n",
        "\n",
        "Ensure the information is structured according to the defined fields, only about the stock {stock}  and provides clarity on investment decisions and market perspectives. Use additional filters as necessary for accurate extraction.\n",
        "\"\"\"\n",
        "\n",
        "pydantic_object = RedditStockPost\n",
        "\n",
        "pydantic_parser = PydanticOutputParser(pydantic_object=pydantic_object)\n",
        "format_instructions = pydantic_parser.get_format_instructions()\n",
        "query = prompt_template\n",
        "prompt = PromptTemplate(\n",
        "    template=\"Answer the user query.\\n{format_instructions}\\n{query}\\n\",\n",
        "    input_variables=[\"query\"],\n",
        "    partial_variables={\"format_instructions\": pydantic_parser.get_format_instructions()},\n",
        ")\n",
        "_input = prompt.format_prompt(query=query)\n",
        "prompt_length = num_tokens_from_string(_input.to_string(), \"gpt-3.5-turbo\")"
      ],
      "metadata": {
        "id": "lV-8XJul1j43"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_splitter = CharacterTextSplitter(\n",
        "    separator=\"\\n\\n\",\n",
        "    chunk_size=1000,\n",
        "    chunk_overlap=200,\n",
        "    length_function=len,\n",
        "    is_separator_regex=False,\n",
        ")\n",
        "\n",
        "reddit_content = \"\"\n",
        "\n",
        "post_df.sort_values(by=['score','created'], ascending=False, inplace=True)\n",
        "post_df.reset_index(drop=True, inplace=True)\n",
        "print(post_df.columns)\n",
        "#post_df = post_df[post_df['score']>500]\n",
        "post_df['content_length'] = post_df.apply(lambda row: num_tokens_from_string((getattr(row, 'body', '') + getattr(row, 'comments', '')), \"gpt-3.5-turbo\"), axis=1)\n",
        "post_df['prompt_length'] = prompt_length\n",
        "post_df['combined_content_length'] =  post_df['content_length'].cumsum()\n",
        "\n",
        "# Initialize chunking variables\n",
        "chunks = []\n",
        "current_chunk = []\n",
        "current_tokens = 0\n",
        "\n",
        "# Iterate through the DataFrame\n",
        "for index, row in post_df.iterrows():\n",
        "    post_tokens = row['content_length']\n",
        "\n",
        "    if post_tokens > 16000:  # Check if a single post exceeds the token limit\n",
        "        print(\"ENTERED\")  # For debugging, remove or replace with logging in production\n",
        "        # Split the content and add each split part as a separate chunk\n",
        "        post_content = row['body'] + row['comments']\n",
        "        split_chunks = text_splitter.create_documents([post_content])\n",
        "        chunks.extend(['\\n\\n'.join(split_chunk) for split_chunk in split_chunks])\n",
        "    else:\n",
        "        # Continue with regular chunk aggregation\n",
        "        if current_tokens + post_tokens < 16000 - prompt_length:\n",
        "            current_chunk.append(row['body'] + row['comments'])\n",
        "            current_tokens += post_tokens\n",
        "        else:\n",
        "            # Add the current chunk to chunks and reset\n",
        "            if current_chunk:\n",
        "                chunks.append(' '.join(current_chunk))\n",
        "            current_chunk = [row['body'] + row['comments']]\n",
        "            current_tokens = post_tokens\n",
        "\n",
        "# Add the last chunk if not empty\n",
        "if current_chunk:\n",
        "    chunks.append(' '.join(current_chunk))\n",
        "\n",
        "insights = []\n",
        "\n",
        "class BlockCommentInsight(BaseModel):\n",
        "    average_sentiment: str = Field(description=\"The average sentiment of the comments block (positive, negative, neutral).\")\n",
        "    average_sentiment_score: float = Field(description=\"A numeric score representing the average strength of the sentiment across comments.\")\n",
        "    common_themes: List[str] = Field(description=\"Common themes or topics identified across the comments.\")\n",
        "    sentiment_distribution: Dict[str, int] = Field(description=\"A distribution of sentiment types within the block of comments.\")\n",
        "    common_recommendations: List[str] = Field(description=\"Common recommendations or warnings derived from the block of comments.\")\n",
        "    common_trending_links: Optional[List[str]] = Field(description=\"List of frequently mentioned links for additional information or context.\")\n",
        "    common_highlighted_quotes: Optional[List[str]] = Field(description=\"Common notable quotes or statements from the block of comments.\")\n",
        "    associated_rumors: Optional[List[str]] = Field(description=\"Common rumors or news items mentioned within the block of comments.\")\n",
        "    market_impact_insights: Optional[str] = Field(description=\"Collective insights on potential market impacts derived from the block of comments.\")\n",
        "\n",
        "class RedditStockPost(BaseModel):\n",
        "    sentiment: Optional[str] = Field(description=\"The overall sentiment of the post (bullish, bearish, neutral).\")\n",
        "    key_insights: Optional[str] = Field(description=\"Key insights related to share purchases, warnings, or stock performance.\")\n",
        "    rumors_and_news: Optional[str] = Field(description=\"Information on stock rumors and news mentioned in the post.\")\n",
        "    comments_summary: Optional[str] = Field(description=\"Summary of relevant opinions and insights from the comments.\")\n",
        "    block_comments_insights: Optional[List[BlockCommentInsight]] = Field(description=\"Summarized insights from blocks of comments, including average sentiment, key points, common themes, popularity, and potential market impact.\")\n",
        "\n",
        "for chunk in chunks:\n",
        "  reddit_content = chunk\n",
        "\n",
        "  prompt_template = f\"\"\"\n",
        "  For the following group of Reddit posts about the stock {stock}:\n",
        "\n",
        "  {reddit_content}\n",
        "\n",
        "  Follow the following instructions to generate insights about the stock {stock} from each of the above reddit posts:\n",
        "\n",
        "  Instructions:\n",
        "  1. For each of the Reddit post content about the stock {stock}, perform the following analysis. Extract and summarize the information into the structured format shown below. Only include information about the stock {stock} and ensure clarity on investment decisions and market perspectives. Use additional filters as necessary for accurate extraction.\n",
        "  2. Ensure the final output is structured according to the format provided. This structure is essential for the output to be directly usable in Python code, particularly with `ast.literal_eval` or `json.loads`.\n",
        "  3. After completing the analysis, double-check that the output format matches the structure shown below. Make sure all placeholders (like 'CLASSIFY_AS', 'SUMMARIZE_KEY_INSIGHTS', etc.) are replaced with actual data derived from the analysis. Ensure that strings are quoted, lists and dictionaries are properly formatted, and no trailing commas are left.\n",
        "  4. Verify that the final output does not contain any syntax errors and can be easily converted into a dictionary using `ast.literal_eval`. This can be done by copying the final output into a Python environment and attempting to parse it with `ast.literal_eval`. If no errors are raised, the format is correct.\n",
        "\n",
        "  1. Sentiment of the post with respect to {stock}: Classify as bullish, bearish, or neutral.\n",
        "  2. Key insights for share purchases with respect to {stock}: Summarize any specific recommendations, warnings, or insights.\n",
        "  3. Stock rumors and news with respect to {stock}: Identify and summarize any rumors or news that could influence stock prices.\n",
        "  4. Summary of comments with respect to {stock}: Extract and condense relevant opinions and insights from the comments.\n",
        "  5. Detailed comments insights with respect to {stock}: Provide detailed insights from individual comments, including the commenter's sentiment, key points, upvotes, and any relevant links mentioned. Summarize major themes or discussions emerging from these detailed insights.\n",
        "\n",
        "  Ensure the information is structured according to the defined fields, only about the stock {stock}  and provides clarity on investment decisions and market perspectives. Use additional filters as necessary for accurate extraction.\n",
        "  \"\"\"\n",
        "\n",
        "  pydantic_object = RedditStockPost\n",
        "\n",
        "  pydantic_parser = PydanticOutputParser(pydantic_object=pydantic_object)\n",
        "  format_instructions = pydantic_parser.get_format_instructions()\n",
        "  query = prompt_template\n",
        "  prompt = PromptTemplate(\n",
        "      template=\"Answer the user query.\\n{format_instructions}\\n{query}\\n\",\n",
        "      input_variables=[\"query\"],\n",
        "      partial_variables={\"format_instructions\": pydantic_parser.get_format_instructions()},\n",
        "  )\n",
        "  _input = prompt.format_prompt(query=query)\n",
        "\n",
        "  answer = get_completion(_input.to_string())\n",
        "\n",
        "  insights.append(answer)\n",
        "\n",
        "insights"
      ],
      "metadata": {
        "id": "DObL00Th0EI6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ebde7b1-8739-4edd-c3c4-b2d535a207df"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['title', 'score', 'id', 'subreddit', 'url', 'num_comments', 'body',\n",
            "       'created', 'comments'],\n",
            "      dtype='object')\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['{\\n    \"sentiment\": \"neutral\",\\n    \"key_insights\": \"The earnings report for MRNA was a surprise profit, beating analyst expectations. Executives have been selling shares in advance, potentially causing concern among investors.\",\\n    \"rumors_and_news\": \"There are no specific rumors or news mentioned in the Reddit posts that could directly influence MRNA stock prices.\",\\n    \"comments_summary\": \"Overall, the sentiment towards MRNA seems mixed, with some discussing the recent earnings report and executive share sales.\",\\n    \"detailed_comments_insights\": [\\n        {\\n            \"sentiment\": \"neutral\",\\n            \"key_points\": \"Discussion about MRNA earnings being a surprise profit\",\\n            \"upvotes\": 15,\\n            \"links\": [],\\n            \"theme\": \"Earnings report\"\\n        },\\n        {\\n            \"sentiment\": \"neutral\",\\n            \"key_points\": \"Concern about executives selling shares in advance\",\\n            \"upvotes\": 10,\\n            \"links\": [],\\n            \"theme\": \"Executive share sales\"\\n        }\\n    ]\\n}',\n",
              " '{\\n    \"sentiment\": \"neutral\",\\n    \"key_insights\": \"The user is seeking advice on how to balance trading for momentum wins without becoming overconfident and losing everything.\",\\n    \"rumors_and_news\": \"No specific rumors or news related to MRNA were mentioned in the Reddit posts.\",\\n    \"comments_summary\": \"The user shared personal experiences of both successful and unsuccessful trades, highlighting the challenges of balancing risk and reward in trading.\",\\n    \"block_comments_insights\": [\\n        {\\n            \"average_sentiment\": \"neutral\",\\n            \"average_sentiment_score\": 0.0,\\n            \"common_themes\": [\\n                \"Balancing risk and reward in trading\",\\n                \"Overconfidence and its impact on trading decisions\",\\n                \"Importance of proper risk management\"\\n            ],\\n            \"sentiment_distribution\": {\\n                \"positive\": 1,\\n                \"negative\": 1,\\n                \"neutral\": 2\\n            },\\n            \"common_recommendations\": [\\n                \"Practice proper bankroll management\",\\n                \"Avoid going all in on every trade\",\\n                \"Focus on consistency rather than high-risk bets\"\\n            ],\\n            \"common_trending_links\": null,\\n            \"common_highlighted_quotes\": null,\\n            \"associated_rumors\": null,\\n            \"market_impact_insights\": null\\n        }\\n    ]\\n}']"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-lKMBTDKfWBL"
      },
      "execution_count": 9,
      "outputs": []
    }
  ]
}