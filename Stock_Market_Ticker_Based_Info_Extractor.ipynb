{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOIhYjdrahWSEfhpRTCYj4B",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shaunck96/AI-Generated-News/blob/main/Stock_Market_Ticker_Based_Info_Extractor.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H8d9AEwhuHpN",
        "outputId": "7497330d-812a-40df-9dee-d70fe48ebf4c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: newspaper3k in /usr/local/lib/python3.10/dist-packages (0.2.8)\n",
            "Requirement already satisfied: beautifulsoup4>=4.4.1 in /usr/local/lib/python3.10/dist-packages (from newspaper3k) (4.11.2)\n",
            "Requirement already satisfied: Pillow>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from newspaper3k) (9.4.0)\n",
            "Requirement already satisfied: PyYAML>=3.11 in /usr/local/lib/python3.10/dist-packages (from newspaper3k) (6.0.1)\n",
            "Requirement already satisfied: cssselect>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from newspaper3k) (1.2.0)\n",
            "Requirement already satisfied: lxml>=3.6.0 in /usr/local/lib/python3.10/dist-packages (from newspaper3k) (4.9.3)\n",
            "Requirement already satisfied: nltk>=3.2.1 in /usr/local/lib/python3.10/dist-packages (from newspaper3k) (3.8.1)\n",
            "Requirement already satisfied: requests>=2.10.0 in /usr/local/lib/python3.10/dist-packages (from newspaper3k) (2.31.0)\n",
            "Requirement already satisfied: feedparser>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from newspaper3k) (6.0.10)\n",
            "Requirement already satisfied: tldextract>=2.0.1 in /usr/local/lib/python3.10/dist-packages (from newspaper3k) (5.1.1)\n",
            "Requirement already satisfied: feedfinder2>=0.0.4 in /usr/local/lib/python3.10/dist-packages (from newspaper3k) (0.0.4)\n",
            "Requirement already satisfied: jieba3k>=0.35.1 in /usr/local/lib/python3.10/dist-packages (from newspaper3k) (0.35.1)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.10/dist-packages (from newspaper3k) (2.8.2)\n",
            "Requirement already satisfied: tinysegmenter==0.3 in /usr/local/lib/python3.10/dist-packages (from newspaper3k) (0.3)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4>=4.4.1->newspaper3k) (2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from feedfinder2>=0.0.4->newspaper3k) (1.16.0)\n",
            "Requirement already satisfied: sgmllib3k in /usr/local/lib/python3.10/dist-packages (from feedparser>=5.2.1->newspaper3k) (1.0.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk>=3.2.1->newspaper3k) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk>=3.2.1->newspaper3k) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk>=3.2.1->newspaper3k) (2023.10.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk>=3.2.1->newspaper3k) (4.66.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.10.0->newspaper3k) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.10.0->newspaper3k) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.10.0->newspaper3k) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.10.0->newspaper3k) (2023.7.22)\n",
            "Requirement already satisfied: requests-file>=1.4 in /usr/local/lib/python3.10/dist-packages (from tldextract>=2.0.1->newspaper3k) (1.5.1)\n",
            "Requirement already satisfied: filelock>=3.0.8 in /usr/local/lib/python3.10/dist-packages (from tldextract>=2.0.1->newspaper3k) (3.13.1)\n",
            "Requirement already satisfied: scrapetube==2.5.1 in /usr/local/lib/python3.10/dist-packages (2.5.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from scrapetube==2.5.1) (2.31.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from scrapetube==2.5.1) (4.8.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->scrapetube==2.5.1) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->scrapetube==2.5.1) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->scrapetube==2.5.1) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->scrapetube==2.5.1) (2023.7.22)\n",
            "Requirement already satisfied: pytube==15.0.0 in /usr/local/lib/python3.10/dist-packages (15.0.0)\n",
            "Requirement already satisfied: huggingsound==0.1.6 in /usr/local/lib/python3.10/dist-packages (0.1.6)\n",
            "Requirement already satisfied: datasets<3.0.0,>=2.6.1 in /usr/local/lib/python3.10/dist-packages (from huggingsound==0.1.6) (2.15.0)\n",
            "Requirement already satisfied: jiwer<3.0.0,>=2.5.1 in /usr/local/lib/python3.10/dist-packages (from huggingsound==0.1.6) (2.6.0)\n",
            "Requirement already satisfied: librosa<0.10.0,>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from huggingsound==0.1.6) (0.9.2)\n",
            "Requirement already satisfied: torch!=1.12.0,<1.13.0,>=1.7 in /usr/local/lib/python3.10/dist-packages (from huggingsound==0.1.6) (1.12.1)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.23.1 in /usr/local/lib/python3.10/dist-packages (from huggingsound==0.1.6) (4.35.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets<3.0.0,>=2.6.1->huggingsound==0.1.6) (1.23.5)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets<3.0.0,>=2.6.1->huggingsound==0.1.6) (9.0.0)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets<3.0.0,>=2.6.1->huggingsound==0.1.6) (0.6)\n",
            "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets<3.0.0,>=2.6.1->huggingsound==0.1.6) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets<3.0.0,>=2.6.1->huggingsound==0.1.6) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets<3.0.0,>=2.6.1->huggingsound==0.1.6) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets<3.0.0,>=2.6.1->huggingsound==0.1.6) (4.66.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets<3.0.0,>=2.6.1->huggingsound==0.1.6) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets<3.0.0,>=2.6.1->huggingsound==0.1.6) (0.70.15)\n",
            "Requirement already satisfied: fsspec[http]<=2023.10.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets<3.0.0,>=2.6.1->huggingsound==0.1.6) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets<3.0.0,>=2.6.1->huggingsound==0.1.6) (3.8.6)\n",
            "Collecting huggingface-hub>=0.18.0 (from datasets<3.0.0,>=2.6.1->huggingsound==0.1.6)\n",
            "  Using cached huggingface_hub-0.19.4-py3-none-any.whl (311 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets<3.0.0,>=2.6.1->huggingsound==0.1.6) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets<3.0.0,>=2.6.1->huggingsound==0.1.6) (6.0.1)\n",
            "Requirement already satisfied: click<9.0.0,>=8.1.3 in /usr/local/lib/python3.10/dist-packages (from jiwer<3.0.0,>=2.5.1->huggingsound==0.1.6) (8.1.7)\n",
            "Requirement already satisfied: rapidfuzz==2.13.7 in /usr/local/lib/python3.10/dist-packages (from jiwer<3.0.0,>=2.5.1->huggingsound==0.1.6) (2.13.7)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.10/dist-packages (from librosa<0.10.0,>=0.9.2->huggingsound==0.1.6) (3.0.1)\n",
            "Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from librosa<0.10.0,>=0.9.2->huggingsound==0.1.6) (1.11.3)\n",
            "Requirement already satisfied: scikit-learn>=0.19.1 in /usr/local/lib/python3.10/dist-packages (from librosa<0.10.0,>=0.9.2->huggingsound==0.1.6) (1.2.2)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.10/dist-packages (from librosa<0.10.0,>=0.9.2->huggingsound==0.1.6) (1.3.2)\n",
            "Requirement already satisfied: decorator>=4.0.10 in /usr/local/lib/python3.10/dist-packages (from librosa<0.10.0,>=0.9.2->huggingsound==0.1.6) (4.4.2)\n",
            "Requirement already satisfied: resampy>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from librosa<0.10.0,>=0.9.2->huggingsound==0.1.6) (0.4.2)\n",
            "Requirement already satisfied: numba>=0.45.1 in /usr/local/lib/python3.10/dist-packages (from librosa<0.10.0,>=0.9.2->huggingsound==0.1.6) (0.58.1)\n",
            "Requirement already satisfied: soundfile>=0.10.2 in /usr/local/lib/python3.10/dist-packages (from librosa<0.10.0,>=0.9.2->huggingsound==0.1.6) (0.12.1)\n",
            "Requirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa<0.10.0,>=0.9.2->huggingsound==0.1.6) (1.8.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,<1.13.0,>=1.7->huggingsound==0.1.6) (4.8.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.23.1->huggingsound==0.1.6) (3.13.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.23.1->huggingsound==0.1.6) (2023.10.3)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.23.1->huggingsound==0.1.6) (0.14.1)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.23.1->huggingsound==0.1.6) (0.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets<3.0.0,>=2.6.1->huggingsound==0.1.6) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets<3.0.0,>=2.6.1->huggingsound==0.1.6) (3.3.2)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets<3.0.0,>=2.6.1->huggingsound==0.1.6) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets<3.0.0,>=2.6.1->huggingsound==0.1.6) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets<3.0.0,>=2.6.1->huggingsound==0.1.6) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets<3.0.0,>=2.6.1->huggingsound==0.1.6) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets<3.0.0,>=2.6.1->huggingsound==0.1.6) (1.3.1)\n",
            "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.45.1->librosa<0.10.0,>=0.9.2->huggingsound==0.1.6) (0.41.1)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.0->librosa<0.10.0,>=0.9.2->huggingsound==0.1.6) (4.0.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets<3.0.0,>=2.6.1->huggingsound==0.1.6) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets<3.0.0,>=2.6.1->huggingsound==0.1.6) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets<3.0.0,>=2.6.1->huggingsound==0.1.6) (2023.7.22)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.19.1->librosa<0.10.0,>=0.9.2->huggingsound==0.1.6) (3.2.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from soundfile>=0.10.2->librosa<0.10.0,>=0.9.2->huggingsound==0.1.6) (1.16.0)\n",
            "INFO: pip is looking at multiple versions of tokenizers to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting tokenizers<0.19,>=0.14 (from transformers<5.0.0,>=4.23.1->huggingsound==0.1.6)\n",
            "  Using cached tokenizers-0.15.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets<3.0.0,>=2.6.1->huggingsound==0.1.6) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets<3.0.0,>=2.6.1->huggingsound==0.1.6) (2023.3.post1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->soundfile>=0.10.2->librosa<0.10.0,>=0.9.2->huggingsound==0.1.6) (2.21)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets<3.0.0,>=2.6.1->huggingsound==0.1.6) (1.16.0)\n",
            "Installing collected packages: huggingface-hub, tokenizers\n",
            "  Attempting uninstall: huggingface-hub\n",
            "    Found existing installation: huggingface-hub 0.17.3\n",
            "    Uninstalling huggingface-hub-0.17.3:\n",
            "      Successfully uninstalled huggingface-hub-0.17.3\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.14.1\n",
            "    Uninstalling tokenizers-0.14.1:\n",
            "      Successfully uninstalled tokenizers-0.14.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "faster-whisper 0.9.0 requires tokenizers<0.15,>=0.13, but you have tokenizers 0.15.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed huggingface-hub-0.19.4 tokenizers-0.15.0\n",
            "Requirement already satisfied: transformers==4.35.2 in /usr/local/lib/python3.10/dist-packages (4.35.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.35.2) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers==4.35.2) (0.19.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.35.2) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.35.2) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.35.2) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.35.2) (2023.10.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.35.2) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers==4.35.2) (0.15.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.35.2) (0.4.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers==4.35.2) (4.66.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers==4.35.2) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers==4.35.2) (4.8.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.35.2) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.35.2) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.35.2) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.35.2) (2023.7.22)\n",
            "Requirement already satisfied: requests==2.31.0 in /usr/local/lib/python3.10/dist-packages (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests==2.31.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests==2.31.0) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests==2.31.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests==2.31.0) (2023.7.22)\n",
            "Requirement already satisfied: tqdm==4.66.1 in /usr/local/lib/python3.10/dist-packages (4.66.1)\n",
            "Requirement already satisfied: openai==0.28 in /usr/local/lib/python3.10/dist-packages (0.28.0)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (4.66.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (3.8.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (2023.7.22)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.3.1)\n",
            "Requirement already satisfied: faster-whisper==0.9.0 in /usr/local/lib/python3.10/dist-packages (0.9.0)\n",
            "Requirement already satisfied: av==10.* in /usr/local/lib/python3.10/dist-packages (from faster-whisper==0.9.0) (10.0.0)\n",
            "Requirement already satisfied: ctranslate2<4,>=3.17 in /usr/local/lib/python3.10/dist-packages (from faster-whisper==0.9.0) (3.22.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.13 in /usr/local/lib/python3.10/dist-packages (from faster-whisper==0.9.0) (0.19.4)\n",
            "Collecting tokenizers<0.15,>=0.13 (from faster-whisper==0.9.0)\n",
            "  Using cached tokenizers-0.14.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\n",
            "Requirement already satisfied: onnxruntime<2,>=1.14 in /usr/local/lib/python3.10/dist-packages (from faster-whisper==0.9.0) (1.16.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from ctranslate2<4,>=3.17->faster-whisper==0.9.0) (67.7.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from ctranslate2<4,>=3.17->faster-whisper==0.9.0) (1.23.5)\n",
            "Requirement already satisfied: pyyaml<7,>=5.3 in /usr/local/lib/python3.10/dist-packages (from ctranslate2<4,>=3.17->faster-whisper==0.9.0) (6.0.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.13->faster-whisper==0.9.0) (3.13.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.13->faster-whisper==0.9.0) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.13->faster-whisper==0.9.0) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.13->faster-whisper==0.9.0) (4.66.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.13->faster-whisper==0.9.0) (4.8.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.13->faster-whisper==0.9.0) (23.2)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.10/dist-packages (from onnxruntime<2,>=1.14->faster-whisper==0.9.0) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime<2,>=1.14->faster-whisper==0.9.0) (23.5.26)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from onnxruntime<2,>=1.14->faster-whisper==0.9.0) (3.20.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime<2,>=1.14->faster-whisper==0.9.0) (1.12)\n",
            "Collecting huggingface-hub>=0.13 (from faster-whisper==0.9.0)\n",
            "  Using cached huggingface_hub-0.17.3-py3-none-any.whl (295 kB)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.10/dist-packages (from coloredlogs->onnxruntime<2,>=1.14->faster-whisper==0.9.0) (10.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.13->faster-whisper==0.9.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.13->faster-whisper==0.9.0) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.13->faster-whisper==0.9.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.13->faster-whisper==0.9.0) (2023.7.22)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime<2,>=1.14->faster-whisper==0.9.0) (1.3.0)\n",
            "Installing collected packages: huggingface-hub, tokenizers\n",
            "  Attempting uninstall: huggingface-hub\n",
            "    Found existing installation: huggingface-hub 0.19.4\n",
            "    Uninstalling huggingface-hub-0.19.4:\n",
            "      Successfully uninstalled huggingface-hub-0.19.4\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.15.0\n",
            "    Uninstalling tokenizers-0.15.0:\n",
            "      Successfully uninstalled tokenizers-0.15.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "datasets 2.15.0 requires huggingface-hub>=0.18.0, but you have huggingface-hub 0.17.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed huggingface-hub-0.17.3 tokenizers-0.14.1\n",
            "Requirement already satisfied: eyed3==0.9.7 in /usr/local/lib/python3.10/dist-packages (0.9.7)\n",
            "Requirement already satisfied: coverage[toml]<6.0.0,>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from eyed3==0.9.7) (5.5)\n",
            "Requirement already satisfied: deprecation<3.0.0,>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from eyed3==0.9.7) (2.1.0)\n",
            "Requirement already satisfied: filetype<2.0.0,>=1.0.7 in /usr/local/lib/python3.10/dist-packages (from eyed3==0.9.7) (1.2.0)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.10/dist-packages (from coverage[toml]<6.0.0,>=5.3.1->eyed3==0.9.7) (0.10.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from deprecation<3.0.0,>=2.1.0->eyed3==0.9.7) (23.2)\n",
            "Requirement already satisfied: tiktoken==0.5.1 in /usr/local/lib/python3.10/dist-packages (0.5.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken==0.5.1) (2023.10.3)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken==0.5.1) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken==0.5.1) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken==0.5.1) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken==0.5.1) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken==0.5.1) (2023.7.22)\n",
            "Requirement already satisfied: langchain==0.0.340 in /usr/local/lib/python3.10/dist-packages (0.0.340)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.340) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.340) (2.0.23)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.340) (3.8.6)\n",
            "Requirement already satisfied: anyio<4.0 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.340) (3.7.1)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.340) (4.0.3)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.340) (0.6.3)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.340) (1.33)\n",
            "Requirement already satisfied: langsmith<0.1.0,>=0.0.63 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.340) (0.0.67)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.340) (1.23.5)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.340) (1.10.13)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.340) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.340) (8.2.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.340) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.340) (3.3.2)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.340) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.340) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.340) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.340) (1.3.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<4.0->langchain==0.0.340) (3.4)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<4.0->langchain==0.0.340) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4.0->langchain==0.0.340) (1.1.3)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain==0.0.340) (3.20.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain==0.0.340) (0.9.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain==0.0.340) (2.4)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain==0.0.340) (4.8.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain==0.0.340) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain==0.0.340) (2023.7.22)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain==0.0.340) (3.0.1)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json<0.7,>=0.5.7->langchain==0.0.340) (23.2)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain==0.0.340) (1.0.0)\n",
            "Requirement already satisfied: youtube-comment-downloader==0.1.70 in /usr/local/lib/python3.10/dist-packages (0.1.70)\n",
            "Requirement already satisfied: dateparser in /usr/local/lib/python3.10/dist-packages (from youtube-comment-downloader==0.1.70) (1.2.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from youtube-comment-downloader==0.1.70) (2.31.0)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from dateparser->youtube-comment-downloader==0.1.70) (2.8.2)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.10/dist-packages (from dateparser->youtube-comment-downloader==0.1.70) (2023.3.post1)\n",
            "Requirement already satisfied: regex!=2019.02.19,!=2021.8.27 in /usr/local/lib/python3.10/dist-packages (from dateparser->youtube-comment-downloader==0.1.70) (2023.10.3)\n",
            "Requirement already satisfied: tzlocal in /usr/local/lib/python3.10/dist-packages (from dateparser->youtube-comment-downloader==0.1.70) (5.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->youtube-comment-downloader==0.1.70) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->youtube-comment-downloader==0.1.70) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->youtube-comment-downloader==0.1.70) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->youtube-comment-downloader==0.1.70) (2023.7.22)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil->dateparser->youtube-comment-downloader==0.1.70) (1.16.0)\n",
            "Requirement already satisfied: guardrails-ai in /usr/local/lib/python3.10/dist-packages (0.2.9)\n",
            "Requirement already satisfied: eliot<2.0.0,>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from guardrails-ai) (1.15.0)\n",
            "Requirement already satisfied: eliot-tree<22.0.0,>=21.0.0 in /usr/local/lib/python3.10/dist-packages (from guardrails-ai) (21.0.0)\n",
            "Requirement already satisfied: griffe<0.37.0,>=0.36.9 in /usr/local/lib/python3.10/dist-packages (from guardrails-ai) (0.36.9)\n",
            "Requirement already satisfied: lxml<5.0.0,>=4.9.3 in /usr/local/lib/python3.10/dist-packages (from guardrails-ai) (4.9.3)\n",
            "Requirement already satisfied: openai<2 in /usr/local/lib/python3.10/dist-packages (from guardrails-ai) (0.28.0)\n",
            "Requirement already satisfied: pydantic<2.5,>=1.10.9 in /usr/local/lib/python3.10/dist-packages (from guardrails-ai) (1.10.13)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from guardrails-ai) (2.8.2)\n",
            "Requirement already satisfied: regex<2024.0.0,>=2023.10.3 in /usr/local/lib/python3.10/dist-packages (from guardrails-ai) (2023.10.3)\n",
            "Requirement already satisfied: rich<14.0.0,>=13.6.0 in /usr/local/lib/python3.10/dist-packages (from guardrails-ai) (13.7.0)\n",
            "Requirement already satisfied: rstr<4.0.0,>=3.2.2 in /usr/local/lib/python3.10/dist-packages (from guardrails-ai) (3.2.2)\n",
            "Requirement already satisfied: tenacity>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from guardrails-ai) (8.2.3)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from guardrails-ai) (0.9.0)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from guardrails-ai) (4.8.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from eliot<2.0.0,>=1.15.0->guardrails-ai) (1.16.0)\n",
            "Requirement already satisfied: zope.interface in /usr/local/lib/python3.10/dist-packages (from eliot<2.0.0,>=1.15.0->guardrails-ai) (6.1)\n",
            "Requirement already satisfied: pyrsistent>=0.11.8 in /usr/local/lib/python3.10/dist-packages (from eliot<2.0.0,>=1.15.0->guardrails-ai) (0.20.0)\n",
            "Requirement already satisfied: boltons>=19.0.1 in /usr/local/lib/python3.10/dist-packages (from eliot<2.0.0,>=1.15.0->guardrails-ai) (23.1.1)\n",
            "Requirement already satisfied: orjson in /usr/local/lib/python3.10/dist-packages (from eliot<2.0.0,>=1.15.0->guardrails-ai) (3.9.10)\n",
            "Requirement already satisfied: jmespath>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from eliot-tree<22.0.0,>=21.0.0->guardrails-ai) (1.0.1)\n",
            "Requirement already satisfied: iso8601>=0.1.10 in /usr/local/lib/python3.10/dist-packages (from eliot-tree<22.0.0,>=21.0.0->guardrails-ai) (2.1.0)\n",
            "Requirement already satisfied: colored>=1.4.2 in /usr/local/lib/python3.10/dist-packages (from eliot-tree<22.0.0,>=21.0.0->guardrails-ai) (2.2.3)\n",
            "Requirement already satisfied: toolz>=0.8.2 in /usr/local/lib/python3.10/dist-packages (from eliot-tree<22.0.0,>=21.0.0->guardrails-ai) (0.12.0)\n",
            "Requirement already satisfied: colorama>=0.4 in /usr/local/lib/python3.10/dist-packages (from griffe<0.37.0,>=0.36.9->guardrails-ai) (0.4.6)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai<2->guardrails-ai) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai<2->guardrails-ai) (4.66.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai<2->guardrails-ai) (3.8.6)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14.0.0,>=13.6.0->guardrails-ai) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14.0.0,>=13.6.0->guardrails-ai) (2.16.1)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.9.0->guardrails-ai) (8.1.7)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14.0.0,>=13.6.0->guardrails-ai) (0.1.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai<2->guardrails-ai) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai<2->guardrails-ai) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai<2->guardrails-ai) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai<2->guardrails-ai) (2023.7.22)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai<2->guardrails-ai) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai<2->guardrails-ai) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai<2->guardrails-ai) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai<2->guardrails-ai) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai<2->guardrails-ai) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai<2->guardrails-ai) (1.3.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from zope.interface->eliot<2.0.0,>=1.15.0->guardrails-ai) (67.7.2)\n",
            "Requirement already satisfied: newsapi-python in /usr/local/lib/python3.10/dist-packages (0.2.7)\n",
            "Requirement already satisfied: requests<3.0.0 in /usr/local/lib/python3.10/dist-packages (from newsapi-python) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0->newsapi-python) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0->newsapi-python) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0->newsapi-python) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0->newsapi-python) (2023.7.22)\n",
            "Requirement already satisfied: yfinance in /usr/local/lib/python3.10/dist-packages (0.2.32)\n",
            "Requirement already satisfied: pandas>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from yfinance) (1.5.3)\n",
            "Requirement already satisfied: numpy>=1.16.5 in /usr/local/lib/python3.10/dist-packages (from yfinance) (1.23.5)\n",
            "Requirement already satisfied: requests>=2.31 in /usr/local/lib/python3.10/dist-packages (from yfinance) (2.31.0)\n",
            "Requirement already satisfied: multitasking>=0.0.7 in /usr/local/lib/python3.10/dist-packages (from yfinance) (0.0.11)\n",
            "Requirement already satisfied: lxml>=4.9.1 in /usr/local/lib/python3.10/dist-packages (from yfinance) (4.9.3)\n",
            "Requirement already satisfied: appdirs>=1.4.4 in /usr/local/lib/python3.10/dist-packages (from yfinance) (1.4.4)\n",
            "Requirement already satisfied: pytz>=2022.5 in /usr/local/lib/python3.10/dist-packages (from yfinance) (2023.3.post1)\n",
            "Requirement already satisfied: frozendict>=2.3.4 in /usr/local/lib/python3.10/dist-packages (from yfinance) (2.3.8)\n",
            "Requirement already satisfied: peewee>=3.16.2 in /usr/local/lib/python3.10/dist-packages (from yfinance) (3.17.0)\n",
            "Requirement already satisfied: beautifulsoup4>=4.11.1 in /usr/local/lib/python3.10/dist-packages (from yfinance) (4.11.2)\n",
            "Requirement already satisfied: html5lib>=1.1 in /usr/local/lib/python3.10/dist-packages (from yfinance) (1.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4>=4.11.1->yfinance) (2.5)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.10/dist-packages (from html5lib>=1.1->yfinance) (1.16.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from html5lib>=1.1->yfinance) (0.5.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.3.0->yfinance) (2.8.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31->yfinance) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31->yfinance) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31->yfinance) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31->yfinance) (2023.7.22)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (0.1.99)\n"
          ]
        }
      ],
      "source": [
        "!pip install newspaper3k\n",
        "!pip install scrapetube==2.5.1\n",
        "!pip install pytube==15.0.0\n",
        "!pip install huggingsound==0.1.6\n",
        "!pip install transformers==4.35.2\n",
        "!pip install requests==2.31.0\n",
        "!pip install tqdm==4.66.1\n",
        "!pip install openai==0.28\n",
        "!pip install faster-whisper==0.9.0\n",
        "!pip install eyed3==0.9.7\n",
        "!pip install tiktoken==0.5.1\n",
        "!pip install langchain==0.0.340\n",
        "!pip install youtube-comment-downloader==0.1.70\n",
        "!pip install guardrails-ai\n",
        "!pip install -q streamlit\n",
        "!pip install newsapi-python\n",
        "!pip install -q sec-api\n",
        "!pip install yfinance --upgrade --no-cache-dir\n",
        "!pip install sentencepiece"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BfL5U_6UB1Ib"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VH4_qtFzCAAz"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import scrapetube\n",
        "from pytube import YouTube\n",
        "import os\n",
        "import librosa\n",
        "import torch\n",
        "from transformers import AutoModelForSpeechSeq2Seq, AutoProcessor, pipeline\n",
        "import os\n",
        "import openai\n",
        "import regex as re\n",
        "import json\n",
        "import requests\n",
        "from tqdm import tqdm\n",
        "from googleapiclient.discovery import build\n",
        "import regex as re\n",
        "from transformers import pipeline\n",
        "from faster_whisper import WhisperModel\n",
        "from transformers import Wav2Vec2Processor, Wav2Vec2ForCTC\n",
        "from faster_whisper import WhisperModel\n",
        "import tiktoken\n",
        "import pandas as pd\n",
        "import re\n",
        "from urllib import parse\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "import torch\n",
        "import ast\n",
        "from langchain.output_parsers import StructuredOutputParser, ResponseSchema\n",
        "from langchain.prompts import PromptTemplate, ChatPromptTemplate, HumanMessagePromptTemplate\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from itertools import islice\n",
        "from youtube_comment_downloader import *\n",
        "from pydantic import BaseModel, Field\n",
        "from langchain.output_parsers import PydanticOutputParser\n",
        "from pydantic import BaseModel, Field\n",
        "from langchain.output_parsers import PydanticOutputParser\n",
        "from itertools import islice\n",
        "from youtube_comment_downloader import *\n",
        "from pytube import YouTube\n",
        "import cv2\n",
        "import base64\n",
        "import requests\n",
        "from PIL import Image\n",
        "from pathlib import Path\n",
        "from moviepy import editor\n",
        "import os\n",
        "import torch\n",
        "import imageio\n",
        "import os\n",
        "import requests\n",
        "import googleapiclient.discovery\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.output_parsers import PydanticOutputParser\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.pydantic_v1 import BaseModel, Field, validator\n",
        "from langchain.llms import OpenAI\n",
        "import requests\n",
        "import requests\n",
        "from langchain.chains.summarize import load_summarize_chain\n",
        "from langchain.docstore.document import Document\n",
        "from sec_api import MappingApi\n",
        "import pandas as pd\n",
        "import nltk\n",
        "from newsapi import NewsApiClient\n",
        "from transformers import PegasusTokenizer, PegasusForConditionalGeneration, TFPegasusForConditionalGeneration\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rVda29-RvBNG",
        "outputId": "2b79c260-2b37-4c4f-ada5-7dfec841dbf2"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mappingApi = MappingApi(api_key='4a60716c33ef48da1e0f77f814631ca6974eed519d1b1cd2ea884f4c2084954a')\n",
        "# map ticker to CIK, CUSIP and company details\n",
        "#by_ticker = mappingApi.resolve('ticker', 'TSLA')\n",
        "# map CIK to ticker, CUSIP and company details\n",
        "#by_cik = mappingApi.resolve('cik', '1318605')\n",
        "# map CUSIP to ticker, CIK and company details\n",
        "#by_cusip = mappingApi.resolve('cusip', '88160R101')\n",
        "# list of companies trading on the NASDAQ exchange\n",
        "by_exchange = mappingApi.resolve('exchange', 'NASDAQ')\n",
        "by_ticker_goog = mappingApi.resolve('ticker', 'GOOG')\n",
        "print('Ticker \"GOOG\" mapped to its CIK, CUSIP and company details')\n",
        "print('----------------------------------------------------------')\n",
        "pd.json_normalize(by_ticker_goog)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 342
        },
        "id": "Ab3XlVg4-yxa",
        "outputId": "58984d90-5aa9-4534-bf42-dcf4dc6347e6"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ticker \"GOOG\" mapped to its CIK, CUSIP and company details\n",
            "----------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           name ticker      cik                cusip exchange  isDelisted  \\\n",
              "0  ALPHABET INC  GOOGL  1652044  02079K305 38259P508   NASDAQ       False   \n",
              "1  ALPHABET INC   GOOG  1652044  02079K107 38259P706   NASDAQ       False   \n",
              "\n",
              "                                category                  sector  \\\n",
              "0    Domestic Common Stock Primary Class  Communication Services   \n",
              "1  Domestic Common Stock Secondary Class  Communication Services   \n",
              "\n",
              "                         industry   sic sicSector  \\\n",
              "0  Internet Content & Information  7370  Services   \n",
              "1  Internet Content & Information  7370  Services   \n",
              "\n",
              "                                         sicIndustry famaSector  \\\n",
              "0  Services-Computer Programming Data Processing ...              \n",
              "1  Services-Computer Programming Data Processing ...              \n",
              "\n",
              "        famaIndustry currency           location  \\\n",
              "0  Business Services      USD  California; U.S.A   \n",
              "1  Business Services      USD  California; U.S.A   \n",
              "\n",
              "                                 id  \n",
              "0  f4d5c493c7fe5a85bcd98005175b18bb  \n",
              "1  594230eef3f5d7c08886c262d2ae6c17  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f54ab677-5c27-4026-9d95-4bbb9493a306\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>name</th>\n",
              "      <th>ticker</th>\n",
              "      <th>cik</th>\n",
              "      <th>cusip</th>\n",
              "      <th>exchange</th>\n",
              "      <th>isDelisted</th>\n",
              "      <th>category</th>\n",
              "      <th>sector</th>\n",
              "      <th>industry</th>\n",
              "      <th>sic</th>\n",
              "      <th>sicSector</th>\n",
              "      <th>sicIndustry</th>\n",
              "      <th>famaSector</th>\n",
              "      <th>famaIndustry</th>\n",
              "      <th>currency</th>\n",
              "      <th>location</th>\n",
              "      <th>id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ALPHABET INC</td>\n",
              "      <td>GOOGL</td>\n",
              "      <td>1652044</td>\n",
              "      <td>02079K305 38259P508</td>\n",
              "      <td>NASDAQ</td>\n",
              "      <td>False</td>\n",
              "      <td>Domestic Common Stock Primary Class</td>\n",
              "      <td>Communication Services</td>\n",
              "      <td>Internet Content &amp; Information</td>\n",
              "      <td>7370</td>\n",
              "      <td>Services</td>\n",
              "      <td>Services-Computer Programming Data Processing ...</td>\n",
              "      <td></td>\n",
              "      <td>Business Services</td>\n",
              "      <td>USD</td>\n",
              "      <td>California; U.S.A</td>\n",
              "      <td>f4d5c493c7fe5a85bcd98005175b18bb</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ALPHABET INC</td>\n",
              "      <td>GOOG</td>\n",
              "      <td>1652044</td>\n",
              "      <td>02079K107 38259P706</td>\n",
              "      <td>NASDAQ</td>\n",
              "      <td>False</td>\n",
              "      <td>Domestic Common Stock Secondary Class</td>\n",
              "      <td>Communication Services</td>\n",
              "      <td>Internet Content &amp; Information</td>\n",
              "      <td>7370</td>\n",
              "      <td>Services</td>\n",
              "      <td>Services-Computer Programming Data Processing ...</td>\n",
              "      <td></td>\n",
              "      <td>Business Services</td>\n",
              "      <td>USD</td>\n",
              "      <td>California; U.S.A</td>\n",
              "      <td>594230eef3f5d7c08886c262d2ae6c17</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f54ab677-5c27-4026-9d95-4bbb9493a306')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f54ab677-5c27-4026-9d95-4bbb9493a306 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f54ab677-5c27-4026-9d95-4bbb9493a306');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-376144ba-cf12-450c-af99-cf51c29c140e\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-376144ba-cf12-450c-af99-cf51c29c140e')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-376144ba-cf12-450c-af99-cf51c29c140e button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(by_exchange)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EKLsao25A6sy",
        "outputId": "812b2c02-32fd-4ffb-9639-7daa00d57fa3"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "14419"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ticker_info_mapping = {}\n",
        "for ticker_info in by_exchange:\n",
        "  ticker_info_mapping[ticker_info['name']] = ticker_info['ticker']\n",
        "\n",
        "ticker_info_mapping"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c7TdN8BZAYnv",
        "outputId": "927e520b-b554-43ac-ac53-a23f7c493d0f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'ADMIRALTY BANCORP INC': 'AAAB',\n",
              " 'ADVANCED ACCELERATOR APPLICATIONS SA': 'AAAP',\n",
              " 'ACCESS ANYTIME BANCORP INC': 'AABC',\n",
              " 'ALLIANCE ATLANTIS COMMUNICATIONS INC': 'AACB',\n",
              " 'ASSET ACCEPTANCE CAPITAL CORP': 'AACC',\n",
              " 'ACE CASH EXPRESS INC': 'AACE',\n",
              " 'ATA CREATIVITY GLOBAL': 'AACG',\n",
              " 'ARMADA ACQUISITION CORP I': 'AACIW',\n",
              " 'AUSTRALIA ACQUISITION CORP': 'AACPF',\n",
              " 'AADI BIOSCIENCE INC': 'AADI',\n",
              " 'ADVANTAGE BANCORP INC': 'AADV',\n",
              " 'AIRTRAN HOLDINGS INC': 'AAI',\n",
              " 'ALABAMA AIRCRAFT INDUSTRIES INC': 'AAIIQ',\n",
              " 'AAIPHARMA INC': 'AAIIQ1',\n",
              " 'AMERICAN AIRLINES GROUP INC': 'AAL',\n",
              " 'ATLANTIC AMERICAN CORP': 'AAME',\n",
              " 'ABIGAIL ADAMS NATIONAL BANCORP INC': 'AANB',\n",
              " 'APPLIED OPTOELECTRONICS INC': 'AAOI',\n",
              " 'AAON INC': 'AAON',\n",
              " 'ATLANTIC ALLIANCE PARTNERSHIP CORP': 'AAPC',\n",
              " 'APPLE INC': 'AAPL',\n",
              " 'AUTOSCOPE TECHNOLOGIES CORP': 'AATC',\n",
              " 'SYMBOLLON CORP': 'SYMBA',\n",
              " 'ADVANCED ANALOGIC TECHNOLOGIES INC': 'AATI',\n",
              " 'ANALYSIS & TECHNOLOGY INC': 'AATI1',\n",
              " 'AAVID THERMAL TECHNOLOGIES INC': 'AATT',\n",
              " 'ATLAS AIR WORLDWIDE HOLDINGS INC': 'AAWW',\n",
              " 'ABACAN RESOURCE CORP': 'ABACQ',\n",
              " 'AMERICAN BANCSHARES INC': 'ABAN',\n",
              " 'AMERICAN BATTERY TECHNOLOGY CO': 'ABAT',\n",
              " 'ADVANCED BATTERY TECHNOLOGIES INC': 'ABAT1',\n",
              " 'ABAXIS INC': 'ABAX',\n",
              " 'ABINGTON BANCORP INC': 'ABBK',\n",
              " 'AMERIS BANCORP': 'ABCB',\n",
              " 'ABC DISPENSING TECHNOLOGIES INC': 'ABCC',\n",
              " 'CAMBIUM LEARNING GROUP INC': 'ABCD',\n",
              " 'ABCELLERA BIOLOGICS INC': 'ABCL',\n",
              " 'ALLIANCE BANCORP': 'ABCL1',\n",
              " 'ABCAM PLC': 'ABCM',\n",
              " 'ADVISORY BOARD CO': 'ABCO',\n",
              " 'AMERICAN BUILDINGS CO': 'ABCO1',\n",
              " 'ABC NACO INC': 'ABCRQ',\n",
              " 'ANCHOR BANCORP WISCONSIN INC': 'ABCWQ',\n",
              " 'ALCENTRA CAPITAL CORP': 'ABDC',\n",
              " 'ABACUS DIRECT CORP': 'ABDR1',\n",
              " 'ALLEGRO BIODIESEL CORP': 'ABDS',\n",
              " 'ABEONA THERAPEUTICS INC': 'ABEOW',\n",
              " 'AMERICAN BUSINESS FINANCIAL SERVICES INC': 'ABFIQ',\n",
              " 'ABENGOA SA': 'ABGBY',\n",
              " 'ABG ACQUISITION CORP I': 'ABGI',\n",
              " 'ABGENIX INC': 'ABGX',\n",
              " 'ABRAXIS BIOSCIENCE INC': 'ABII',\n",
              " 'ABILITY INC': 'ABILW',\n",
              " 'ARCA BIOPHARMA INC': 'ABIO',\n",
              " 'APPLIED BIOMETRICS INC': 'ABIO1',\n",
              " 'ABATIX CORP': 'ABIX',\n",
              " 'ADELPHIA BUSINESS SOLUTIONS INC': 'ABIZQ',\n",
              " 'AMBAC FINANCIAL GROUP INC': 'ABKFQ',\n",
              " 'ABACUS LIFE INC': 'ABLLL',\n",
              " 'ABLE LABORATORIES INC': 'ABLSQ',\n",
              " 'ABLE VIEW GLOBAL INC': 'HMACU',\n",
              " 'ABLYNX NV': 'ABLX',\n",
              " 'AMERICAN BIO MEDICA CORP': 'ABMC',\n",
              " 'ABIOMED INC': 'ABMD',\n",
              " 'AIRBNB INC': 'ABNB',\n",
              " 'AMERICAN BANCORP OF NEW JERSEY INC': 'ABNJ',\n",
              " 'AMEGY BANCORPORATION INC': 'ABNK1',\n",
              " 'ACUMEN PHARMACEUTICALS INC': 'ABOS',\n",
              " 'ABOVENET COMMUNICATIONS INC': 'ABOV',\n",
              " 'ACCENTIA BIOPHARMACEUTICALS INC': 'ABPI',\n",
              " 'ABR INFORMATION SERVICES INC': 'ABRX1',\n",
              " 'AURORA BIOSCIENCES CORP': 'ABSC',\n",
              " 'ABSCI CORP': 'ABSI',\n",
              " 'ABSOLUTE SOFTWARE CORP': 'ABST',\n",
              " 'ABT BUILDING PRODUCTS CORP': 'ABTC',\n",
              " 'ABLE TELCOM HOLDING CORP': 'ABTE',\n",
              " 'ALPHA BETA TECHNOLOGY INC': 'ABTI1',\n",
              " 'ABITS GROUP INC': 'ABTS',\n",
              " 'ALLEGIANCE BANCSHARES INC': 'ABTX',\n",
              " 'AGRIBIOTECH INC': 'ABTXQ',\n",
              " 'ARBUTUS BIOPHARMA CORP': 'ABUS',\n",
              " 'ALLIANCE BANKSHARES CORP': 'ABVA',\n",
              " 'ABVC BIOPHARMA INC': 'ABVC',\n",
              " 'ABIVAX SA': 'ABVX',\n",
              " 'AB WATLEY GROUP INC': 'ABWG',\n",
              " 'ATLANTIC COASTAL ACQUISITION CORP II': 'ACABW',\n",
              " 'ACRI CAPITAL ACQUISITION CORP': 'ACACW',\n",
              " 'ACADIA PHARMACEUTICALS INC': 'ACAD',\n",
              " 'ATLANTIC COASTAL ACQUISITION CORP': 'ACAHW',\n",
              " 'AUTOCAM CORP': 'ACAM1',\n",
              " 'AMERICAN PHYSICIANS CAPITAL INC': 'ACAP',\n",
              " 'AMERICAN CAPITAL LTD': 'ACAS',\n",
              " 'ARCTIC CAT INC': 'ACAT',\n",
              " 'ALSET CAPITAL ACQUISITION CORP': 'ACAXW',\n",
              " 'AURORA CANNABIS INC': 'ACB',\n",
              " 'ACE GLOBAL BUSINESS ACQUISITION LTD': 'ACBAW',\n",
              " 'AMERICAN COMMUNITY BANCSHARES INC': 'ACBA1',\n",
              " 'ATLANTIC CAPITAL BANCSHARES INC': 'ACBI',\n",
              " 'ACC CORP': 'ACCC',\n",
              " 'ACCOLADE INC': 'ACCD',\n",
              " 'ACCORD NETWORKS LTD': 'ACCD1',\n",
              " 'ACCELRYS INC': 'ACCL',\n",
              " 'ACCESS HEALTH INC': 'ACCS2',\n",
              " 'ARGENT CAPITAL CORP': 'ACCT',\n",
              " 'PROFRAC HOLDING CORP': 'ACDCW',\n",
              " 'ACCREDO HEALTH INC': 'ACDO',\n",
              " 'ACE COMM CORP': 'ACEC',\n",
              " 'ACME ELECTRIC CORP': 'ACEE',\n",
              " 'AMERICAN CHAMPION ENTERTAINMENT INC': 'ACEI',\n",
              " 'PARTS SOURCE INC': 'ACEP',\n",
              " 'ACER THERAPEUTICS INC': 'ACERW',\n",
              " 'ADICET BIO INC': 'ACET',\n",
              " 'ACETO CORP': 'ACETQ',\n",
              " 'AMERICREDIT CORP': 'ACF',\n",
              " 'ATLANTIC COAST FINANCIAL CORP': 'ACFC',\n",
              " 'ARCH CAPITAL GROUP LTD': 'ACGLP',\n",
              " 'ACERAGEN INC': 'ACGN',\n",
              " 'ACADIA HEALTHCARE COMPANY INC': 'ACHC',\n",
              " 'AMERICAN COUNTRY HOLDINGS INC': 'ACHI1',\n",
              " 'ACHILLES THERAPEUTICS PLC': 'ACHL',\n",
              " 'ACHILLION PHARMACEUTICALS INC': 'ACHN',\n",
              " 'ACHIEVE LIFE SCIENCES INC': 'ACHV',\n",
              " 'ACACIA COMMUNICATIONS INC': 'ACIA',\n",
              " 'AMERICAN COASTAL INSURANCE CORP': 'ACIC',\n",
              " 'AC IMMUNE SA': 'ACIU',\n",
              " 'ACI WORLDWIDE INC': 'ACIW',\n",
              " 'ACKRELL SPAC PARTNERS I CO': 'ACKIW',\n",
              " 'ACLARA BIOSCIENCES INC': 'ACLA',\n",
              " 'ACCEL INTERNATIONAL CORP': 'ACLE1',\n",
              " 'AMERICAN COMMERCIAL LINES INC': 'ACLI',\n",
              " 'ACLN LTD': 'ACLNF',\n",
              " 'ACCELIO CORP': 'ACLO',\n",
              " 'AXCELIS TECHNOLOGIES INC': 'ACLS',\n",
              " 'ARCELLX INC': 'ACLX',\n",
              " 'ACME COMMUNICATIONS INC': 'ACME',\n",
              " 'ACCUMED INTERNATIONAL INC': 'ACMI',\n",
              " 'ACCOM INC': 'ACMM',\n",
              " 'ACM RESEARCH INC': 'ACMR',\n",
              " 'AC MOORE ARTS & CRAFTS INC': 'ACMR1',\n",
              " 'AIR CANADA': 'ACNAQ',\n",
              " 'ACNB CORP': 'ACNB',\n",
              " 'ASCENT INDUSTRIES CO': 'ACNT',\n",
              " 'ANCESTRYCOM INC': 'ACOM',\n",
              " 'AGENCY COM LTD': 'ACOM1',\n",
              " 'ACLARION INC': 'ACONW',\n",
              " 'ACORDA THERAPEUTICS INC': 'ACOR',\n",
              " 'ACAP CORP': 'ACPC',\n",
              " 'INDEPENDENCE HOLDINGS CORP': 'ACQRW',\n",
              " 'ACRODYNE COMMUNICATIONS INC': 'ACRO1',\n",
              " 'ACLARIS THERAPEUTICS INC': 'ACRS',\n",
              " 'ACTRADE FINANCIAL TECHNOLOGIES LTD': 'ACRTQ',\n",
              " 'ACCRUE SOFTWARE INC': 'ACRUQ',\n",
              " 'ACRIVON THERAPEUTICS INC': 'ACRV',\n",
              " 'ACELRX PHARMACEUTICALS INC': 'ACRX',\n",
              " 'ADVANCED COMMUNICATION SYSTEMS INC': 'ACSC',\n",
              " 'AMERICAN CAPITAL SENIOR FLOATING LTD': 'ACSF',\n",
              " 'ACASTI PHARMA INC': 'ACST',\n",
              " 'ENACT HOLDINGS INC': 'ACT',\n",
              " 'ACTUA CORP': 'ACTA',\n",
              " 'ACACIA RESEARCH CORP': 'ACTG',\n",
              " 'ACTIVIDENTITY CORP': 'ACTI',\n",
              " 'ACTIVCARD SA': 'ACTI1',\n",
              " 'APPLIED COMPUTER TECHNOLOGY INC': 'ACTI2',\n",
              " 'ACTEL CORP': 'ACTL1',\n",
              " 'ACTERNA CORP': 'ACTRQ',\n",
              " 'ACTIONS SEMICONDUCTOR CO LTD': 'ACTS',\n",
              " 'ACT TELECONFERENCING INC': 'ACTT1',\n",
              " 'ACTV INC': 'ACTV1',\n",
              " 'ACURA PHARMACEUTICALS INC': 'ACUR',\n",
              " 'ACUSPHERE INC': 'ACUS',\n",
              " 'ACV AUCTIONS INC': 'ACVA',\n",
              " 'ACTIVE VOICE CORP': 'ACVC',\n",
              " 'ACURX PHARMACEUTICALS INC': 'ACXP',\n",
              " 'ADAC LABORATORIES': 'ADAC1',\n",
              " 'ADAGENE INC': 'ADAG',\n",
              " 'ANTHEMIS DIGITAL ACQUISITIONS I CORP': 'ADALW',\n",
              " 'ADAM INC': 'ADAM',\n",
              " 'ADAPTIMMUNE THERAPEUTICS PLC': 'ADAP',\n",
              " 'ADAPTIVE BROADBAND CORP': 'ADAPQ',\n",
              " 'APPLIED DIGITAL ACCESS INC': 'ADAX',\n",
              " 'ADOBE INC': 'ADBE',\n",
              " 'AUDIBLE INC': 'ADBL',\n",
              " 'ANDEAN DEVELOPMENT CORP': 'ADCC',\n",
              " 'ADC TELECOMMUNICATIONS INC': 'ADCT1',\n",
              " 'COLOR STAR TECHNOLOGY CO LTD': 'ADD',\n",
              " 'ADEIA INC': 'ADEA',\n",
              " 'ADELPHIA COMMUNICATIONS CORP': 'ADELQ',\n",
              " 'ADEPT TECHNOLOGY INC': 'ADEP',\n",
              " '26 CAPITAL ACQUISITION CORP': 'ADERW',\n",
              " 'ADVANCED EMISSIONS SOLUTIONS INC': 'ADES',\n",
              " 'ADE CORP': 'ADEX1',\n",
              " 'ADFORCE INC': 'ADFC',\n",
              " 'ADAMS GOLF INC': 'ADGF',\n",
              " 'ANALOG DEVICES INC': 'ADI',\n",
              " 'ADVANCED DIGITAL INFORMATION CORP': 'ADIC',\n",
              " 'ADIAL PHARMACEUTICALS INC': 'ADILW',\n",
              " 'AMERICAN MEDICAL TECHNOLOGIES INC': 'ADLI',\n",
              " 'ADOLOR CORP': 'ADLR',\n",
              " 'ARDEN GROUP INC': 'ARDNA',\n",
              " 'ADVANCED LIGHTING TECHNOLOGIES INC': 'ADLTQ',\n",
              " 'ADMA BIOLOGICS INC': 'ADMA',\n",
              " 'ADVANCED MATERIALS GROUP INC': 'ADMGQ',\n",
              " 'ADAMAS PHARMACEUTICALS INC': 'ADMS',\n",
              " 'ADVENT TECHNOLOGIES HOLDINGS INC': 'AMCIU1',\n",
              " 'AUDIENCE INC': 'ADNC',\n",
              " 'EDOC ACQUISITION CORP': 'ADOCW',\n",
              " 'AUTOMATIC DATA PROCESSING INC': 'ADP',\n",
              " 'AMERICAN DENTAL PARTNERS INC': 'ADPI',\n",
              " 'ADAPTIVE BIOTECHNOLOGIES CORP': 'ADPT',\n",
              " 'ANDRX CORP': 'CYBA2',\n",
              " 'ATLANTIC DATA SERVICES INC': 'ADSC',\n",
              " 'ADS-TEC ENERGY PUBLIC LTD CO': 'EUSGU',\n",
              " 'AMERICAN DISPOSAL SERVICES INC': 'ADSI',\n",
              " 'AUTODESK INC': 'ADSK',\n",
              " 'ADAPTIVE SOLUTIONS INC': 'ADSO1',\n",
              " 'ARIEL CORP': 'ADSPQ',\n",
              " 'ADVANCED DEPOSITION TECHNOLOGIES INC': 'ADTCQ',\n",
              " 'ADTHEORENT HOLDING COMPANY INC': 'MACQU',\n",
              " 'ADATOM COM INC': 'ADTM1',\n",
              " 'ADTRAN HOLDINGS INC': 'ADTN',\n",
              " 'ADITXT INC': 'ADTX',\n",
              " 'ADDUS HOMECARE CORP': 'ADUS',\n",
              " 'ADVANTAGE SOLUTIONS INC': 'CPAAU1',\n",
              " 'ADVERUM BIOTECHNOLOGIES INC': 'ADVM',\n",
              " 'ADVANTA CORP': 'ADVBQ',\n",
              " 'ADVANCEPCS': 'ADVP',\n",
              " 'ADVENT SOFTWARE INC': 'ADVS',\n",
              " 'ADDEX THERAPEUTICS LTD': 'ADXN',\n",
              " 'AVIDYN INC': 'ADYN',\n",
              " 'ADYNXX INC': 'ADYX',\n",
              " 'ADEZA BIOMEDICAL CORP': 'ADZA',\n",
              " 'AUTHENTIC EQUITY ACQUISITION CORP': 'AEACW',\n",
              " 'ALTENERGY ACQUISITION CORP': 'AEAEW',\n",
              " 'AMERICAN ENERGY DEVELOPMENT CORP': 'AEDC',\n",
              " 'AEGION CORP': 'AEGN',\n",
              " 'AEROGEN INC': 'AEGN1',\n",
              " 'AEGERION PHARMACEUTICALS INC': 'AEGR',\n",
              " 'ANTELOPE ENTERPRISE HOLDINGS LTD': 'AEHL',\n",
              " 'AF ACQUISITION CORP': 'AFAQW',\n",
              " 'AEHR TEST SYSTEMS': 'AEHR',\n",
              " 'ALSET INC': 'AEI',\n",
              " 'AIR EXPRESS INTERNATIONAL CORP': 'AEIC',\n",
              " 'ADVANCED ENERGY INDUSTRIES INC': 'AEIS',\n",
              " 'AETHLON MEDICAL INC': 'AEMD',\n",
              " 'ACCESS TO MONEY INC': 'AEMI',\n",
              " 'AMC ENTERTAINMENT INC': 'AEN1',\n",
              " 'ALLIANCE ENTERTAINMENT HOLDING CORP': 'AENTW',\n",
              " 'AMERICAN ELECTRIC POWER CO INC': 'AEPPZ',\n",
              " 'AEP INDUSTRIES INC': 'AEPI',\n",
              " 'APPLIED ENERGETICS INC': 'AERG',\n",
              " 'AERIE PHARMACEUTICALS INC': 'AERI',\n",
              " 'AERIAL COMMUNICATIONS INC': 'AERL1',\n",
              " 'AERO SYSTEMS ENGINEERING INC': 'AERS1',\n",
              " 'AERIES TECHNOLOGY INC': 'WWACU',\n",
              " 'ADVANCED ENVIRONMENTAL RECYCLING TECHNOLOGIES INC': 'AERT1',\n",
              " 'AESP INC': 'AESP',\n",
              " 'APPLIED EXTRUSION TECHNOLOGIES INC': 'AETCQ',\n",
              " 'ADDVANTAGE TECHNOLOGIES GROUP INC': 'AEY',\n",
              " 'AUDIOEYE INC': 'AEYE',\n",
              " 'AETERNA ZENTARIS INC': 'AEZS',\n",
              " 'ARENA FORTIFY ACQUISITION CORP': 'AFACU',\n",
              " 'ALMOST FAMILY INC': 'AFAM',\n",
              " 'AURA FAT PROJECTS ACQUISITION CORP': 'AFARW',\n",
              " 'ADVANCE FINANCIAL BANCORP': 'AFBC',\n",
              " 'AFFINITY BANCSHARES INC': 'AFBI',\n",
              " 'ATHENS BANCSHARES CORP': 'AFCB',\n",
              " 'AFC GAMMA INC': 'AFCG',\n",
              " 'ADVANCED FIBRE COMMUNICATIONS INC': 'AFCI',\n",
              " 'APPLIED FILMS CORP': 'AFCO1',\n",
              " 'AFC CABLE SYSTEMS INC': 'AFCX',\n",
              " 'AFSALA BANCORP INC': 'AFED',\n",
              " 'AFFINITY TECHNOLOGY GROUP INC': 'AFFIQ',\n",
              " 'AFFIRMATIVE INSURANCE HOLDINGS INC': 'AFFMQ',\n",
              " 'AFFYMETRIX INC': 'AFFX',\n",
              " 'AFFYMAX INC': 'AFFY',\n",
              " 'ATLAS FINANCIAL HOLDINGS INC': 'AFHBL',\n",
              " 'ACUTUS MEDICAL INC': 'AFIB',\n",
              " 'PRINTRAK INTERNATIONAL INC': 'AFIS',\n",
              " 'ADFLEX SOLUTIONS INC': 'AFLX',\n",
              " 'AMFM INC': 'AFM',\n",
              " 'AMERICAN RADIO SYSTEMS CORP': 'AFM1',\n",
              " 'AFFIMED NV': 'AFMD',\n",
              " 'ALLIANCE FIBER OPTIC PRODUCTS INC': 'AFOP',\n",
              " 'FORAFRIC GLOBAL PLC': 'GLAQU',\n",
              " 'AFFIRM HOLDINGS INC': 'AFRM',\n",
              " 'ANCHOR FINANCIAL CORP': 'AFSC',\n",
              " 'AMTRUST FINANCIAL SERVICES INC': 'AFSI',\n",
              " 'AMERICAN FREIGHTWAYS CORP': 'AFWY',\n",
              " 'AFYA LTD': 'AFYA',\n",
              " 'ALLIED GAMING & ENTERTAINMENT INC': 'BRACR1',\n",
              " 'AG ASSOCIATES INC': 'AGAI',\n",
              " 'AGA MEDICAL HOLDINGS INC': 'AGAM',\n",
              " 'ACRES GAMING INC': 'AGAM1',\n",
              " 'AGBA GROUP HOLDING LTD': 'AGBAW',\n",
              " 'AB HOLDING GROUP INC': 'AGBG',\n",
              " 'ANCHOR GLASS CONTAINER CORP': 'AGCCQ',\n",
              " 'AG-CHEM EQUIPMENT CO INC': 'AGCH',\n",
              " 'AMERICANA GOLD & DIAMOND HOLDINGS INC': 'AGDM',\n",
              " 'AGENUS INC': 'AGEN',\n",
              " 'AGROFRESH SOLUTIONS INC': 'AGFSW',\n",
              " 'AGRIFY CORP': 'AGFY',\n",
              " 'AGILE GROWTH CORP': 'AGGRW',\n",
              " 'AEON GLOBAL HEALTH CORP': 'AGHC',\n",
              " 'ARGONAUT GROUP INC': 'AGII1',\n",
              " 'AGILE SOFTWARE CORP': 'AGIL1',\n",
              " 'AGILETHOUGHT INC': 'LIVKU',\n",
              " 'AGIOS PHARMACEUTICALS INC': 'AGIO',\n",
              " 'AEGIS COMMUNICATIONS GROUP INC': 'AGIS',\n",
              " 'ATHEROGENICS INC': 'AGIXQ',\n",
              " 'ATLANTIC GULF COMMUNITIES CORP': 'AGLFQ',\n",
              " 'AGM GROUP HOLDINGS INC': 'AGMH',\n",
              " 'AGNC INVESTMENT CORP': 'AGNCP1',\n",
              " 'ARGONAUT TECHNOLOGIES INC': 'AGNT',\n",
              " 'AGOURON PHARMACEUTICALS INC': 'AGPH',\n",
              " 'AGRIFORCE GROWING SYSTEMS LTD': 'AGRIW',\n",
              " 'ASSOCIATED GROUP INC': 'AGRPB',\n",
              " 'AGILE THERAPEUTICS INC': 'AGRX',\n",
              " 'APPLIED GENETIC TECHNOLOGIES CORP': 'AGTC',\n",
              " 'AGRITOPE INC': 'AGTO',\n",
              " 'AGILYSYS INC': 'AGYS',\n",
              " 'ALPHA TECHNOLOGIES GROUP INC': 'AHAG',\n",
              " 'ALLIED HEALTHCARE INTERNATIONAL INC': 'AHCI',\n",
              " 'AMBANC HOLDING CO INC': 'AHCI1',\n",
              " 'ADAPTHEALTH CORP': 'AHCOW',\n",
              " 'AKSO HEALTH GROUP': 'AHG',\n",
              " 'APRIA HEALTHCARE GROUP INC': 'AHG1',\n",
              " 'ALLIANCE HOLDINGS GP LP': 'AHGP',\n",
              " 'ADVANCED HEALTH INTELLIGENCE LTD': 'AHI',\n",
              " 'AMERICAN HERITAGE INTERNATIONAL INC': 'AHII',\n",
              " 'ANIMAL HEALTH HOLDINGS INC': 'AHII1',\n",
              " 'AHL SERVICES INC': 'AHLS',\n",
              " 'AMERICAN HOMEPATIENT INC': 'AHOM',\n",
              " 'ALLIED HEALTHCARE PRODUCTS INC': 'AHPIQ',\n",
              " 'AHREN ACQUISITION CORP': 'AHRNW',\n",
              " 'AHT CORP': 'AHTCQ',\n",
              " 'AUDIO HIGHWAY-COM': 'AHWY',\n",
              " 'AIB ACQUISITION CORP': 'AIBBU',\n",
              " 'APPLIED IMAGING CORP': 'AICX',\n",
              " 'AID AUTO STORES INC': 'AIDA1',\n",
              " 'AMERICAN INDEMNITY FINANCIAL CORP': 'AIFC',\n",
              " 'AESTHETIC MEDICAL INTERNATIONAL HOLDINGS GROUP LTD': 'AIH',\n",
              " 'SENMIAO TECHNOLOGY LTD': 'AIHS',\n",
              " 'AUTOLOGIC INFORMATION INTERNATIONAL INC': 'AIII1',\n",
              " 'AIXTRON SE': 'AIIXY',\n",
              " 'ALPNET INC': 'AILP',\n",
              " 'AIMFINITY INVESTMENT CORP I': 'AIMBU',\n",
              " 'ALTRA INDUSTRIAL MOTION CORP': 'AIMC',\n",
              " 'AINOS INC': 'AIMDW',\n",
              " 'AUTOIMMUNE INC': 'AIMM',\n",
              " 'AIMMUNE THERAPEUTICS INC': 'AIMT',\n",
              " 'ARNOLD INDUSTRIES INC': 'AIND',\n",
              " 'APPLIED INNOVATION INC': 'AINN',\n",
              " 'ARTERIS INC': 'AIP',\n",
              " 'AMERICAN ITALIAN PASTA CO': 'AIPC',\n",
              " 'AMERICAN INTERNATIONAL PETROLEUM CORP': 'AIPN',\n",
              " 'ALLIANCE HEALTHCARE SERVICES INC': 'AIQ1',\n",
              " 'REALPHA TECH CORP': 'AIRE',\n",
              " 'AIRGAIN INC': 'AIRG',\n",
              " 'AIR METHODS CORP': 'AIRM',\n",
              " 'AIRSPAN NETWORKS INC': 'AIRO',\n",
              " 'AIRONET WIRELESS COMMUNICATIONS INC': 'AIRO1',\n",
              " 'AIRSCULPT TECHNOLOGIES INC': 'AIRS',\n",
              " 'AMERICAN AIRCARRIERS SUPPORT INC': 'AIRS1',\n",
              " 'AIR T INC': 'AIRTW',\n",
              " 'AIRVANA INC': 'AIRV',\n",
              " 'AI TRANSPORTATION ACQUISITION CORP': 'AITRU',\n",
              " 'XIAO-I CORP': 'AIXI',\n",
              " 'ALCIDE CORP': 'ALCD',\n",
              " 'AKAMAI TECHNOLOGIES INC': 'AKAM',\n",
              " 'AKANDA CORP': 'AKAN',\n",
              " 'ACHAOGEN INC': 'AKAOQ',\n",
              " 'AKEBIA THERAPEUTICS INC': 'AKBA',\n",
              " 'AKCEA THERAPEUTICS INC': 'AKCA',\n",
              " 'SPORTS VENTURES ACQUISITION CORP': 'AKICW',\n",
              " 'AKILI INC': 'AKLI',\n",
              " 'ACCLAIM ENTERTAINMENT INC': 'AKLMQ',\n",
              " 'AKERO THERAPEUTICS INC': 'AKRO',\n",
              " 'AKORN INC': 'AKRXQ',\n",
              " 'AKOUSTIS TECHNOLOGIES INC': 'AKTS',\n",
              " 'AKARI THERAPEUTICS PLC': 'AKTX',\n",
              " 'AKUMIN INC': 'AKUMQ',\n",
              " 'AKOUOS INC': 'AKUS',\n",
              " 'AKOYA BIOSCIENCES INC': 'AKYA',\n",
              " 'AKZO NOBEL NV': 'AKZOY',\n",
              " 'ALABAMA NATIONAL BANCORPORATION': 'ALAB',\n",
              " 'ALBERTON ACQUISITION CORP': 'ALACW',\n",
              " 'ALANCO TECHNOLOGIES INC': 'ALAN',\n",
              " 'ALARUM TECHNOLOGIES LTD': 'ALAR',\n",
              " 'ALBION BANC CORP': 'ALBC',\n",
              " 'ALBANK FINANCIAL CORP': 'ALBK',\n",
              " 'ALBIREO PHARMA INC': 'ALBO',\n",
              " 'AVALON GLOBOCARE CORP': 'ALBT',\n",
              " 'COMMUNITY CAPITAL BANCSHARES INC': 'ALBY',\n",
              " 'ALLCITY INSURANCE CO': 'ALCI',\n",
              " 'ALICO INC': 'ALCO',\n",
              " 'ALCO STORES INC': 'ALCSQ',\n",
              " 'ALCHEMY INVESTMENTS ACQUISITION CORP 1': 'ALCYW',\n",
              " 'ALDILA INC': 'ALDA',\n",
              " 'ALADDIN KNOWLEDGE SYSTEMS LTD': 'ALDN',\n",
              " 'ALDER BIOPHARMACEUTICALS INC': 'ALDR',\n",
              " 'ALLIED DEVICES CORP': 'ALDV1',\n",
              " 'ALDEYRA THERAPEUTICS INC': 'ALDX',\n",
              " 'ALECTOR INC': 'ALEC',\n",
              " 'ALFA CORP': 'ALFA1',\n",
              " 'ATLANTIC LIBERTY FINANCIAL CORP': 'ALFC',\n",
              " 'ALLIED LIFE FINANCIAL CORP': 'ALFC1',\n",
              " 'ALFI INC': 'ALFIW',\n",
              " 'ALFORD REFRIGERATED WAREHOUSES INC': 'ALFO',\n",
              " 'AMERICAN LOCKER GROUP INC': 'ALGI',\n",
              " 'ALLEGRO MICROSYSTEMS INC': 'ALGM',\n",
              " 'ALIGN TECHNOLOGY INC': 'ALGN',\n",
              " 'ALGOS PHARMACEUTICAL CORP': 'ALGO',\n",
              " 'ALLEGRO MERGER CORP': 'ALGRR',\n",
              " 'ALIGOS THERAPEUTICS INC': 'ALGS',\n",
              " 'ALLEGIANT TRAVEL CO': 'ALGT',\n",
              " 'ALLEGIANCE TELECOM INC': 'ALGXQ',\n",
              " 'ALIGNMENT HEALTHCARE INC': 'ALHC',\n",
              " 'ALIMERA SCIENCES INC': 'ALIM',\n",
              " 'ALJ REGIONAL HOLDINGS INC': 'ALJJ',\n",
              " 'ALKERMES PLC': 'ALKS',\n",
              " 'ALKAMI TECHNOLOGY INC': 'ALKT',\n",
              " 'ALPHA STAR ACQUISITION CORP': 'ALSAU',\n",
              " 'ALLIANCE BANCORP INC OF PENNSYLVANIA': 'ALLB',\n",
              " 'ALLION HEALTHCARE INC': 'ALLI',\n",
              " 'ALLAKOS INC': 'ALLK',\n",
              " 'ALLOGENE THERAPEUTICS INC': 'ALLO',\n",
              " 'ALLIANCE PHARMACEUTICAL CORP': 'ALLP',\n",
              " 'ALLARITY THERAPEUTICS INC': 'ALLR',\n",
              " 'ALLAIRE CORP': 'ALLR1',\n",
              " 'ALLSTREAM INC': 'ALLSB',\n",
              " 'ALLOT LTD': 'ALLT',\n",
              " 'ALLENA PHARMACEUTICALS INC': 'ALNAQ',\n",
              " 'ALLIANCE FINANCIAL CORP': 'ALNC',\n",
              " 'AMERILINK CORP': 'ALNK',\n",
              " 'ALLIENT INC': 'ALNT',\n",
              " 'ALIANT COMMUNICATIONS INC': 'ALNT1',\n",
              " 'ALNYLAM PHARMACEUTICALS INC': 'ALNY',\n",
              " 'ANALOGIC CORP': 'ALOG',\n",
              " 'ALSP ORCHID ACQUISITION CORP I': 'ALORW',\n",
              " 'ASTRONOVA INC': 'ALOT',\n",
              " 'ALLOY INC': 'ALOY',\n",
              " 'ALPHANET SOLUTIONS INC': 'ALPH',\n",
              " 'ALPINE IMMUNE SCIENCES INC': 'ALPN',\n",
              " 'ALPINE 4 HOLDINGS INC': 'ALPP',\n",
              " 'ALPINE SUMMIT ENERGY PARTNERS INC': 'ALPSQ',\n",
              " 'ALERISLIFE INC': 'ALR',\n",
              " 'ALTERNATIVE RESOURCES CORP': 'ALRC',\n",
              " 'ALARMCOM HOLDINGS INC': 'ALRM',\n",
              " 'AILERON THERAPEUTICS INC': 'ALRN',\n",
              " 'AMERICAN LEARNING CORP': 'ALRN1',\n",
              " 'ALTRON INC': 'ALRN2',\n",
              " 'ALERUS FINANCIAL CORP': 'ALRS',\n",
              " 'ALSERES PHARMACEUTICALS INC': 'ALSE',\n",
              " 'ALASKA COMMUNICATIONS SYSTEMS GROUP INC': 'ALSK',\n",
              " 'ALPHASMART INC': 'ALSM',\n",
              " 'ALTIMMUNE INC': 'ALT',\n",
              " 'ALTABANCORP': 'ALTA',\n",
              " 'ALTERRA CAPITAL HOLDINGS LTD': 'ALTE',\n",
              " 'ALLOS THERAPEUTICS INC': 'ALTH',\n",
              " 'ALTI GLOBAL INC': 'GLBLU',\n",
              " 'ALTAIR NANOTECHNOLOGIES INC': 'ALTI1',\n",
              " 'ALTO INGREDIENTS INC': 'ALTO',\n",
              " 'ALTAIR ENGINEERING INC': 'ALTR',\n",
              " 'ALTERA CORP': 'ALTR1',\n",
              " 'ALTITUDE ACQUISITION CORP': 'ALTUW',\n",
              " 'ALTUS PHARMACEUTICALS INC': 'ALTUQ',\n",
              " 'ALSIUS CORP': 'ALUS1',\n",
              " 'ALVOTECH': 'ALVOW',\n",
              " 'ALLOVIR INC': 'ALVR',\n",
              " 'ALVARION LTD': 'ALVRQ',\n",
              " 'ALEXZA PHARMACEUTICALS INC': 'ALXA',\n",
              " 'ALEXION PHARMACEUTICALS INC': 'ALXN',\n",
              " 'ALX ONCOLOGY HOLDINGS INC': 'ALXO',\n",
              " 'ALITHYA GROUP INC': 'ALYA',\n",
              " 'ALYN CORP': 'ALYNQ',\n",
              " 'ALYSIS TECHNOLOGIES INC': 'ALYS',\n",
              " 'ALZAMEND NEURO INC': 'ALZN',\n",
              " 'AMERICAN MEDICAL ALERT CORP': 'AMAC',\n",
              " 'AMAG PHARMACEUTICALS INC': 'AMAG',\n",
              " 'AMALGAMATED FINANCIAL CORP': 'AMAL',\n",
              " 'AMBRX BIOPHARMA INC': 'AMAM',\n",
              " 'AUTONAVI HOLDINGS LTD': 'AMAP',\n",
              " 'AMARILLO BIOSCIENCES INC': 'AMARQ',\n",
              " 'APPLIED MATERIALS INC': 'AMAT',\n",
              " 'AMBARELLA INC': 'AMBA',\n",
              " 'AMERICAN BANCORPORATION': 'AMBC1',\n",
              " 'AMBIT BIOSCIENCES CORP': 'AMBI1',\n",
              " 'AMBANC CORP': 'AMBK1',\n",
              " 'AMBIENT CORP': 'AMBTQ',\n",
              " 'APPLIED MICRO CIRCUITS CORP': 'AMCC',\n",
              " 'ANDATEE CHINA MARINE FUEL SERVICES CORP': 'AMCF',\n",
              " 'AMERICAN COIN MERCHANDISING INC': 'AMCN1',\n",
              " 'AMCOMP INC': 'AMCP',\n",
              " 'AMICAS INC': 'AMCS',\n",
              " 'AMRESCO CAPITAL TRUST': 'AMCT',\n",
              " 'AMERICAN CLASSIC VOYAGES CO': 'AMCVQ',\n",
              " 'AMC NETWORKS INC': 'AMCX',\n",
              " 'ADVANCED MICRO DEVICES INC': 'AMD',\n",
              " 'AMEDISYS INC': 'AMED',\n",
              " 'APOLLO MEDICAL HOLDINGS INC': 'AMEH',\n",
              " 'AMERICAN EDUCATIONAL PRODUCTS INC': 'AMEP',\n",
              " 'AMES DEPARTMENT STORES INC': 'AMESQ',\n",
              " 'APPLIED MOLECULAR EVOLUTION INC': 'AMEV',\n",
              " 'AMERICAN FINANCIAL HOLDINGS INC': 'AMFH',\n",
              " 'AMCORE FINANCIAL INC': 'AMFIQ',\n",
              " 'AMERICAN MOLD GUARD INC': 'AMGI',\n",
              " 'ASCENT MEDIA GROUP INC': 'AMGIA',\n",
              " 'AMGEN INC': 'AMGN',\n",
              " 'AMERICAN HEALTHCHOICE INC': 'AMHI',\n",
              " 'AMERICAN INDEPENDENCE CORP': 'AMIC',\n",
              " 'AMBASSADORS INTERNATIONAL INC': 'AMIEQ',\n",
              " 'AMIS HOLDINGS INC': 'AMIS',\n",
              " 'AMKOR TECHNOLOGY INC': 'AMKR',\n",
              " 'AMERICAN LITHIUM CORP': 'AMLI',\n",
              " 'AML COMMUNICATIONS INC': 'AMLJ',\n",
              " 'AMYLIN PHARMACEUTICALS INC': 'AMLN',\n",
              " 'AMYLYX PHARMACEUTICALS INC': 'AMLX',\n",
              " 'AMRESCO INC': 'AMMBQ',\n",
              " 'AMERICAN MEDICAL SYSTEMS HOLDINGS INC': 'AMMD',\n",
              " 'AMERICAN NATIONAL BANKSHARES INC': 'AMNB',\n",
              " 'ACT MANUFACTURING INC': 'AMNUQ',\n",
              " 'AMPLITECH GROUP INC': 'AMPGW',\n",
              " 'AMPHASTAR PHARMACEUTICALS INC': 'AMPH',\n",
              " 'AMERICAN PHYSICIANS SERVICE GROUP INC': 'AMPH1',\n",
              " 'AMPLITUDE INC': 'AMPL',\n",
              " 'AMPAL-AMERICAN ISRAEL CORP': 'AMPLQ',\n",
              " 'AMPEX CORP': 'AMPXQ',\n",
              " 'AMERICAN RIVER BANKSHARES': 'AMRB',\n",
              " 'ALBANY MOLECULAR RESEARCH INC': 'AMRI',\n",
              " 'A-MARK PRECIOUS METALS INC': 'AMRK',\n",
              " 'AMARIN CORP PLC': 'AMRN',\n",
              " 'AMERIN CORP': 'AMRN1',\n",
              " 'ALTA MESA RESOURCES INC': 'AMRWW',\n",
              " 'AMYRIS INC': 'AMRSQ',\n",
              " 'AMERICAN SUPERCONDUCTOR CORP': 'AMSC',\n",
              " 'AMERISAFE INC': 'AMSF',\n",
              " 'AAMES FINANCIAL CORP': 'AMSF1',\n",
              " 'AMSURG CORP': 'AMSGP',\n",
              " 'ARTEMIS INTERNATIONAL SOLUTIONS CORP': 'AMSI',\n",
              " 'APACHE MEDICAL SYSTEMS INC': 'AMSI1',\n",
              " 'AMESITE INC': 'AMST',\n",
              " 'AMERICAN SOFTWARE INC': 'AMSWA',\n",
              " 'AMERICAN MANAGEMENT SYSTEMS INC': 'AMSY',\n",
              " 'AMERITRANS CAPITAL CORP': 'AMTCQ',\n",
              " 'TD AMERITRADE HOLDING CORP': 'AMTD1',\n",
              " 'APPLIED MOLECULAR TRANSPORT INC': 'AMTI',\n",
              " 'AMERICAN MATERIALS & TECHNOLOGIES CORP': 'AMTK1',\n",
              " 'AEMETIS INC': 'AMTX',\n",
              " 'AMERITYRE CORP': 'AMTY',\n",
              " 'AMERIVEST PROPERTIES INC': 'AMV2',\n",
              " 'ADVANCED MACHINE VISION CORP': 'AMVC',\n",
              " 'AMERICAN WOODMARK CORP': 'AMWD',\n",
              " 'ANC RENTAL CORP': 'ANCJQ',\n",
              " 'AMX CORP': 'AMXC',\n",
              " 'AMNEX INC': 'AMXIQ',\n",
              " 'AMRYT PHARMA PLC': 'AMYT',\n",
              " 'AMAZON COM INC': 'AMZN',\n",
              " 'ANAPTYSBIO INC': 'ANAB',\n",
              " 'ANACOR PHARMACEUTICALS INC': 'ANAC1',\n",
              " 'ANADIGICS INC': 'ANAD',\n",
              " 'AMERICAN NATIONAL GROUP INC': 'ANAT',\n",
              " 'ANB CORP': 'ANBC',\n",
              " 'ANCHOR BANCORP': 'ANCB',\n",
              " 'AIRNET COMMUNICATIONS CORP': 'ANCCQ',\n",
              " 'ANCOR COMMUNICATIONS INC': 'ANCR',\n",
              " 'ACCESS NATIONAL CORP': 'ANCX',\n",
              " 'ANDATACO INC': 'ANDA1',\n",
              " 'ANDINA ACQUISITION CORP II': 'ANDAW2',\n",
              " 'ANDOVER BANCORP INC': 'ANDB',\n",
              " 'ANDERSONS INC': 'ANDE',\n",
              " 'ANDOVER NET INC': 'ANDN1',\n",
              " 'ANADYS PHARMACEUTICALS INC': 'ANDS',\n",
              " 'ANDREW CORP': 'ANDW',\n",
              " 'ANEBULO PHARMACEUTICALS INC': 'ANEB',\n",
              " 'ANAREN  INC': 'ANEN',\n",
              " 'AUTHORIZENET HOLDINGS INC': 'ANET1',\n",
              " 'ACT NETWORKS INC': 'ANET2',\n",
              " 'ANFI INC': 'ANFI1',\n",
              " 'ANGHAMI INC': 'VMACU',\n",
              " 'ANGI INC': 'ANGI',\n",
              " 'ANGEION CORP': 'ANGN1',\n",
              " 'ANGIODYNAMICS INC': 'ANGO',\n",
              " 'ANICOM INC': 'ANIC',\n",
              " 'ANIKA THERAPEUTICS INC': 'ANIK',\n",
              " 'ANI PHARMACEUTICALS INC': 'ANIP',\n",
              " 'ANIXA BIOSCIENCES INC': 'ANIX',\n",
              " 'ADLAI NORTYE LTD': 'ANL',\n",
              " 'ANALOGY INC': 'ANLG',\n",
              " 'ANALYSTS INTERNATIONAL CORP': 'ANLY',\n",
              " 'ANACOMP INC': 'ANMP',\n",
              " 'ANNAPOLIS BANCORP INC': 'ANNB',\n",
              " 'ANNEXON INC': 'ANNX',\n",
              " 'ANGIOTECH PHARMACEUTICALS INC': 'ANPIQ',\n",
              " 'ANERGEN INC': 'ANRG',\n",
              " 'AGRICULTURE & NATURAL SOLUTIONS ACQUISITION CORP': 'ANSCU',\n",
              " 'ADVANCED NEUROMODULATION SYSTEMS INC': 'ANSI',\n",
              " 'ANSELL LTD': 'ANSLY',\n",
              " 'ANSYS INC': 'ANSS',\n",
              " 'ANSOFT CORP': 'ANST',\n",
              " 'ANESIVA INC': 'ANSVQ',\n",
              " 'ANSWERS CORP': 'ANSW',\n",
              " 'AIRNET TECHNOLOGY INC': 'ANTE',\n",
              " 'ANTHERA PHARMACEUTICALS INC': 'ANTH',\n",
              " 'PHAZAR CORP': 'ANTP',\n",
              " 'AN2 THERAPEUTICS INC': 'ANTX',\n",
              " 'SPHERE 3D CORP': 'ANY',\n",
              " 'AROGO CAPITAL ACQUISITION CORP': 'AOGOW',\n",
              " 'AMERICA ONLINE LATIN AMERICA INC': 'AOLAQ',\n",
              " 'AMERICAN ONCOLOGY NETWORK INC': 'DTOCU',\n",
              " 'A123 SYSTEMS INC': 'AONEQ',\n",
              " 'ALLEN ORGAN CO': 'AORGB',\n",
              " 'ALPHA & OMEGA SEMICONDUCTOR LTD': 'AOSL',\n",
              " 'AMERICAN OUTDOOR BRANDS INC': 'AOUT',\n",
              " 'GLOBAL X GURU ACTIVIST INDEX ETF': 'ACTX1',\n",
              " 'APA CORP': 'APA',\n",
              " 'APPALACHIAN BANCSHARES INC': 'APAB',\n",
              " 'STONEBRIDGE ACQUISITION CORP': 'APACU',\n",
              " 'APAC CUSTOMER SERVICES INC': 'APAC1',\n",
              " 'APCO OIL & GAS INTERNATIONAL INC': 'APAGF',\n",
              " 'AMERICAN POWER CONVERSION CORP': 'APCC',\n",
              " 'ATLAS SOUTH SEA PEARL LTD': 'APCFY',\n",
              " 'AUTOMOBILE PROTECTION CORP APCO': 'APCO',\n",
              " 'APPTECH PAYMENTS CORP': 'APCXW',\n",
              " 'APPLIED DNA SCIENCES INC': 'APDNW',\n",
              " 'AMERICAN PUBLIC EDUCATION INC': 'APEI',\n",
              " 'APOLLO ENDOSURGERY INC': 'APEN',\n",
              " 'APEX GLOBAL BRANDS INC': 'APEX',\n",
              " 'APEX INC': 'APEX1',\n",
              " 'AMERICAN PACIFIC CORP': 'APFC',\n",
              " 'APOGEE THERAPEUTICS INC': 'APGE',\n",
              " 'APEXIGEN INC': 'BCACU',\n",
              " 'APHRIA INC': 'APHA',\n",
              " 'AGORA INC': 'API',\n",
              " 'APIGEE CORP': 'APIC',\n",
              " 'ACME PACKET INC': 'APKT',\n",
              " 'APPLIED DIGITAL CORP': 'APLD',\n",
              " 'APOLLOMICS INC': 'JMACU',\n",
              " 'AT PLAN INC': 'APLN',\n",
              " 'ARCHROCK PARTNERS LP': 'APLP',\n",
              " 'APELLIS PHARMACEUTICALS INC': 'APLS',\n",
              " 'APPLIED THERAPEUTICS INC': 'APLT',\n",
              " 'APPLIX INC': 'APLX',\n",
              " 'APTORUM GROUP LTD': 'APM',\n",
              " 'APPLIED MICROSYSTEMS CORP': 'APMC',\n",
              " 'AXONPRIME INFRASTRUCTURE ACQUISITION CORP': 'APMIW',\n",
              " 'ALPHA INNOTECH CORP': 'APNO',\n",
              " 'APPNET INC': 'APNT1',\n",
              " 'APOGEE ENTERPRISES INC': 'APOG',\n",
              " 'APOLLO EDUCATION GROUP INC': 'UOPX',\n",
              " 'APPLOVIN CORP': 'APP',\n",
              " 'APPLEBEES INTERNATIONAL INC': 'APPB',\n",
              " 'APPFOLIO INC': 'APPF',\n",
              " 'APPHARVEST INC': 'NOVSU',\n",
              " 'APPIAN CORP': 'APPN',\n",
              " 'DIGITAL TURBINE INC': 'EBTBQ',\n",
              " 'APPIANT TECHNOLOGIES INC': 'APPS1',\n",
              " 'APP PHARMACEUTICALS INC': 'APPX',\n",
              " 'ASIA PACIFIC RESOURCES LTD': 'APQCF',\n",
              " 'APRIA INC': 'APR',\n",
              " 'APREA THERAPEUTICS INC': 'APRE',\n",
              " 'AMERICA FIRST APARTMENT INVESTORS INC': 'APRO1',\n",
              " 'APROPOS TECHNOLOGY INC': 'APRS',\n",
              " 'APPLIED SIGNAL TECHNOLOGY INC': 'APSG1',\n",
              " 'APPTIO INC': 'APTI',\n",
              " 'ADVANCED POWER TECHNOLOGY INC': 'APTI1',\n",
              " 'ALPHA PARTNERS TECHNOLOGY MERGER CORP': 'APTMW',\n",
              " 'APTIMUS INC': 'APTM1',\n",
              " 'APTOSE BIOSCIENCES INC': 'APTO',\n",
              " 'APTINYX INC': 'APTX',\n",
              " 'APTEVO THERAPEUTICS INC': 'APVO',\n",
              " 'ASIA PACIFIC WIRE & CABLE CORP LTD': 'APWC',\n",
              " 'APPLEWOODS INC': 'APWD',\n",
              " 'A-POWER ENERGY GENERATION SYSTEMS LTD': 'APWR1',\n",
              " 'ASTROPOWER INC': 'APWRQ',\n",
              " 'APX ACQUISITION CORP I': 'APXIW',\n",
              " 'APYX MEDICAL CORP': 'APYX',\n",
              " 'AQUABOUNTY TECHNOLOGIES INC': 'AQB',\n",
              " 'AQUA CARE SYSTEMS INC': 'AQCR',\n",
              " 'AQUA METALS INC': 'AQMS',\n",
              " 'AQUANTIVE INC': 'AQNT',\n",
              " 'AQUESTIVE THERAPEUTICS INC': 'AQST',\n",
              " 'AQUARON ACQUISITION CORP': 'AQUNU',\n",
              " 'ARAVIVE INC': 'ARAV',\n",
              " 'ACCURAY INC': 'ARAY',\n",
              " 'ARIBA INC': 'ARBA',\n",
              " 'ARB IOT GROUP LTD': 'ARBB',\n",
              " 'ARBE ROBOTICS LTD': 'ITACU',\n",
              " 'AEQUI ACQUISITION CORP': 'ARBGW',\n",
              " 'ARGO BLOCKCHAIN PLC': 'ARBKL',\n",
              " 'ARBINET CORP': 'ARBX',\n",
              " 'ARCBEST CORP': 'ARCB',\n",
              " 'ARES CAPITAL CORP': 'ARCC',\n",
              " 'ALLIED RISER COMMUNICATIONS CORP': 'ARCC1',\n",
              " 'ARCO PLATFORM LTD': 'ARCE',\n",
              " 'ARCH WIRELESS INC': 'AWIN1',\n",
              " 'ARBOR RAPHA CAPITAL BIOHOLDINGS CORP I': 'ARCKW',\n",
              " 'ARCHIPELAGO LEARNING INC': 'ARCL',\n",
              " 'ARCTURUS THERAPEUTICS HOLDINGS INC': 'ARCT',\n",
              " 'AMERICAN REALTY CAPITAL TRUST INC': 'ARCT1',\n",
              " 'ARC GROUP WORLDWIDE INC': 'ARCW',\n",
              " '@ROAD INC': 'ARDI',\n",
              " 'ARADIGM CORP': 'ARDMQ',\n",
              " 'ARIDIS PHARMACEUTICALS INC': 'ARDS',\n",
              " 'ARDENT SOFTWARE INC': 'ARDT',\n",
              " 'ARDELYX INC': 'ARDX',\n",
              " 'AREA BANCSHARES CORP': 'AREA',\n",
              " 'AMERICAN REBEL HOLDINGS INC': 'AREBW',\n",
              " 'AMERICAN RESOURCES CORP': 'AREC',\n",
              " 'AREMISSOFT CORP': 'AREM1',\n",
              " 'APPROACH RESOURCES INC': 'AREXQ',\n",
              " 'AURIGA LABORATORIES INC': 'ARGA',\n",
              " 'ARGOS THERAPEUTICS INC': 'ARGSQ',\n",
              " 'ARGUS CAPITAL CORP': 'ARGUW',\n",
              " 'ARGENX SE': 'ARGX',\n",
              " 'ARGOSY EDUCATION GROUP INC': 'ARGY',\n",
              " 'ARHAUS INC': 'ARHS',\n",
              " 'ARIAD PHARMACEUTICALS INC': 'ARIA',\n",
              " 'AMERICAN RAILCAR INDUSTRIES INC': 'ARII',\n",
              " 'ARI NETWORK SERVICES INC': 'ARIS1',\n",
              " 'ARISZ ACQUISITION CORP': 'ARIZW',\n",
              " 'ARKO CORP': 'ARKOW',\n",
              " 'ARK RESTAURANTS CORP': 'ARKR',\n",
              " 'AREL COMMUNICATIONS & SOFTWARE LTD': 'ARLCF',\n",
              " 'ALLIANCE RESOURCE PARTNERS LP': 'ARLP',\n",
              " 'ARALEZ PHARMACEUTICALS INC': 'ARLZQ',\n",
              " 'ARM HOLDINGS PLC': 'ARMH',\n",
              " 'ARMO BIOSCIENCES INC': 'ARMO',\n",
              " 'ISHARES MSCI ACWI ETF': 'ACWI',\n",
              " 'ARENA PHARMACEUTICALS INC': 'ARNA',\n",
              " 'ARROW FINANCIAL CORP': 'AROW',\n",
              " 'ARROWPOINT COMMUNICATIONS INC': 'ARPT',\n",
              " 'ARQULE INC': 'ARQL',\n",
              " 'ARQIT QUANTUM INC': 'CENHU',\n",
              " 'ARCUTIS BIOTHERAPEUTICS INC': 'ARQT',\n",
              " 'ARROW INTERNATIONAL INC': 'ARRO',\n",
              " 'ARRIS INTERNATIONAL PLC': 'ARRS',\n",
              " 'ARROWROOT ACQUISITION CORP': 'ARRWW',\n",
              " 'ARRAY TECHNOLOGIES INC': 'ARRY',\n",
              " 'ARRAY BIOPHARMA INC': 'ARRY1',\n",
              " 'ALERIS INTERNATIONAL INC': 'ARS',\n",
              " 'ARIS CORP': 'ARSC1',\n",
              " 'ARCSIGHT INC': 'ARST',\n",
              " 'ARTHROCARE CORP': 'ARTC',\n",
              " 'ARTEMIS STRATEGIC INVESTMENT CORP': 'ARTEU',\n",
              " 'ARTECON INC': 'ARTE1',\n",
              " 'ARTES MEDICAL INC': 'ARTEQ',\n",
              " 'ART TECHNOLOGY GROUP INC': 'ARTG',\n",
              " 'ARTISAN COMPONENTS INC': 'ARTI1',\n",
              " 'ARTELO BIOSCIENCES INC': 'ARTLW',\n",
              " 'ARISTOTLE CORP': 'ARTL1',\n",
              " 'ARTESIAN RESOURCES CORP': 'ARTNA',\n",
              " 'ADVANCED RADIO TELECOM CORP': 'ARTT',\n",
              " 'ARTS WAY MANUFACTURING CO INC': 'ARTW',\n",
              " 'AROTECH CORP': 'ARTX',\n",
              " 'ARUBA NETWORKS INC': 'ARUN',\n",
              " 'ARRIVAL': 'CIICU',\n",
              " 'ARVINAS INC': 'ARVN',\n",
              " 'AEROVOX INC': 'ARVX',\n",
              " 'AROWANA INC': 'ARWA',\n",
              " 'ARROW MAGNOLIA INTERNATIONAL INC': 'ARWM',\n",
              " 'ARROWHEAD PHARMACEUTICALS INC': 'ARWR',\n",
              " 'ADAMS RESPIRATORY THERAPEUTICS INC': 'ARXT',\n",
              " 'AEROFLEX INC': 'ARXX',\n",
              " 'ARYA SCIENCES ACQUISITION CORP IV': 'ARYD',\n",
              " 'ARYA SCIENCES ACQUISITION CORP V': 'ARYE',\n",
              " 'ARYX THERAPEUTICS INC': 'ARYX',\n",
              " 'ASA HOLDINGS INC': 'ASAI1',\n",
              " 'ASA INTERNATIONAL LTD': 'ASAL',\n",
              " 'ASAHI AMERICA INC': 'ASAM1',\n",
              " 'WAITR HOLDINGS INC': 'WTRHW',\n",
              " 'ASTREA ACQUISITION CORP': 'ASAXW',\n",
              " 'ASTA FUNDING INC': 'ASFI',\n",
              " 'ASB BANCORP INC': 'ASBB',\n",
              " 'AMERIANA BANCORP': 'ASBI',\n",
              " 'ASB FINANCIAL CORP': 'ASBN',\n",
              " 'ASPAC I ACQUISITION CORP': 'ASCAW',\n",
              " 'AMERISTAR CASINOS INC': 'ASCA1',\n",
              " 'ASPAC II ACQUISITION CORP': 'ASCBW',\n",
              " 'ASCENTIAL SOFTWARE CORP': 'ASCL',\n",
              " 'ASCENT CAPITAL GROUP INC': 'ASCMA',\n",
              " 'ASCENT PEDIATRICS INC': 'ASCT',\n",
              " 'ADVANCED SWITCHING COMMUNICATIONS INC': 'ASCX',\n",
              " 'ASD GROUP INC': 'ASDG',\n",
              " 'ASCENDANT SOLUTIONS INC': 'ASDS',\n",
              " 'ASPECT DEVELOPMENT INC': 'ASDV',\n",
              " 'ASECO CORP': 'ASEC',\n",
              " 'AMERICAN SCIENCE & ENGINEERING INC': 'ASEI',\n",
              " 'ASHFORD COM INC': 'ASFD',\n",
              " 'ATLANTIC SOUTHERN FINANCIAL GROUP INC': 'ASFN',\n",
              " 'ALLSTATE FINANCIAL CORP': 'ASFN1',\n",
              " 'AMERICA SERVICE GROUP INC': 'ASGR',\n",
              " 'ASIA GLOBAL CROSSING LTD': 'ASGXF',\n",
              " 'ASCHE TRANSPORTATION SERVICES INC': 'ASHE',\n",
              " 'ASHWORTH INC': 'ASHW',\n",
              " 'ASIAINFO-LINKAGE INC': 'ASIA1',\n",
              " 'ALPHASTAR INSURANCE GROUP LTD': 'ASIGF',\n",
              " 'ANSALDO SIGNAL NV': 'ASIGF1',\n",
              " 'ASI SOLUTIONS INC': 'ASIS',\n",
              " 'ASK JEEVES INC': 'ASKJ',\n",
              " 'AERSALE CORP': 'ASLEW',\n",
              " 'ASLAN PHARMACEUTICALS LTD': 'ASLN',\n",
              " 'ASSEMBLY BIOSCIENCES INC': 'ASMB',\n",
              " 'ASM INTERNATIONAL N V': 'ASMIY',\n",
              " 'ASML HOLDING NV': 'ASML',\n",
              " 'MAHWAH BERGEN RETAIL GROUP INC': 'ASNAQ',\n",
              " 'ASCENDIS PHARMA A': 'ASND',\n",
              " 'ASCEND COMMUNICATIONS INC': 'ASND1',\n",
              " 'ACTELIS NETWORKS INC': 'ASNS',\n",
              " 'ACADEMY SPORTS & OUTDOORS INC': 'ASO',\n",
              " 'AMSOUTH BANCORPORATION': 'ASO1',\n",
              " 'ASP ISOTOPES INC': 'ASPI',\n",
              " 'ANANGEL AMERICAN SHIPHOLDINGS LTD': 'ASPIY',\n",
              " 'ASPECT MEDICAL SYSTEMS INC': 'ASPM',\n",
              " 'ALTISOURCE PORTFOLIO SOLUTIONS SA': 'ASPS',\n",
              " 'ASPECT COMMUNICATIONS CORP': 'ASPT',\n",
              " 'ASPEN GROUP INC': 'ASPU',\n",
              " 'ASPREVA PHARMACEUTICALS CORP': 'ASPV',\n",
              " 'AUSPEX PHARMACEUTICALS INC': 'ASPX',\n",
              " 'AUSPEX SYSTEMS INC': 'ASPXQ',\n",
              " 'ISHARES MSCI ACWI EX US ETF': 'ACWX',\n",
              " 'ASSERTIO HOLDINGS INC': 'ASRT',\n",
              " 'AMERISERV FINANCIAL INC': 'ASRVP',\n",
              " 'ASSET ENTITIES INC': 'ASST',\n",
              " 'ASTROTECH CORP': 'ASTC',\n",
              " 'ASTEC INDUSTRIES INC': 'ASTE',\n",
              " 'ASCENT SOLAR TECHNOLOGIES INC': 'ASTI',\n",
              " 'ALLERGAN SPECIALTY THERAPEUTICS INC': 'ASTI1',\n",
              " 'ALGOMA STEEL GROUP INC': 'LEGOU',\n",
              " 'ASHTON TECHNOLOGY GROUP INC': 'ASTN',\n",
              " 'ASTRA SPACE INC': 'HOLUU',\n",
              " 'AST SPACEMOBILE INC': 'NPAUU',\n",
              " 'ASAT HOLDINGS LTD': 'ASTTY',\n",
              " 'ASTEX PHARMACEUTICALS INC': 'ASTX',\n",
              " 'APPLIED SCIENCE & TECHNOLOGY INC': 'ASTX1',\n",
              " 'ASURE SOFTWARE INC': 'ASUR',\n",
              " 'ASV HOLDINGS INC': 'ASV',\n",
              " 'ASV INC': 'ASVI',\n",
              " 'ACTIVE SOFTWARE INC': 'ASWX',\n",
              " 'AMTECH SYSTEMS INC': 'ASYS',\n",
              " 'ASYST TECHNOLOGIES INC': 'ASYTQ',\n",
              " 'ATC TECHNOLOGY CORP': 'ATAC1',\n",
              " 'ATA HOLDINGS CORP': 'ATAHQ',\n",
              " 'ATAI LIFE SCIENCES NV': 'ATAI',\n",
              " 'AURORA TECHNOLOGY ACQUISITION CORP': 'ATAKW',\n",
              " 'ATARI INC': 'ATAR1',\n",
              " 'ATOUR LIFESTYLE HOLDINGS LTD': 'ATAT',\n",
              " 'ATLANTIC BANCGROUP INC': 'ATBC',\n",
              " 'AUTONOMOUS TECHNOLOGIES CORP': 'ATCI1',\n",
              " 'AT COMM CORP': 'ATCM',\n",
              " 'ATLAS TECHNICAL CONSULTANTS INC': 'ATCXW',\n",
              " 'ASTEA INTERNATIONAL INC': 'ATEA',\n",
              " 'ALPHATEC HOLDINGS INC': 'ATEC',\n",
              " 'AMERICAN TELECASTING INC': 'ATEL1',\n",
              " 'ENTERTAINMENT INC': 'ATEN1',\n",
              " 'ATERIAN INC': 'ATER',\n",
              " 'ANTERIX INC': 'ATEX',\n",
              " 'ATG INC': 'ATGCQ',\n",
              " 'ALTA GOLD CO': 'ATGDQ',\n",
              " 'ALPHA TECHNOLOGY GROUP LTD': 'ATGL',\n",
              " 'ALTIGEN COMMUNICATIONS INC': 'ATGN',\n",
              " 'ATHIRA PHARMA INC': 'ATHA',\n",
              " 'ALTERITY THERAPEUTICS LTD': 'ATHE',\n",
              " 'AT HOME CORP': 'ATHM1',\n",
              " 'ATHENAHEALTH INC': 'ATHN1',\n",
              " 'ATHEROS COMMUNICATIONS INC': 'ATHR',\n",
              " 'ATHERSYS INC': 'ATHX',\n",
              " 'APPLIEDTHEORY CORP': 'ATHYQ',\n",
              " 'ATIF HOLDINGS LTD': 'ATIF',\n",
              " 'ATTIS INDUSTRIES INC': 'ATISW',\n",
              " 'ADVANCED TISSUE SCIENCES INC': 'ATISZ',\n",
              " 'ATLANTICUS HOLDINGS CORP': 'ATLCL',\n",
              " 'AMES NATIONAL CORP': 'ATLO',\n",
              " 'ATL PRODUCTS INC': 'ATLPA',\n",
              " 'ATLAS LITHIUM CORP': 'ATLX',\n",
              " 'ALPHATIME ACQUISITION CORP': 'ATMCW',\n",
              " 'ATMI INC': 'ATMI',\n",
              " 'ATMEL CORP': 'ATML',\n",
              " 'ALPHAVEST ACQUISITION CORP': 'ATMVU',\n",
              " '180 LIFE SCIENCES CORP': 'KBLMR',\n",
              " 'ATN INTERNATIONAL INC': 'ATNI',\n",
              " 'ATHENEX INC': 'ATNXQ',\n",
              " 'API TECHNOLOGIES CORP': 'ATNY',\n",
              " 'ATOMERA INC': 'ATOM',\n",
              " 'ATOMIC BURRITO INC': 'ATOM1',\n",
              " 'ALTEON WEBSYSTEMS INC': 'ATON',\n",
              " 'ATOSSA THERAPEUTICS INC': 'ATOS',\n",
              " 'ATP OIL & GAS CORP': 'ATPAQ',\n",
              " 'AGAPE ATP CORP': 'ATPC',\n",
              " 'ATHEY PRODUCTS CORP': 'ATPC1',\n",
              " 'ATLANTIS PLASTICS INC': 'ATPL',\n",
              " 'ADVANCED TECHNICAL PRODUCTS INC': 'ATPX',\n",
              " 'ATARA BIOTHERAPEUTICS INC': 'ATRA',\n",
              " 'ATRICURE INC': 'ATRC',\n",
              " 'ATRION CORP': 'ATRI',\n",
              " 'ATRM HOLDINGS INC': 'ATRM',\n",
              " 'ASTRONICS CORP': 'ATRO',\n",
              " 'ANTARES PHARMA INC': 'ATRS',\n",
              " 'ALTIRIS INC': 'ATRS1',\n",
              " 'ADHERA THERAPEUTICS INC': 'ATRX',\n",
              " 'ATRIX LABORATORIES INC': 'ATRX1',\n",
              " 'AMTRUST CAPITAL CORP': 'ATSB',\n",
              " 'AIR TRANSPORT SERVICES GROUP INC': 'ATSG',\n",
              " 'ATS MEDICAL INC': 'ATSI',\n",
              " 'ARTESYN TECHNOLOGIES INC': 'ATSN',\n",
              " 'AT&T CANADA INC': 'ATTC1',\n",
              " 'AT&T LATIN AMERICA CORP': 'ATTL',\n",
              " 'ATTUNITY LTD': 'ATTU',\n",
              " '1-800 ATTORNEY INC': 'ATTY',\n",
              " 'ALTIVA FINANCIAL CORP': 'ATVA',\n",
              " 'ACTIVISION BLIZZARD INC': 'ATVI',\n",
              " 'COSTA INC': 'ATX',\n",
              " 'ADDENTAX GROUP CORP': 'ATXG',\n",
              " 'AVENUE THERAPEUTICS INC': 'ATXI',\n",
              " 'ATRIX INTERNATIONAL INC': 'ATXI1',\n",
              " 'ASTRIA THERAPEUTICS INC': 'ATXS',\n",
              " 'ATI TECHNOLOGIES INC': 'ATYT',\n",
              " 'AUBURN NATIONAL BANCORPORATION INC': 'AUBN',\n",
              " 'AUDIOCODES LTD': 'AUDC',\n",
              " 'AUGMENT SYSTEMS INC': 'AUGS',\n",
              " 'AUGUST TECHNOLOGY CORP': 'AUGT1',\n",
              " 'AUGMEDIX INC': 'AUGX',\n",
              " 'AUTHID INC': 'AUID',\n",
              " 'AULT INC': 'AULT1',\n",
              " 'AURINIA PHARMACEUTICALS INC': 'AUPH',\n",
              " 'AURORA INNOVATION INC': 'RTPYU',\n",
              " 'AURA BIOSCIENCES INC': 'AURA',\n",
              " 'AURA SYSTEMS INC': 'AURAQ',\n",
              " 'ACCESS PLANS USA INC': 'AUSA',\n",
              " 'AUTHENTEC INC': 'AUTH',\n",
              " 'AUTOLUS THERAPEUTICS PLC': 'AUTL',\n",
              " 'AUTONOMY CORP PLC': 'AUTNY',\n",
              " 'AUTOWEB INC': 'AUTO',\n",
              " 'AUTOINFO INC': 'AUTO1',\n",
              " 'AUDDIA INC': 'AUUDW',\n",
              " 'APPLIED UV INC': 'AUVIP',\n",
              " 'AUXILIUM PHARMACEUTICALS INC': 'AUXL',\n",
              " 'AUTHORISZOR INC': 'AUZR',\n",
              " 'AVEANNA HEALTHCARE HOLDINGS INC': 'AVAH',\n",
              " 'ACM MANAGED DOLLAR INCOME FUND INC': 'ADF1',\n",
              " 'AEROVIRONMENT INC': 'AVAV',\n",
              " 'AMERICAN VANTAGE COMPANIES': 'AVCS',\n",
              " 'AVOCENT CORP': 'AVCT1',\n",
              " 'AMERICAN VIRTUAL CLOUD TECHNOLOGIES INC': 'WRLSR',\n",
              " 'AVADEL PHARMACEUTICALS PLC': 'AVDL',\n",
              " 'AVONDALE INDUSTRIES INC': 'AVDL1',\n",
              " 'AVADO BRANDS INC': 'AVDO',\n",
              " 'AVEDRO INC': 'AVDR1',\n",
              " 'AVALON DIGITAL MARKETING SYSTEMS INC': 'AVDS1',\n",
              " 'AVIDXCHANGE HOLDINGS INC': 'AVDX',\n",
              " 'AVECOR CARDIOVASCULAR INC': 'AVEC',\n",
              " 'ARTERIAL VASCULAR ENGINEERING INC': 'AVEI',\n",
              " 'AVEO PHARMACEUTICALS INC': 'AVEO',\n",
              " 'AVIATION GENERAL INC': 'AVGE1',\n",
              " 'AVIGEN INC': 'AVGN',\n",
              " 'BROADCOM INC': 'AVGOP',\n",
              " 'AVANTGO INC': 'AVGO1',\n",
              " 'AVINGER INC': 'AVGR',\n",
              " 'ACHARI VENTURES HOLDINGS CORP I': 'AVHIW',\n",
              " 'AV HOMES INC': 'AVHI1',\n",
              " 'AVID TECHNOLOGY INC': 'AVID',\n",
              " 'ATEA PHARMACEUTICALS INC': 'AVIR',\n",
              " 'AVIRON': 'AVIR1',\n",
              " 'AVINCI MEDIA CORP': 'AVMC1',\n",
              " 'AVANIR PHARMACEUTICALS INC': 'AVNR',\n",
              " 'AVANT CORP': 'AVNT1',\n",
              " 'AVENUE FINANCIAL HOLDINGS INC': 'AVNU',\n",
              " 'AVIAT NETWORKS INC': 'AVNW',\n",
              " 'AVANEX CORP': 'AVNX',\n",
              " 'MISSION PRODUCE INC': 'AVO',\n",
              " 'AVEPOINT INC': 'AVPTW',\n",
              " 'AVROBIO INC': 'AVRO',\n",
              " 'AVERT INC': 'AVRT1',\n",
              " 'AVALON PHARMACEUTICALS INC': 'AVRX',\n",
              " 'AVNET INC': 'AVT',\n",
              " 'AVANTAX INC': 'AVTA',\n",
              " 'AEROVATE THERAPEUTICS INC': 'AVTE',\n",
              " 'AVITAR INC': 'AVTI',\n",
              " 'AVTEAM INC': 'AVTMQ',\n",
              " 'AVALO THERAPEUTICS INC': 'CERCZ',\n",
              " 'ANAVEX LIFE SCIENCES CORP': 'AVXL',\n",
              " 'AVEXIS INC': 'AVXS',\n",
              " 'AVIZA TECHNOLOGY INC': 'AVZAQ',\n",
              " 'HOMEAWAY INC': 'AWAY1',\n",
              " 'AMERICANWEST BANCORPORATION': 'AWBCQ',\n",
              " 'AUTOWEB COM INC': 'AWEB',\n",
              " 'ALDERWOODS GROUP INC': 'AWGI1',\n",
              " \"ASPIRA WOMEN'S HEALTH INC\": 'AWH',\n",
              " 'AERWINS TECHNOLOGIES INC': 'PONOU',\n",
              " 'AXTIVE CORP': 'AXTC',\n",
              " 'AWARE INC': 'AWRE',\n",
              " 'AXAR ACQUISITION CORP': 'AXAR',\n",
              " 'ABRAXAS PETROLEUM CORP': 'AXAS',\n",
              " 'AXCAN PHARMA INC': 'AXCA',\n",
              " 'ACCELERATE DIAGNOSTICS INC': 'AXDX',\n",
              " 'AXOGEN INC': 'AXGN',\n",
              " 'AXIOHM TRANSACTION SOLUTIONS INC': 'AXHM',\n",
              " 'EURAND NV': 'EURX',\n",
              " 'AXION INTERNATIONAL HOLDINGS INC': 'AXIHQ',\n",
              " 'AXCELLA HEALTH INC': 'AXLA',\n",
              " 'AXENT TECHNOLOGIES INC': 'AXNT',\n",
              " ...}"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import yfinance as yf\n",
        "\n",
        "msft = yf.Ticker(\"AAPL\")\n",
        "\n",
        "# get all stock info\n",
        "msft.info\n",
        "\n",
        "# get historical market data\n",
        "hist = msft.history(period=\"1mo\")"
      ],
      "metadata": {
        "id": "TRgZfRu1MqEM"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list(msft.info.keys())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g1UQonb-NC0g",
        "outputId": "57f8332e-48ed-4b04-de88-83421e6be375"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['address1',\n",
              " 'city',\n",
              " 'state',\n",
              " 'zip',\n",
              " 'country',\n",
              " 'phone',\n",
              " 'website',\n",
              " 'industry',\n",
              " 'industryKey',\n",
              " 'industryDisp',\n",
              " 'sector',\n",
              " 'sectorKey',\n",
              " 'sectorDisp',\n",
              " 'longBusinessSummary',\n",
              " 'fullTimeEmployees',\n",
              " 'companyOfficers',\n",
              " 'auditRisk',\n",
              " 'boardRisk',\n",
              " 'compensationRisk',\n",
              " 'shareHolderRightsRisk',\n",
              " 'overallRisk',\n",
              " 'governanceEpochDate',\n",
              " 'compensationAsOfEpochDate',\n",
              " 'maxAge',\n",
              " 'priceHint',\n",
              " 'previousClose',\n",
              " 'open',\n",
              " 'dayLow',\n",
              " 'dayHigh',\n",
              " 'regularMarketPreviousClose',\n",
              " 'regularMarketOpen',\n",
              " 'regularMarketDayLow',\n",
              " 'regularMarketDayHigh',\n",
              " 'dividendRate',\n",
              " 'dividendYield',\n",
              " 'exDividendDate',\n",
              " 'payoutRatio',\n",
              " 'fiveYearAvgDividendYield',\n",
              " 'beta',\n",
              " 'trailingPE',\n",
              " 'forwardPE',\n",
              " 'volume',\n",
              " 'regularMarketVolume',\n",
              " 'averageVolume',\n",
              " 'averageVolume10days',\n",
              " 'averageDailyVolume10Day',\n",
              " 'bid',\n",
              " 'ask',\n",
              " 'bidSize',\n",
              " 'askSize',\n",
              " 'marketCap',\n",
              " 'fiftyTwoWeekLow',\n",
              " 'fiftyTwoWeekHigh',\n",
              " 'priceToSalesTrailing12Months',\n",
              " 'fiftyDayAverage',\n",
              " 'twoHundredDayAverage',\n",
              " 'trailingAnnualDividendRate',\n",
              " 'trailingAnnualDividendYield',\n",
              " 'currency',\n",
              " 'enterpriseValue',\n",
              " 'profitMargins',\n",
              " 'floatShares',\n",
              " 'sharesOutstanding',\n",
              " 'sharesShort',\n",
              " 'sharesShortPriorMonth',\n",
              " 'sharesShortPreviousMonthDate',\n",
              " 'dateShortInterest',\n",
              " 'sharesPercentSharesOut',\n",
              " 'heldPercentInsiders',\n",
              " 'heldPercentInstitutions',\n",
              " 'shortRatio',\n",
              " 'shortPercentOfFloat',\n",
              " 'impliedSharesOutstanding',\n",
              " 'bookValue',\n",
              " 'priceToBook',\n",
              " 'lastFiscalYearEnd',\n",
              " 'nextFiscalYearEnd',\n",
              " 'mostRecentQuarter',\n",
              " 'earningsQuarterlyGrowth',\n",
              " 'netIncomeToCommon',\n",
              " 'trailingEps',\n",
              " 'forwardEps',\n",
              " 'pegRatio',\n",
              " 'lastSplitFactor',\n",
              " 'lastSplitDate',\n",
              " 'enterpriseToRevenue',\n",
              " 'enterpriseToEbitda',\n",
              " '52WeekChange',\n",
              " 'SandP52WeekChange',\n",
              " 'lastDividendValue',\n",
              " 'lastDividendDate',\n",
              " 'exchange',\n",
              " 'quoteType',\n",
              " 'symbol',\n",
              " 'underlyingSymbol',\n",
              " 'shortName',\n",
              " 'longName',\n",
              " 'firstTradeDateEpochUtc',\n",
              " 'timeZoneFullName',\n",
              " 'timeZoneShortName',\n",
              " 'uuid',\n",
              " 'messageBoardId',\n",
              " 'gmtOffSetMilliseconds',\n",
              " 'currentPrice',\n",
              " 'targetHighPrice',\n",
              " 'targetLowPrice',\n",
              " 'targetMeanPrice',\n",
              " 'targetMedianPrice',\n",
              " 'recommendationMean',\n",
              " 'recommendationKey',\n",
              " 'numberOfAnalystOpinions',\n",
              " 'totalCash',\n",
              " 'totalCashPerShare',\n",
              " 'ebitda',\n",
              " 'totalDebt',\n",
              " 'quickRatio',\n",
              " 'currentRatio',\n",
              " 'totalRevenue',\n",
              " 'debtToEquity',\n",
              " 'revenuePerShare',\n",
              " 'returnOnAssets',\n",
              " 'returnOnEquity',\n",
              " 'grossProfits',\n",
              " 'freeCashflow',\n",
              " 'operatingCashflow',\n",
              " 'earningsGrowth',\n",
              " 'revenueGrowth',\n",
              " 'grossMargins',\n",
              " 'ebitdaMargins',\n",
              " 'operatingMargins',\n",
              " 'financialCurrency',\n",
              " 'trailingPegRatio']"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hist['ticker'] = 'AAPL'"
      ],
      "metadata": {
        "id": "vR9JLgfNQMTo"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hist"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 770
        },
        "id": "jJVc-ndVR6PF",
        "outputId": "56aebf7e-89b0-48a1-c60b-1abde0fac957"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                 Open        High         Low       Close  \\\n",
              "Date                                                                        \n",
              "2023-11-01 00:00:00-04:00  170.775011  174.000757  169.896164  173.741104   \n",
              "2023-11-02 00:00:00-04:00  175.289074  177.546095  175.229156  177.336380   \n",
              "2023-11-03 00:00:00-04:00  174.010754  176.587362  173.121926  176.417572   \n",
              "2023-11-06 00:00:00-05:00  176.147945  179.193920  175.978171  178.994186   \n",
              "2023-11-07 00:00:00-05:00  178.944239  182.199959  178.734524  181.580780   \n",
              "2023-11-08 00:00:00-05:00  182.110085  183.208629  181.351076  182.649368   \n",
              "2023-11-09 00:00:00-05:00  182.719278  183.877740  181.570782  182.169998   \n",
              "2023-11-10 00:00:00-05:00  183.970001  186.570007  183.529999  186.399994   \n",
              "2023-11-13 00:00:00-05:00  185.820007  186.029999  184.210007  184.800003   \n",
              "2023-11-14 00:00:00-05:00  187.699997  188.110001  186.300003  187.440002   \n",
              "2023-11-15 00:00:00-05:00  187.850006  189.500000  187.779999  188.009995   \n",
              "2023-11-16 00:00:00-05:00  189.570007  190.960007  188.649994  189.710007   \n",
              "2023-11-17 00:00:00-05:00  190.250000  190.380005  188.570007  189.690002   \n",
              "2023-11-20 00:00:00-05:00  189.889999  191.910004  189.880005  191.449997   \n",
              "2023-11-21 00:00:00-05:00  191.410004  191.520004  189.740005  190.639999   \n",
              "2023-11-22 00:00:00-05:00  191.490005  192.929993  190.830002  191.309998   \n",
              "2023-11-24 00:00:00-05:00  190.869995  190.899994  189.250000  189.970001   \n",
              "2023-11-27 00:00:00-05:00  189.919998  190.669998  188.899994  189.789993   \n",
              "2023-11-28 00:00:00-05:00  189.779999  191.080002  189.399994  190.399994   \n",
              "2023-11-29 00:00:00-05:00  190.899994  192.089996  188.970001  189.369995   \n",
              "2023-11-30 00:00:00-05:00  189.839996  190.320007  188.190002  189.949997   \n",
              "2023-12-01 00:00:00-05:00  190.330002  191.339996  189.229996  191.259995   \n",
              "\n",
              "                             Volume  Dividends  Stock Splits ticker  \n",
              "Date                                                                 \n",
              "2023-11-01 00:00:00-04:00  56934900       0.00           0.0   AAPL  \n",
              "2023-11-02 00:00:00-04:00  77334800       0.00           0.0   AAPL  \n",
              "2023-11-03 00:00:00-04:00  79763700       0.00           0.0   AAPL  \n",
              "2023-11-06 00:00:00-05:00  63841300       0.00           0.0   AAPL  \n",
              "2023-11-07 00:00:00-05:00  70530000       0.00           0.0   AAPL  \n",
              "2023-11-08 00:00:00-05:00  49340300       0.00           0.0   AAPL  \n",
              "2023-11-09 00:00:00-05:00  53763500       0.00           0.0   AAPL  \n",
              "2023-11-10 00:00:00-05:00  66133400       0.24           0.0   AAPL  \n",
              "2023-11-13 00:00:00-05:00  43627500       0.00           0.0   AAPL  \n",
              "2023-11-14 00:00:00-05:00  60108400       0.00           0.0   AAPL  \n",
              "2023-11-15 00:00:00-05:00  53790500       0.00           0.0   AAPL  \n",
              "2023-11-16 00:00:00-05:00  54412900       0.00           0.0   AAPL  \n",
              "2023-11-17 00:00:00-05:00  50922700       0.00           0.0   AAPL  \n",
              "2023-11-20 00:00:00-05:00  46505100       0.00           0.0   AAPL  \n",
              "2023-11-21 00:00:00-05:00  38134500       0.00           0.0   AAPL  \n",
              "2023-11-22 00:00:00-05:00  39617700       0.00           0.0   AAPL  \n",
              "2023-11-24 00:00:00-05:00  24048300       0.00           0.0   AAPL  \n",
              "2023-11-27 00:00:00-05:00  40552600       0.00           0.0   AAPL  \n",
              "2023-11-28 00:00:00-05:00  38415400       0.00           0.0   AAPL  \n",
              "2023-11-29 00:00:00-05:00  43014200       0.00           0.0   AAPL  \n",
              "2023-11-30 00:00:00-05:00  48715100       0.00           0.0   AAPL  \n",
              "2023-12-01 00:00:00-05:00  18494967       0.00           0.0   AAPL  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f53b5e0b-ba63-4da1-80ab-b0c16f769a35\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Volume</th>\n",
              "      <th>Dividends</th>\n",
              "      <th>Stock Splits</th>\n",
              "      <th>ticker</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2023-11-01 00:00:00-04:00</th>\n",
              "      <td>170.775011</td>\n",
              "      <td>174.000757</td>\n",
              "      <td>169.896164</td>\n",
              "      <td>173.741104</td>\n",
              "      <td>56934900</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>AAPL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-11-02 00:00:00-04:00</th>\n",
              "      <td>175.289074</td>\n",
              "      <td>177.546095</td>\n",
              "      <td>175.229156</td>\n",
              "      <td>177.336380</td>\n",
              "      <td>77334800</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>AAPL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-11-03 00:00:00-04:00</th>\n",
              "      <td>174.010754</td>\n",
              "      <td>176.587362</td>\n",
              "      <td>173.121926</td>\n",
              "      <td>176.417572</td>\n",
              "      <td>79763700</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>AAPL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-11-06 00:00:00-05:00</th>\n",
              "      <td>176.147945</td>\n",
              "      <td>179.193920</td>\n",
              "      <td>175.978171</td>\n",
              "      <td>178.994186</td>\n",
              "      <td>63841300</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>AAPL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-11-07 00:00:00-05:00</th>\n",
              "      <td>178.944239</td>\n",
              "      <td>182.199959</td>\n",
              "      <td>178.734524</td>\n",
              "      <td>181.580780</td>\n",
              "      <td>70530000</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>AAPL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-11-08 00:00:00-05:00</th>\n",
              "      <td>182.110085</td>\n",
              "      <td>183.208629</td>\n",
              "      <td>181.351076</td>\n",
              "      <td>182.649368</td>\n",
              "      <td>49340300</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>AAPL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-11-09 00:00:00-05:00</th>\n",
              "      <td>182.719278</td>\n",
              "      <td>183.877740</td>\n",
              "      <td>181.570782</td>\n",
              "      <td>182.169998</td>\n",
              "      <td>53763500</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>AAPL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-11-10 00:00:00-05:00</th>\n",
              "      <td>183.970001</td>\n",
              "      <td>186.570007</td>\n",
              "      <td>183.529999</td>\n",
              "      <td>186.399994</td>\n",
              "      <td>66133400</td>\n",
              "      <td>0.24</td>\n",
              "      <td>0.0</td>\n",
              "      <td>AAPL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-11-13 00:00:00-05:00</th>\n",
              "      <td>185.820007</td>\n",
              "      <td>186.029999</td>\n",
              "      <td>184.210007</td>\n",
              "      <td>184.800003</td>\n",
              "      <td>43627500</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>AAPL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-11-14 00:00:00-05:00</th>\n",
              "      <td>187.699997</td>\n",
              "      <td>188.110001</td>\n",
              "      <td>186.300003</td>\n",
              "      <td>187.440002</td>\n",
              "      <td>60108400</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>AAPL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-11-15 00:00:00-05:00</th>\n",
              "      <td>187.850006</td>\n",
              "      <td>189.500000</td>\n",
              "      <td>187.779999</td>\n",
              "      <td>188.009995</td>\n",
              "      <td>53790500</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>AAPL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-11-16 00:00:00-05:00</th>\n",
              "      <td>189.570007</td>\n",
              "      <td>190.960007</td>\n",
              "      <td>188.649994</td>\n",
              "      <td>189.710007</td>\n",
              "      <td>54412900</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>AAPL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-11-17 00:00:00-05:00</th>\n",
              "      <td>190.250000</td>\n",
              "      <td>190.380005</td>\n",
              "      <td>188.570007</td>\n",
              "      <td>189.690002</td>\n",
              "      <td>50922700</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>AAPL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-11-20 00:00:00-05:00</th>\n",
              "      <td>189.889999</td>\n",
              "      <td>191.910004</td>\n",
              "      <td>189.880005</td>\n",
              "      <td>191.449997</td>\n",
              "      <td>46505100</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>AAPL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-11-21 00:00:00-05:00</th>\n",
              "      <td>191.410004</td>\n",
              "      <td>191.520004</td>\n",
              "      <td>189.740005</td>\n",
              "      <td>190.639999</td>\n",
              "      <td>38134500</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>AAPL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-11-22 00:00:00-05:00</th>\n",
              "      <td>191.490005</td>\n",
              "      <td>192.929993</td>\n",
              "      <td>190.830002</td>\n",
              "      <td>191.309998</td>\n",
              "      <td>39617700</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>AAPL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-11-24 00:00:00-05:00</th>\n",
              "      <td>190.869995</td>\n",
              "      <td>190.899994</td>\n",
              "      <td>189.250000</td>\n",
              "      <td>189.970001</td>\n",
              "      <td>24048300</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>AAPL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-11-27 00:00:00-05:00</th>\n",
              "      <td>189.919998</td>\n",
              "      <td>190.669998</td>\n",
              "      <td>188.899994</td>\n",
              "      <td>189.789993</td>\n",
              "      <td>40552600</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>AAPL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-11-28 00:00:00-05:00</th>\n",
              "      <td>189.779999</td>\n",
              "      <td>191.080002</td>\n",
              "      <td>189.399994</td>\n",
              "      <td>190.399994</td>\n",
              "      <td>38415400</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>AAPL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-11-29 00:00:00-05:00</th>\n",
              "      <td>190.899994</td>\n",
              "      <td>192.089996</td>\n",
              "      <td>188.970001</td>\n",
              "      <td>189.369995</td>\n",
              "      <td>43014200</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>AAPL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-11-30 00:00:00-05:00</th>\n",
              "      <td>189.839996</td>\n",
              "      <td>190.320007</td>\n",
              "      <td>188.190002</td>\n",
              "      <td>189.949997</td>\n",
              "      <td>48715100</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>AAPL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-12-01 00:00:00-05:00</th>\n",
              "      <td>190.330002</td>\n",
              "      <td>191.339996</td>\n",
              "      <td>189.229996</td>\n",
              "      <td>191.259995</td>\n",
              "      <td>18494967</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>AAPL</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f53b5e0b-ba63-4da1-80ab-b0c16f769a35')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f53b5e0b-ba63-4da1-80ab-b0c16f769a35 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f53b5e0b-ba63-4da1-80ab-b0c16f769a35');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-245fe61f-4b6f-422d-9347-951224fdf3ed\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-245fe61f-4b6f-422d-9347-951224fdf3ed')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-245fe61f-4b6f-422d-9347-951224fdf3ed button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_74bbfd10-9675-4ad6-8586-8be29c0faa17\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('hist')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_74bbfd10-9675-4ad6-8586-8be29c0faa17 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('hist');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hist_data_by_ticker = pd.DataFrame(columns=['Trend Analysis','Volatiity','Trading Volume','Dividend Payout','Stock Splits'])\n",
        "\n",
        "hist_str = \"\"\n",
        "\n",
        "for i in hist.index:\n",
        "  hist_str+=str(\"AAPL\")+' '\n",
        "  hist_str+=\"Date: **\"+str(i)+'**\\n'\n",
        "  hist_str+=\"Open Price: **\"+str(hist.at[i,'Open'])+'**\\n'\n",
        "  hist_str+=\"Highest Price: **\"+str(hist.at[i,'High'])+'**\\n'\n",
        "  hist_str+=\"Lowest Price: **\"+str(hist.at[i,'Low'])+'**\\n'\n",
        "  hist_str+=\"Closing Price: **\"+str(hist.at[i,'Close'])+'**\\n'\n",
        "  hist_str+=\"Volume Traded: **\"+str(hist.at[i,'Volume'])+'**\\n'\n",
        "  hist_str+=\"Dividends paid out: **\"+str(hist.at[i,'Dividends'])+'**\\n'\n",
        "  hist_str+=\"Stock Splits: **\"+str(hist.at[i,'Stock Splits'])+'**\\n'\n",
        "  hist_str+='\\n\\n'"
      ],
      "metadata": {
        "id": "c-hiOmulRPZo"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_tokens_from_string(hist_str, \"gpt-3.5-turbo-16k\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s6uAkzDeSjLu",
        "outputId": "a93b3572-8083-4eba-fbcf-6482d4a7cc3c"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2209"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hist_str[:2200]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 182
        },
        "id": "wqb1G3A_U61V",
        "outputId": "fc4da15c-5c92-458c-e3b1-41ac4a236f7c"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'AAPL Date: **2023-11-01 00:00:00-04:00**\\nOpen Price: **170.7750106172122**\\nHighest Price: **174.00075655092**\\nLowest Price: **169.8961635809227**\\nClosing Price: **173.74110412597656**\\nVolume Traded: **56934900**\\nDividends paid out: **0.0**\\nStock Splits: **0.0**\\n\\n\\nAAPL Date: **2023-11-02 00:00:00-04:00**\\nOpen Price: **175.28907412436934**\\nHighest Price: **177.54609517602384**\\nLowest Price: **175.22915550404335**\\nClosing Price: **177.3363800048828**\\nVolume Traded: **77334800**\\nDividends paid out: **0.0**\\nStock Splits: **0.0**\\n\\n\\nAAPL Date: **2023-11-03 00:00:00-04:00**\\nOpen Price: **174.01075448735614**\\nHighest Price: **176.58736175920453**\\nLowest Price: **173.1219260874277**\\nClosing Price: **176.41757202148438**\\nVolume Traded: **79763700**\\nDividends paid out: **0.0**\\nStock Splits: **0.0**\\n\\n\\nAAPL Date: **2023-11-06 00:00:00-05:00**\\nOpen Price: **176.14794523268097**\\nHighest Price: **179.19392021761848**\\nLowest Price: **175.9781707269317**\\nClosing Price: **178.9941864013672**\\nVolume Traded: **63841300**\\nDividends paid out: **0.0**\\nStock Splits: **0.0**\\n\\n\\nAAPL Date: **2023-11-07 00:00:00-05:00**\\nOpen Price: **178.94423894557977**\\nHighest Price: **182.19995939602362**\\nLowest Price: **178.7345237840102**\\nClosing Price: **181.58078002929688**\\nVolume Traded: **70530000**\\nDividends paid out: **0.0**\\nStock Splits: **0.0**\\n\\n\\nAAPL Date: **2023-11-08 00:00:00-05:00**\\nOpen Price: **182.11008547723094**\\nHighest Price: **183.2086290475756**\\nLowest Price: **181.35107566780474**\\nClosing Price: **182.6493682861328**\\nVolume Traded: **49340300**\\nDividends paid out: **0.0**\\nStock Splits: **0.0**\\n\\n\\nAAPL Date: **2023-11-09 00:00:00-05:00**\\nOpen Price: **182.71927755560236**\\nHighest Price: **183.87773970716447**\\nLowest Price: **181.57078152191718**\\nClosing Price: **182.1699981689453**\\nVolume Traded: **53763500**\\nDividends paid out: **0.0**\\nStock Splits: **0.0**\\n\\n\\nAAPL Date: **2023-11-10 00:00:00-05:00**\\nOpen Price: **183.97000122070312**\\nHighest Price: **186.57000732421875**\\nLowest Price: **183.52999877929688**\\nClosing Price: **186.39999389648438**\\nVolume Traded: **66133400**\\nDividends paid out: **0.24**\\nStock Splits: **0.0**\\n\\n\\nAAPL Date: **2023-11-13 00:00:00-05:00**\\nOpen Price: **185.8'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def split_into_chunks(text, chunk_size=4000):\n",
        "    return [text[i:i+chunk_size] for i in range(0, len(text), chunk_size)]\n",
        "\n",
        "def num_tokens_from_string(string: str, encoding_name: str) -> int:\n",
        "    \"\"\"Returns the number of tokens in a text string.\"\"\"\n",
        "    encoding = tiktoken.encoding_for_model(encoding_name)\n",
        "    num_tokens = len(encoding.encode(string))\n",
        "    return num_tokens\n",
        "\n",
        "def historical_data_evaluator(hist_str):\n",
        "    response_schemas = [\n",
        "        ResponseSchema(name=\"Price Summary\", description=\"\"\"Summary of open, high, low and close price for the ticker in the given time period\"\"\"),\n",
        "        ResponseSchema(name=\"Volatility\", description=\"\"\"Summary of volume of shares traded for the ticker over the given time period\"\"\"),\n",
        "        ResponseSchema(name=\"Dividend Payout\", description=\"\"\"Summary of dividend payout schedule for the ticker over the given time period\"\"\"),\n",
        "        ResponseSchema(name=\"Stock Split\", description=\"\"\"Summary of stock splits conducted over the given time frame\"\"\"),\n",
        "    ]\n",
        "    output_parser = StructuredOutputParser.from_response_schemas(response_schemas)\n",
        "    format_instructions = output_parser.get_format_instructions()\n",
        "\n",
        "    chat_model = ChatOpenAI(model_name=\"gpt-3.5-turbo-16k\", temperature=0.5, openai_api_key = \"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\")\n",
        "\n",
        "    prompt = ChatPromptTemplate(\n",
        "        messages=[\n",
        "            HumanMessagePromptTemplate.from_template(\"\"\"\n",
        "            You are a helpful assistant who evaluates historical stock price data by ticker and extracts the required information in the following format:\n",
        "            {format_instructions}\n",
        "\n",
        "            Historical Data: {question}\"\"\")\n",
        "        ],\n",
        "        input_variables=[\"question\"],\n",
        "        partial_variables={\"format_instructions\": format_instructions}\n",
        "    )\n",
        "\n",
        "    topic_dict = {}\n",
        "    token_check = 0\n",
        "    clean_transcript = hist_str\n",
        "    transcription_token_length = num_tokens_from_string(clean_transcript, \"gpt-3.5-turbo-16k\")\n",
        "    if transcription_token_length<16000:\n",
        "      _input = prompt.format_prompt(question=clean_transcript)\n",
        "      output = chat_model(_input.to_messages())\n",
        "      return(output_parser.parse(output.content))\n",
        "    else:\n",
        "      print(\"Token Limit Exceeded. Summarizing and evaluating\")\n",
        "      complete_content_chunks = split_into_chunks(clean_transcript,16000)\n",
        "      summarized_transcription = []\n",
        "      for chunk in complete_content_chunks:\n",
        "        doc =  Document(page_content=chunk, metadata={\"source\": \"transcription\"})\n",
        "        summ_chain = load_summarize_chain(chat_model, chain_type=\"stuff\")\n",
        "        transcription = summ_chain.run([doc])\n",
        "        summarized_transcription.append(transcription)\n",
        "      summarized_transcription = ' '.join(summarized_transcription)\n",
        "      summ_chain = load_summarize_chain(chat_model, chain_type=\"stuff\")\n",
        "      doc_summarized =  Document(page_content=summarized_transcription, metadata={\"source\": \"summarized_transcription\"})\n",
        "      summarized_transcription_updated = summ_chain.run([doc_summarized])\n",
        "      _input = prompt.format_prompt(question=summarized_transcription_updated+'\\nURL: '+str(list(self.transcriptions.keys())[0]))\n",
        "      output = chat_model(_input.to_messages())\n",
        "      topic_dict[output_parser.parse(output.content)['URL']] = output_parser.parse(output.content)\n",
        "      return(output_parser.parse(output.content))"
      ],
      "metadata": {
        "id": "nE8nco-8Q6oI"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "historical_data_evaluator(hist_str)"
      ],
      "metadata": {
        "id": "64J790hpT1lL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import yfinance as yf\n",
        "\n",
        "apple = yf.Ticker(\"AAPL\")\n",
        "apple"
      ],
      "metadata": {
        "id": "uwuQ0G3HNDyT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_news_by_ticker(ticker):\n",
        "  newspaper_df = pd.DataFrame(columns=['Source','Title','Description','ticker'])\n",
        "  newsapi = NewsApiClient(api_key='5fc3bec598764fb494807952a7797ce8')\n",
        "  all_articles = newsapi.get_everything(\n",
        "      q=ticker,\n",
        "      language='en',\n",
        "      from_param='2023-11-01',\n",
        "      sort_by='relevancy'\n",
        "  )\n",
        "  for article in all_articles['articles']:\n",
        "      print('Source : ',article['source']['name'])\n",
        "      print('Title : ',article['title'])\n",
        "      print('Description : ',article['description'],'\\n\\n')\n",
        "      newspaper_df = newspaper_df.append({'Source':article['source']['name'],'Title':article['title'],'Description':article['description'],'Ticker':ticker},ignore_index=True)\n",
        "\n",
        "  return(newspaper_df)\n",
        "\n",
        "news_by_ticker = pd.DataFrame(columns=['Source','Title','Description','Ticker'])\n",
        "\n",
        "for ticker_name in list(ticker_info_mapping.keys())[:5]:\n",
        "  news_by_ticker = pd.concat([news_by_ticker,get_news_by_ticker(ticker_name)], axis=0)"
      ],
      "metadata": {
        "id": "9UzdytEXAHE5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "news_by_ticker"
      ],
      "metadata": {
        "id": "qbuH8R01ySsm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"human-centered-summarization/financial-summarization-pegasus\"\n",
        "tokenizer = PegasusTokenizer.from_pretrained(model_name)\n",
        "model = PegasusForConditionalGeneration.from_pretrained(model_name)"
      ],
      "metadata": {
        "id": "tadrBSc9EUQC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_to_summarize = news_by_ticker['Description'].iloc[1]\n",
        "input_ids = tokenizer(text_to_summarize, return_tensors=\"pt\").input_ids\n",
        "\n",
        "# Generate the output (Here, we use beam search but you can also use any other strategy you like)\n",
        "output = model.generate(\n",
        "    input_ids,\n",
        "    max_length=60,\n",
        "    num_beams=5,\n",
        "    early_stopping=True\n",
        ")\n",
        "\n",
        "# Finally, we can print the generated summary\n",
        "print(tokenizer.decode(output[0], skip_special_tokens=True))"
      ],
      "metadata": {
        "id": "W31cPt_CLQpB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_to_llm = \"\"\n",
        "\n",
        "for ticker in list(news_by_ticker.Ticker.unique()):\n",
        "  input_to_llm+=\"Ticker\"+str(ticker)+\"\\n\"\n",
        "  req = news_by_ticker[news_by_ticker.Ticker==ticker]\n",
        "  for index in req.index:\n",
        "    input_to_llm+=\"ARTICLE SOURCE: \"+req.at[index,'Source']+\"; \"\n",
        "    input_to_llm+=\"ARTICLE TITLE: \"+req.at[index,'Title']+\"; \"\n",
        "    input_to_llm+=\"ARTICLE DESCRIPTION: \"+str(req.at[index,'Description'])+\"; \"\n",
        "    input_to_llm+=\"\\n\"\n",
        "  input_to_llm+=\"--------------------------\\n\\n\"\n",
        "\n",
        "input_to_llm"
      ],
      "metadata": {
        "id": "wizcbfFHC8CR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_tokens_from_string()"
      ],
      "metadata": {
        "id": "mOZm5HfpFAFC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def split_into_chunks(text, chunk_size=4000):\n",
        "    return [text[i:i+chunk_size] for i in range(0, len(text), chunk_size)]\n",
        "\n",
        "def num_tokens_from_string(string: str, encoding_name: str) -> int:\n",
        "    \"\"\"Returns the number of tokens in a text string.\"\"\"\n",
        "    encoding = tiktoken.encoding_for_model(encoding_name)\n",
        "    num_tokens = len(encoding.encode(string))\n",
        "    return num_tokens\n",
        "\n",
        "def ppl_news_entities_extractor(self):\n",
        "    response_schemas = [\n",
        "        ResponseSchema(name=\"Positive News\", description=\"List of Positive News Articles about **PPL Corporation**, if any else return no news\"),\n",
        "        ResponseSchema(name=\"Positive Aspect\", description=\"List of Topics discussed by the Positive News Articles about **PPL Corporation**, if any else return no news\"),\n",
        "        ResponseSchema(name=\"Negative News\", description=\"List of Negative News Articles about **PPL Corporation**, if any else return no news\"),\n",
        "        ResponseSchema(name=\"Negative Aspect\", description=\"List of Topics discussed by the Negative News Articles about **PPL Corporation**, if any else return no news\"),\n",
        "        ResponseSchema(name=\"Neutral News\", description=\"List of Neutral News Articles about **PPL Corporation**, if any else return no news\"),\n",
        "        ResponseSchema(name=\"Neutral Aspect\", description=\"List of Topics discussed by the Neutral News Articles about **PPL Corporation**, if any else return no news\"),\n",
        "        ResponseSchema(name=\"Publish Date\", description=\"List of dates the articles was published, if any else return no news\"),\n",
        "    ]\n",
        "    output_parser = StructuredOutputParser.from_response_schemas(response_schemas)\n",
        "    format_instructions = output_parser.get_format_instructions()\n",
        "\n",
        "    chat_model = ChatOpenAI(model_name=\"gpt-3.5-turbo-16k\", temperature=0.5, openai_api_key = \"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\")\n",
        "\n",
        "    prompt = ChatPromptTemplate(\n",
        "        messages=[\n",
        "            HumanMessagePromptTemplate.from_template(\"\"\"\n",
        "            You are a helpful assistant who evaluates news articles for the day split by \"\\n\\n\", identifies positive and negative news about **PPL Corporation** and summarizes it in a concise format.\n",
        "            {format_instructions}\n",
        "            News Articles: {question}\"\"\")\n",
        "        ],\n",
        "        input_variables=[\"question\"],\n",
        "        partial_variables={\"format_instructions\": format_instructions}\n",
        "    )\n",
        "\n",
        "    topic_dict = {}\n",
        "    token_check = 0\n",
        "    clean_transcript = input_to_llm_two[:16000]\n",
        "    transcription_token_length = num_tokens_from_string(clean_transcript, \"gpt-3.5-turbo-16k\")\n",
        "    if transcription_token_length<16000:\n",
        "      _input = prompt.format_prompt(question=clean_transcript)\n",
        "      output = chat_model(_input.to_messages())\n",
        "      return(output_parser.parse(output.content))\n",
        "    else:\n",
        "      print(\"Token Limit Exceeded. Summarizing and evaluating\")\n",
        "      complete_content_chunks = split_into_chunks(clean_transcript,16000)\n",
        "      summarized_transcription = []\n",
        "      for chunk in complete_content_chunks:\n",
        "        doc =  Document(page_content=chunk, metadata={\"source\": \"transcription\"})\n",
        "        summ_chain = load_summarize_chain(chat_model, chain_type=\"stuff\")\n",
        "        transcription = summ_chain.run([doc])\n",
        "        summarized_transcription.append(transcription)\n",
        "      summarized_transcription = ' '.join(summarized_transcription)\n",
        "      summ_chain = load_summarize_chain(chat_model, chain_type=\"stuff\")\n",
        "      doc_summarized =  Document(page_content=summarized_transcription, metadata={\"source\": \"summarized_transcription\"})\n",
        "      summarized_transcription_updated = summ_chain.run([doc_summarized])\n",
        "      _input = prompt.format_prompt(question=summarized_transcription_updated+'\\nURL: '+str(list(self.transcriptions.keys())[0]))\n",
        "      output = chat_model(_input.to_messages())\n",
        "      topic_dict[output_parser.parse(output.content)['URL']] = output_parser.parse(output.content)\n",
        "      return(output_parser.parse(output.content))"
      ],
      "metadata": {
        "id": "19HuFkMPCoXD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = ppl_news_entities_extractor(input_to_llm_two)\n",
        "output_df = pd.DataFrame(columns=['Positive News','Positive Aspect','Negative News','Negative Aspect','Neutral News','Neutral Aspect','Publish Date'])\n",
        "output_df = output_df.append({'Positive News':response['Positive News'],'Positive Aspect':response['Positive Aspect'],'Negative News':response['Negative News'], 'Negative Aspect':response['Negative Aspect'],'Neutral News':response['Neutral News'], 'Neutral Aspect':response['Neutral Aspect'], 'Publish Date':response['Publish Date']}, ignore_index=True)\n",
        "output_df"
      ],
      "metadata": {
        "id": "oNOc-d-K0JsE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output_df['Positive News'].iloc[0]"
      ],
      "metadata": {
        "id": "6U7VrWL7SBao"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output_df['Neutral News'].iloc[0].split(',')"
      ],
      "metadata": {
        "id": "1fsb75C0TaDW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output_df['Negative News'].iloc[0]"
      ],
      "metadata": {
        "id": "3LsFllM5Td9s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "\n",
        "review_df = pd.DataFrame(columns=['Review'])\n",
        "\n",
        "# Loop through all pages\n",
        "for i in range(10):\n",
        "  # Send GET request and retrieve HTML content\n",
        "  response = requests.get('https://www.yelp.com/biz/ppl-electric-utilities-allentown?start=10')\n",
        "  soup = BeautifulSoup(response.content, 'html.parser')\n",
        "  comment_sections = soup.find_all('div', {'class': 'css-9ul5p9'})\n",
        "  # List to hold reviews\n",
        "  reviews = []\n",
        "\n",
        "  # Loop through all divs and extract the text\n",
        "  for div in comment_sections:\n",
        "      review_p = div.find(\"p\", class_=\"comment__09f24__D0cxf\")\n",
        "      if review_p:\n",
        "          review_text = review_p.get_text(strip=True)\n",
        "          reviews.append(review_text)\n",
        "\n",
        "  # Convert list to DataFrame\n",
        "  df_reviews = pd.DataFrame(reviews, columns=['Review'])\n",
        "  review_df = pd.concat([review_df,df_reviews])\n",
        "\n",
        "review_df"
      ],
      "metadata": {
        "id": "XCfKEHfJVTKK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "review_df.reset_index(drop=True, inplace=True)"
      ],
      "metadata": {
        "id": "VgntBwBXctxL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_to_llm_three = \"\"\n",
        "\n",
        "for index in review_df.index:\n",
        "  input_to_llm_three+=\"Review\"+str(index)+\": \"\n",
        "  input_to_llm_three+=\"Review: \"+review_df.at[index,'Review']\n",
        "  input_to_llm_three+=\"\\n\\n\"\n",
        "\n",
        "input_to_llm_three"
      ],
      "metadata": {
        "id": "HUSwT4-qWwkC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def split_into_chunks(text, chunk_size=4000):\n",
        "    return [text[i:i+chunk_size] for i in range(0, len(text), chunk_size)]\n",
        "\n",
        "def num_tokens_from_string(string: str, encoding_name: str) -> int:\n",
        "    \"\"\"Returns the number of tokens in a text string.\"\"\"\n",
        "    encoding = tiktoken.encoding_for_model(encoding_name)\n",
        "    num_tokens = len(encoding.encode(string))\n",
        "    return num_tokens\n",
        "\n",
        "def ppl_comments_entities_extractor(self):\n",
        "    response_schemas = [\n",
        "        ResponseSchema(name=\"Positive Comments\", description=\"List of Positive Comments about **PPL Corporation**, if any else return no news\"),\n",
        "        ResponseSchema(name=\"Positive Aspect\", description=\"List of Topics discussed by the Positive Comments about **PPL Corporation**, if any else return no news\"),\n",
        "        ResponseSchema(name=\"Negative Comments\", description=\"List of Negative Comments about **PPL Corporation**, if any else return no news\"),\n",
        "        ResponseSchema(name=\"Negative Aspect\", description=\"List of Topics discussed by the Negative Comments about **PPL Corporation**, if any else return no news\"),\n",
        "        ResponseSchema(name=\"Neutral Comments\", description=\"List of Neutral Comments about **PPL Corporation**, if any else return no news\"),\n",
        "        ResponseSchema(name=\"Neutral Aspect\", description=\"List of Topics discussed by the Neutral Comments about **PPL Corporation**, if any else return no news\")\n",
        "    ]\n",
        "    output_parser = StructuredOutputParser.from_response_schemas(response_schemas)\n",
        "    format_instructions = output_parser.get_format_instructions()\n",
        "\n",
        "    chat_model = ChatOpenAI(model_name=\"gpt-3.5-turbo-16k\", temperature=0.5, openai_api_key = \"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\")\n",
        "\n",
        "    prompt = ChatPromptTemplate(\n",
        "        messages=[\n",
        "            HumanMessagePromptTemplate.from_template(\"\"\"\n",
        "            You are a helpful assistant who evaluates reviews about PPL Corporation over a period of time split by \"\\n\\n\", identifies positive, negative and neutral comments about **PPL Corporation** and summarizes it in a concise format.\n",
        "            {format_instructions}\n",
        "            Comments: {question}\"\"\")\n",
        "        ],\n",
        "        input_variables=[\"question\"],\n",
        "        partial_variables={\"format_instructions\": format_instructions}\n",
        "    )\n",
        "\n",
        "    topic_dict = {}\n",
        "    token_check = 0\n",
        "    clean_transcript = input_to_llm_three[:16000]\n",
        "    transcription_token_length = num_tokens_from_string(clean_transcript, \"gpt-3.5-turbo-16k\")\n",
        "    if transcription_token_length<16000:\n",
        "      _input = prompt.format_prompt(question=clean_transcript)\n",
        "      output = chat_model(_input.to_messages())\n",
        "      return(output_parser.parse(output.content))\n",
        "    else:\n",
        "      print(\"Token Limit Exceeded. Summarizing and evaluating\")\n",
        "      complete_content_chunks = split_into_chunks(clean_transcript,16000)\n",
        "      summarized_transcription = []\n",
        "      for chunk in complete_content_chunks:\n",
        "        doc =  Document(page_content=chunk, metadata={\"source\": \"transcription\"})\n",
        "        summ_chain = load_summarize_chain(chat_model, chain_type=\"stuff\")\n",
        "        transcription = summ_chain.run([doc])\n",
        "        summarized_transcription.append(transcription)\n",
        "      summarized_transcription = ' '.join(summarized_transcription)\n",
        "      summ_chain = load_summarize_chain(chat_model, chain_type=\"stuff\")\n",
        "      doc_summarized =  Document(page_content=summarized_transcription, metadata={\"source\": \"summarized_transcription\"})\n",
        "      summarized_transcription_updated = summ_chain.run([doc_summarized])\n",
        "      _input = prompt.format_prompt(question=summarized_transcription_updated+'\\nURL: '+str(list(self.transcriptions.keys())[0]))\n",
        "      output = chat_model(_input.to_messages())\n",
        "      topic_dict[output_parser.parse(output.content)['URL']] = output_parser.parse(output.content)\n",
        "      return(output_parser.parse(output.content))"
      ],
      "metadata": {
        "id": "un647FodYQrl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ppl_comments_entities_extractor(input_to_llm_three)"
      ],
      "metadata": {
        "id": "CUbIiL9aTfhu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = ppl_comments_entities_extractor(input_to_llm_three)\n",
        "output_df_two = pd.DataFrame(columns=['Positive Comments','Positive Aspect','Negative Comments','Negative Aspect','Neutral Comments','Neutral Aspect','Publish Date'])\n",
        "output_df_two = output_df_two.append({'Positive Comments':response['Positive Comments'],'Positive Aspect':response['Positive Aspect'],'Negative Comments':response['Negative Comments'], 'Negative Aspect':response['Negative Aspect'],'Neutral Comments':response['Neutral Comments'], 'Neutral Aspect':response['Neutral Aspect']}, ignore_index=True)\n",
        "output_df_two"
      ],
      "metadata": {
        "id": "eAC17GzOdab-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output_df.to_csv(r'/content/news_info.csv')"
      ],
      "metadata": {
        "id": "maSRrheSfHxZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output_df_two.to_csv(r'/content/comments_info.csv')"
      ],
      "metadata": {
        "id": "L81Sxg3IfyNQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#review_df = pd.DataFrame(columns=['Review'])\n",
        "\n",
        "# Loop through all pages\n",
        "#for i in range(10):\n",
        "# Send GET request and retrieve HTML content\n",
        "\n",
        "response = requests.get('https://www.papowerswitch.com/shop-for-electricity/shop-for-your-home/')\n",
        "soup = BeautifulSoup(response.content, 'html.parser')\n",
        "comment_sections = soup.find_all('div', {'class': 'distributor-estimated-rated'})\n",
        "comment_sections"
      ],
      "metadata": {
        "id": "alEUwGdmf8g8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "o_2XBdpuyvgC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}